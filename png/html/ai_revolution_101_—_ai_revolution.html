<!DOCTYPE html><html><head><title>AI Revolution 101 — AI Revolution</title></head><body>
<h1>AI Revolution 101 — AI Revolution</h1><p><a href="https://medium.com/ai-revolution/ai-revolution-101-8dce1d9cb62d" target="_new">Original URL</a></p>
<p><blockquote>This essay, originally published in eight short parts, aims to condense the current knowledge on Artificial Intelligence. It explores the state of AI development, overviews its challenges and&hellip;</blockquote></p>
<div score="17.5"><section name="ada5" class=" section--body section--first" score="41.25"><div class="section-content" score="67.5"><div class="section-inner sectionLayout--fullWidth" score="1.25"><figure name="777d" id="777d" class="graf--figure graf--layoutFillWidth graf--leading" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/2000/1*Iw5mXpFl-Hoy06WaenJvWw.gif"></div></figure></div><div class="section-inner layoutSingleColumn" score="1.25"><p name="777b" id="777b" class="graf--p graf-after--h4">This essay, originally published in eight short parts, aims to condense the current knowledge on Artificial Intelligence. It explores the state of AI development, overviews its challenges and dangers, features work by the most significant scientists, and describes the main predictions of possible AI outcomes. This project is an adaptation and major shortening of the two&#x2013;part essay <a href="http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html" class="markup--anchor markup--p-anchor" rel="nofollow">AI Revolution</a> by Tim Urban of Wait But Why. I shortened it by a factor of 3, recreated all images, and tweaked it a bit. Read more on why/how I wrote it <a href="https://medium.com/ai-revolution/writing-ai-revolution-231633145281#.14j00ygg1" class="markup--anchor markup--p-anchor">here</a>.</p><p name="19cd" id="19cd" class="graf--p graf-after--h4">Assuming that human scientific activity continues without major disruptions, artificial intelligence may become either the most positive transformation of our history or, as many fear, our most dangerous invention of all. AI research is on a steady path to develop a computer that has cognitive abilities equal to the human brain, most likely within three decades (timeline in chapter 5). From what most AI scientists predict, this invention may enable very rapid improvements (called <em class="markup--em markup--p-em">fast take-off</em>), toward something much more powerful&#x200A;&#x2014;&#x200A;Artificial Super Intelligence&#x200A;&#x2014;&#x200A;an entity smarter than all of humanity combined (more on ASI in chapter 3). We are not talking about some imaginary future. The first level of AI development is gradually appearing in the technology we use everyday (newest AI advancements in chapter 2). With every coming year these advancements will accelerate and the technology will become more complex, addictive, and ubiquitous. We will continue to outsource more and more kinds of mental work to computers, disrupting every part of our reality: the way we organize ourselves and our work, form communities, and experience the world.</p><p name="f62c" id="f62c" class="graf--p graf-after--h4">To more intuitively grasp the guiding principles of AI revolution, let&#x2019;s first step away from scientific research. Let me invite you to take part in a story. Imagine that you&#x2019;ve received a time machine and been given a quest to bring somebody from the past. The goal is to shock them by showing them the technological and cultural advancements of our time, to such a degree that this person would perform SAFD (Spinning Around From Disbelief).</p><figure name="4799" id="4799" class="graf--figure graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/800/0*nztrdWTZ3NM9L8eI."></div></figure><p name="dbc2" id="dbc2" class="graf--p graf-after--figure">So you wonder which era should you time-travel to, and decide to hop back around 200 years. You get to the early 1800s, retrieve a guy and bring him back to 2016. You &#x201C;&#x2026;walk him around and watch him react to everything. It&#x2019;s impossible for us to understand what it would be like for him to see shiny capsules racing by on a highway, talk to people who had been on the other side of the ocean earlier in the day, watch sports that were being played 1,000 miles away, hear a musical performance that happened 50 years ago, and play with&#xA0;&#x2026;[a] magical wizard rectangle that he could use to capture a real-life image or record a living moment, generate a map with a paranormal moving blue dot that shows him where he is, look at someone&#x2019;s face and chat with them even though they&#x2019;re on the other side of the country, and worlds of other inconceivable sorcery.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;</a> It doesn&#x2019;t take much. After two minutes he is SAFDing.</p><p name="aab4" id="aab4" class="graf--p graf-after--p">Now, both of you want to try the same thing, see somebody Spinning Around From Disbelief, but in your new friend&#x2019;s era. Since 200 years worked, you jump back to the 1600s and bring a guy to the 1800s. He&#x2019;s certainly genuinely interested in what he sees. However, you feel it with confidence&#x200A;&#x2014;&#x200A;SAFD will never happen to him. You feel that you need to jump back again, but somewhere radically further. You settle on rewinding the clock 15,000 years, to the times &#x201C;&#x2026;before the First Agricultural Revolution gave rise to the first cities and the concept of civilisations.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB2;</a> You bring someone from the hunter-gatherer world and show him &#x201C;&#x2026;the vast human empires of 1750 with their towering churches, their ocean-crossing ships, their concept of being &#x201C;inside,&#x201D; and their enormous mountain of collective, accumulated human knowledge and discovery&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB3;</a>&#x200A;&#x2014;&#x200A;in forms of books. It doesn&#x2019;t take much. He is SAFDing in the first two minutes.</p><p name="0231" id="0231" class="graf--p graf-after--p">Now there are three of you, enormously excited to do it again. You know that it doesn&#x2019;t make sense to go back another 15,000, 30,000 or 45,000 years. You have to jump back, again, radically further. So you pick up a guy from 100,000 years ago and you you walk with him into large tribes with organized, sophisticated social hierarchies. He encounters a variety of hunting weapons, sophisticated tools, sees fire and for the first time experiences language in the form of signs and sounds. You get the idea, it has to be immensely mind-blowing. He is SAFDing after two minutes.</p><p name="d6df" id="d6df" class="graf--p graf-after--p">So what happened? Why did the last guy had to hop &#x2192; 100,000 years, the next one &#x2192; 15,000 years, and the guy who was hopping to our times only &#x2192; 200 years?</p></div><div class="section-inner sectionLayout--fullWidth" score="1.25"><figure name="c618" id="c618" class="graf--figure graf--layoutFillWidth graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/2000/1*Wbd0td3DqD3pJo7_YHjkbQ.gif"></div></figure></div><div class="section-inner layoutSingleColumn" score="8.25"><p name="8ed2" id="8ed2" class="graf--p graf--startsWithDoubleQuote graf-after--figure">&#x201C;This happens because more advanced societies have the ability to progress at a faster rate than less advanced societies&#x200A;&#x2014;&#x200A;because they&#x2019;re more advanced. [1800s] humanity knew more and had better technology&#x2026;&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2074;</a>, so it&#x2019;s no wonder they could make further advancements than humanity from 15,000 years ago. The time to achieve SAFD shrank from ~100,000 years to ~200 years and if we look into the future it will rapidly shrink even further. Ray Kurzweil, AI expert and scientist, predicts that a &#x201C;&#x2026;20th century&#x2019;s worth of progress happened between 2000 and 2014 and that another 20th century&#x2019;s worth of progress will happen by 2021, in only seven years<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2075;</a>&#x2026;A couple decades later, he believes a 20th century&#x2019;s worth of progress will happen multiple times in the same year, and even later, in less than one month<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2076;</a>&#x2026;Kurzweil believes that the 21st century will achieve 1,000 times the progress of the 20th century.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2077;</a></p><p name="fde1" id="fde1" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;Logic also suggests that if the most advanced species on a planet keeps making larger and larger leaps forward at an ever-faster rate, at some point, they&#x2019;ll make a leap so great that it completely alters life as they know it and the perception they have of what it means to be a human. Kind of like how evolution kept making great leaps toward intelligence until finally it made such a large leap to the human being that it completely altered what it meant for any creature to live on planet Earth. And if you spend some time reading about what&#x2019;s going on today in science and technology, you start to see a lot of signs quietly hinting that life as we currently know it cannot withstand the leap that&#x2019;s coming next.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2078;</a></p><p name="7186" id="7186" class="graf--p graf-after--h4">Artificial Intelligence, or AI, is a broad term for the advancement of intelligence in computers. Despite varied opinions on this topic, most experts agree that there are three categories, or calibers, of AI development. They are:</p><p name="2e82" id="2e82" class="graf--p graf-after--h4">1st intelligence caliber. &#x201C;AI that specializes in one area. There&#x2019;s AI that can beat the world chess champion in chess, but that&#x2019;s the only thing it does.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2079;</a></p><p name="ada4" id="ada4" class="graf--p graf-after--h4">2nd intelligence caliber. AI that reaches and then passes the intelligence level of a human, meaning it has the ability to &#x201C;reason, plan, solve problems, think abstractly, comprehend complex ideas, learn quickly, and learn from experience.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#x2070;</a></p><p name="0c03" id="0c03" class="graf--p graf-after--h4">3rd intelligence caliber. AI that achieves a level of intelligence smarter than all of humanity combined&#x200A;&#x2014;&#x200A;&#x201C;ranging from just a little smarter&#xA0;&#x2026; to one trillion times smarter.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB9;</a></p><figure name="64ca" id="64ca" class="graf--figure graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/800/1*5AkzXZJoVXRrGNSOO8ZojQ.gif"></div></figure><p name="5c6b" id="5c6b" class="graf--p graf--startsWithDoubleQuote graf-after--h4">&#x201C;As of now, humans have conquered the lowest caliber of AI&#x200A;&#x2014;&#x200A;ANI&#x200A;&#x2014;&#x200A;in many ways, and it&#x2019;s everywhere:&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB2;</a></p><ul class="postList"><li name="a3fa" id="a3fa" class="graf--li graf--startsWithDoubleQuote graf-after--p">&#x201C;Cars are full of ANI systems, from the computer that figures out when the anti-lock brakes kick in, to the computer that tunes the parameters of the fuel injection systems.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--li-anchor">&#xB9;&#xB3;</a></li><li name="7627" id="7627" class="graf--li graf--startsWithDoubleQuote graf-after--li">&#x201C;Google search is one large ANI brain with incredibly sophisticated methods for ranking pages and figuring out what to show you in particular. Same goes for Facebook&#x2019;s Newsfeed.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--li-anchor">&#xB9;&#x2074;</a></li><li name="8878" id="8878" class="graf--li graf-after--li">Email spam filters &#x201C;start off loaded with intelligence about how to figure out what&#x2019;s spam and what&#x2019;s not, and then it learns and tailors its intelligence to your particular preferences.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--li-anchor">&#xB9;&#x2075;</a></li><li name="a3f4" id="a3f4" class="graf--li graf-after--li">Passenger planes are flown almost entirely by ANI, without the help of humans.</li><li name="e2de" id="e2de" class="graf--li graf--startsWithDoubleQuote graf-after--li">&#x201C;Google&#x2019;s <a href="https://www.youtube.com/channel/UCCLyNDhxwpqNe3UeEmGHl8g" class="markup--anchor markup--li-anchor" rel="nofollow">self-driving car</a>, which is being tested now, will contain robust ANI systems that allow it to perceive and react to the world around it.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--li-anchor">&#xB9;&#x2076;</a></li><li name="61d5" id="61d5" class="graf--li graf--startsWithDoubleQuote graf-after--li">&#x201C;Your phone is a little ANI factory&#xA0;&#x2026; you navigate using your map app, receive tailored music recommendations from Pandora, check tomorrow&#x2019;s weather, talk to Siri.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--li-anchor">&#xB9;&#x2077;</a></li><li name="2a84" id="2a84" class="graf--li graf--startsWithDoubleQuote graf-after--li">&#x201C;The world&#x2019;s best Checkers, Chess, Scrabble, Backgammon, and Othello players are now all ANI systems.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--li-anchor">&#xB9;&#x2078;</a></li><li name="5f1c" id="5f1c" class="graf--li graf--startsWithDoubleQuote graf-after--li">&#x201C;Sophisticated ANI systems are widely used in sectors and industries like military, manufacturing, and finance (algorithmic high-frequency AI traders account for more than half of equity shares traded on US markets<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--li-anchor">&#xB9;&#x2079;</a>).&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--li-anchor">&#xB2;&#x2070;</a></li></ul><p name="c090" id="c090" class="graf--p graf--startsWithDoubleQuote graf-after--li">&#x201C;ANI systems as they are now aren&#x2019;t especially scary. At worst, a glitchy or badly-programed ANI can cause an isolated catastrophe like&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB2;&#xB9;</a> a plane crash, a nuclear power plant malfunction, or &#x201C;a financial markets disaster (like the <a href="http://www.ritholtz.com/blog/wp-content/uploads/2010/10/flash-crash-dow-popup.png" class="markup--anchor markup--p-anchor" rel="nofollow">2010 Flash Crash</a> when an ANI program reacted the wrong way to an unexpected situation and caused the stock market to briefly plummet, taking $1 trillion of market value with it, only part of which was recovered when the mistake was corrected)&#xA0;&#x2026; But while ANI doesn&#x2019;t have the capability to cause an existential threat, we should see this increasingly large and complex ecosystem of relatively-harmless ANI as a precursor of the world-altering hurricane that&#x2019;s on the way. Each new ANI innovation quietly adds another brick onto the road to AGI and ASI.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB2;&#xB2;</a></p></div><div class="section-inner layoutSingleColumn"><p name="4487" id="4487" class="graf--p graf--startsWithDoubleQuote graf-after--h4">&#x201C;Nothing will make you appreciate human intelligence like learning about how unbelievably challenging it is to try to create a computer as smart as we are&#xA0;&#x2026; Build a computer that can multiply ten-digit numbers in a split second&#x200A;&#x2014;&#x200A;incredibly easy. Build one that can look at a dog and answer whether it&#x2019;s a dog or a cat&#x200A;&#x2014;&#x200A;spectacularly difficult. Make AI that can beat any human in chess? Done. Make one that can read a paragraph from a six-year-old&#x2019;s picture book and not just recognise the words but understand the meaning of them? Google is currently spending <a href="http://www.wired.com/2014/01/google-buying-way-making-brain-irrelevant/" class="markup--anchor markup--p-anchor" rel="nofollow">billions</a> of dollars trying to do it.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB2;&#xB3;</a></p><p name="daed" id="daed" class="graf--p graf-after--p">Why are &#x201C;hard things&#x200A;&#x2014;&#x200A;like calculus, financial market strategy, and language translation&#xA0;&#x2026; mind-numbingly easy for a computer, while easy things&#x200A;&#x2014;&#x200A;like vision, motion, movement, and perception&#x200A;&#x2014;&#x200A;are insanely hard for it&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB2;&#x2074;</a>?</p><p name="9c88" id="9c88" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;Things that seem easy to us are actually unbelievably complicated. They only seem easy because those skills have been optimized in us (and most animals) by hundreds of million years of animal evolution. When you reach your hand up toward an object, the muscles, tendons, and bones in your shoulder, elbow, and wrist instantly perform a long series of physics operations, in conjunction with your eyes, to allow you to move your hand in a straight line through three dimensions&#xA0;&#x2026; On the other hand, multiplying big numbers or playing chess are new activities for biological creatures and we haven&#x2019;t had any time to evolve a proficiency at them, so a computer doesn&#x2019;t need to work too hard to beat us.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB2;&#x2075;</a></p><p name="b95d" id="b95d" class="graf--p graf-after--p">One fun example&#x2026;</p></div><div class="section-inner sectionLayout--outsetColumn" score="1.25"><figure name="ca49" id="ca49" class="graf--figure graf--layoutOutsetCenter graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/1200/0*E-qdF22nxvOrVPxP."></div></figure></div><div class="section-inner layoutSingleColumn" score="4.5"><p name="efec" id="efec" class="graf--p graf-after--figure">When you look at picture A, &#x201C;you and a computer both can figure out that it&#x2019;s a rectangle with two distinct shades, alternating. Tied so far.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB2;&#x2076;</a></p><p name="0de1" id="0de1" class="graf--p graf-after--p">Picture B. &#x201C;You have no problem giving a full description of the various opaque and translucent cylinders, slats, and 3-D corners, but the computer would fail miserably. It would describe what it sees&#x200A;&#x2014;&#x200A;a variety of two-dimensional shapes in several different shades&#x200A;&#x2014;&#x200A;which is actually what&#x2019;s there.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB2;&#x2077;</a> &#x201C;Your brain is doing a ton of fancy shit to interpret the implied depth, shade-mixing, and room lighting the picture is trying to portray.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB2;&#x2078;</a></p><p name="e406" id="e406" class="graf--p graf-after--p">Looking at picture C, &#x201C;a computer sees a two-dimensional white, black, and gray collage, while you easily see what it really is&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB2;&#x2079;</a>&#x200A;&#x2014;&#x200A;a photo of a girl and a dog standing on a rocky shore.</p><p name="252b" id="252b" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;And everything we just mentioned is still only taking in visual information and processing it. To be human-level intelligent, a computer would have to understand things like the difference between subtle facial expressions, the distinction between being pleased, relieved and content&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB3;&#x2070;</a>.</p><p name="bcbf" id="bcbf" class="graf--p graf-after--p">How will computers reach even higher abilities like complex reasoning, interpreting data, and associating ideas from separate fields (<em class="markup--em markup--p-em">domain-general knowledge</em>)?</p><p name="c953" id="c953" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;Building skyscrapers, putting humans in space, figuring out the details of how the Big Bang went down&#x200A;&#x2014;&#x200A;all far easier than understanding our own brain or how to make something as cool as it. As of now, the human brain is the most complex object in the known universe.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB3;&#xB9;</a></p><p name="72a9" id="72a9" class="graf--p graf-after--h4">If an artificial intelligence is going to be as intelligent as the human brain, one crucial thing has to happen&#x200A;&#x2014;&#x200A;the AI &#x201C;needs to equal the brain&#x2019;s raw computing capacity. One way to express this capacity is in the total calculations per second the brain could manage.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB3;&#xB2;</a></p><figure name="7b9a" id="7b9a" class="graf--figure graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/800/0*aMyRLkUtYWlB04HU."></div></figure><p name="c9ee" id="c9ee" class="graf--p graf-after--figure">The challenge is that currently only a few of the brain&#x2019;s regions are precisely measured. However, Ray Kurzweil, has developed a method for estimating the total cps of the human brain. He arrived at this estimate by taking the cps from one brain region and multiplying it proportionally to the weight of that region, compared to the weight of the whole brain. &#x201C;He did this a bunch of times with various professional estimates of different regions, and the total always arrived in the same ballpark&#x200A;&#x2014;&#x200A;around 10&#xB9;&#x2076;, or 10 quadrillion cps.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB3;&#xB3;</a></p><p name="bb98" id="bb98" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;Currently, the world&#x2019;s fastest supercomputer, China&#x2019;s <a href="http://www.reuters.com/article/2014/11/17/us-china-supercomputer-idUSKCN0J11VV20141117" class="markup--anchor markup--p-anchor" rel="nofollow">Tianhe-2</a>, has actually beaten that number, clocking in at about 34 quadrillion cps.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB3;&#x2074;</a> But Tianhe-2 is also monstrous, &#x201C;taking up 720 square meters of space, using 24 megawatts of power (the brain runs on just <a href="http://www.popsci.com/technology/article/2009-11/neuron-computer-chips-could-overcome-power-limitations-digital" class="markup--anchor markup--p-anchor" rel="nofollow">20 watts</a>), and costing $390 million to build. Not especially applicable to wide usage, or even most commercial or industrial usage yet.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB3;&#x2075;</a></p><p name="4e35" id="4e35" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;Kurzweil suggests that we think about the state of computers by looking at how many cps you can buy for $1,000. When that number reaches human-level&#x200A;&#x2014;&#x200A;10 quadrillion cps&#x200A;&#x2014;&#x200A;then that&#x2019;ll mean AGI could become a very real part of life.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB3;&#x2076;</a></p><p name="ccb4" id="ccb4" class="graf--p graf-after--p">Currently we&#x2019;re only at about 10&#xB9;&#x2070; (10 trillion) cps per $1,000. However, historically reliable <a href="http://www.mooreslaw.org/" class="markup--anchor markup--p-anchor" rel="nofollow">Moore&#x2019;s Law</a> states &#x201C;that the world&#x2019;s maximum computing power doubles approximately every two years, meaning computer hardware advancement, like general human advancement through history, grows exponentially<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB3;&#x2077;</a>&#xA0;&#x2026; right on pace with this graph&#x2019;s predicted trajectory:&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB3;&#x2078;</a></p><figure name="ef38" id="ef38" class="graf--figure graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/800/1*4qcqwbsWjvWh-BWPnAsp6g.gif"></div><figcaption class="imageCaption">Visualization based on Ray Kurzweil&#x2019;s <a href="https://upload.wikimedia.org/wikipedia/commons/d/df/PPTExponentialGrowthof_Computing.jpg" class="markup--anchor markup--figure-anchor" rel="nofollow">graph</a> and analysis from his book <a href="https://en.wikipedia.org/wiki/The_Singularity_Is_Near" class="markup--anchor markup--figure-anchor" rel="nofollow">The Singularity is Near</a></figcaption></figure><p name="773d" id="773d" class="graf--p graf-after--figure">This dynamic &#x201C;puts us right on pace to get to an affordable computer by 2025 that rivals the power of the brain&#xA0;&#x2026; But raw computational power alone doesn&#x2019;t make a computer generally intelligent&#x200A;&#x2014;&#x200A;the next question is, how do we bring human-level intelligence to all that power?&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB3;&#x2079;</a></p><p name="00fc" id="00fc" class="graf--p graf-after--h4">The hardest part of creating AGI is learning how to develop its software. &#x201C;The truth is, no one really knows how to make it smart&#x200A;&#x2014;&#x200A;we&#x2019;re still debating how to make a computer human-level intelligent and capable of knowing what a dog and a weird-written B and a mediocre movie is.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2074;&#x2070;</a> But there are a couple of strategies. These are the three most common:</p><ol class="postList"><li name="2a38" id="2a38" class="graf--li graf-after--p">Copy how the brain works.</li></ol><p name="af95" id="af95" class="graf--p graf-after--li">The most straight-forward idea is to plagiarize the brain, and build the computer&#x2019;s architecture with close resemblance to how a brain is structured. One example &#x201C;is the artificial neural network. It starts out as a network of transistor &#x2018;neurons,&#x2019; connected to each other with inputs and outputs, and it knows nothing&#x200A;&#x2014;&#x200A;like an infant brain. The way it &#x2018;learns&#x2019; is it tries to do a task, say handwriting recognition, and at first, its neural firings and subsequent guesses at deciphering each letter will be completely random. But when it&#x2019;s told it got something right, the transistor connections in the firing pathways that happened to create that answer are strengthened; when it&#x2019;s told it was wrong, those pathways&#x2019; connections are weakened. After a lot of this trial and feedback, the network has, by itself, formed smart neural pathways and the machine has become optimized for the task.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2074;&#xB9;</a></p><p name="57c1" id="57c1" class="graf--p graf-after--p">The second, more radical approach to plagiarism is <em class="markup--em markup--p-em">whole brain emulation.</em> Scientists take a real brain, cut it into a large number of tiny slices to look at the neural connections and replicate them in a computer as software. If that method is ever successful, we will have &#x201C;a computer officially capable of everything the brain is capable of&#x200A;&#x2014;&#x200A;it would just need to learn and gather information&#xA0;&#x2026; How far are we from achieving whole brain emulation? Well so far, we&#x2019;ve <a href="http://www.smithsonianmag.com/smart-news/weve-put-worms-mind-lego-robot-body-180953399/?no-ist" class="markup--anchor markup--p-anchor" rel="nofollow">just recently</a> been able to emulate a 1mm-long flatworm brain, which consists of just 302 total neurons.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2074;&#xB2;</a> To put this into perspective, the human brain consists of <a href="http://www.ncbi.nlm.nih.gov/pubmed/19226510" class="markup--anchor markup--p-anchor" rel="nofollow">86 billion neurons</a> linked by trillions of synapses.</p><p name="c583" id="c583" class="graf--p graf-after--p">2. Introduce evolution to computers.</p><p name="7e40" id="7e40" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;The fact is, even if we can emulate a brain, that might be like trying to build an airplane by copying a bird&#x2019;s wing-flapping motions&#x200A;&#x2014;&#x200A;often, machines are best designed using a fresh, machine-oriented approach, not by mimicking biology exactly.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2074;&#xB3;</a> If the brain is just too complex for us to digitally replicate, we could try to emulate evolution instead. This uses a process called <em class="markup--em markup--p-em">genetic algorithms</em>. &#x201C;A group of computers would try to do tasks, and the most successful ones would be <em class="markup--em markup--p-em">bred </em>with each other by having half of each of their programming merged together into a new computer. The less successful ones would be eliminated.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2074;&#x2074;</a> Speed and a goal-oriented approach are the advantages that artificial evolution has over biological evolution. &#x201C;Over many, many iterations, this natural selection process would produce better and better computers. The challenge would be creating an automated evaluation and breeding cycle so this evolution process could run on its own.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2074;&#x2075;</a></p><p name="a888" id="a888" class="graf--p graf-after--p">3. &#x201C;Make this whole thing the computer&#x2019;s problem, not ours.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2074;&#x2076;</a></p><p name="f417" id="f417" class="graf--p graf-after--p">The last concept is the simplest, but probably the scariest of them all. &#x201C;We&#x2019;d build a computer whose two major skills would be doing research on AI and coding changes into itself&#x200A;&#x2014;&#x200A;allowing it to not only learn but to improve its own architecture. We&#x2019;d teach computers to be computer scientists so they could bootstrap their own development.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2074;&#x2077;</a> This is the likeliest way to get AGI soon that we know of.</p><p name="9fca" id="9fca" class="graf--p graf-after--p">All these software advances may seem slow or a little bit intangible, but as it is with the sciences, one minor innovation can suddenly accelerate the pace of developments. Kind of like the aftermath of the Copernican revolution&#x200A;&#x2014;&#x200A;the discovery that suddenly made all the complicated mathematics of the planets&#x2019; trajectories much easier to calculate, which enabled a multitude of other innovations. Also, the &#x201C;exponential growth is intense and what seems like a snail&#x2019;s pace of advancement can quickly race upwards.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2074;&#x2078;</a></p></div><div class="section-inner layoutSingleColumn" score="4.5"><p name="c0fa" id="c0fa" class="graf--p graf-after--h4">It&#x2019;s very real that at some point we will achieve AGI: software that has achieved human-level, or beyond human-level, intelligence. Does this mean that at that very moment the computers will be equally capable as us? Actually, not at all&#x200A;&#x2014;&#x200A;computers will be way more efficient. Because of the fact that they are electronic, they will have following advantages:</p><ul class="postList"><li name="35bc" id="35bc" class="graf--li graf-after--p">Speed. &#x201C;The brain&#x2019;s neurons max out at around 200 Hz, while today&#x2019;s microprocessors&#xA0;&#x2026; run at 2 GHz, or 10 million times faster.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--li-anchor">&#x2075;&#xB9;</a></li><li name="b143" id="b143" class="graf--li graf-after--li">Memory. Forgetting or confusing things is much harder in an artificial world. Computers can memorize more things in one second than a human can in ten years. A computer&#x2019;s memory is also more precise and has a much greater storage capacity.</li><li name="41ad" id="41ad" class="graf--li graf-after--li">Performance. &#x201C;Computer transistors are more accurate than biological neurons, and they&#x2019;re less likely to deteriorate (and can be repaired or replaced if they do). Human brains also get fatigued easily, while computers can run nonstop, at peak performance, 24/7.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--li-anchor">&#x2075;&#xB2;</a></li><li name="fade" id="fade" class="graf--li graf-after--li">Collective capability. Group work is ridiculously challenging because of time-consuming communication and complex social hierarchies. The bigger the group gets, the slower the output of each person becomes. AI, on the other hand, isn&#x2019;t biologically constrained to one body, won&#x2019;t have human cooperation problems, and is able to synchronize and update its own operating system.</li></ul><p name="9a60" id="9a60" class="graf--p graf-after--h4">We need to realize that AI &#x201C;wouldn&#x2019;t see &#x2018;human-level intelligence&#x2019; as some important milestone&#x200A;&#x2014;&#x200A;it&#x2019;s only a relevant marker from our point of view&#x200A;&#x2014;&#x200A;and wouldn&#x2019;t have any reason to &#x2018;stop&#x2019; at our level. And given the advantages over us that even human intelligence-equivalent AGI would have, it&#x2019;s pretty obvious that it would only hit human intelligence for a brief instant before racing onwards to the realm of superior-to-human intelligence.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2075;&#xB3;</a></p><p name="7f2f" id="7f2f" class="graf--p graf-after--p">The true distinction between humans and ASI wouldn&#x2019;t be its advantage in intelligence speed, but &#x201C;in intelligence quality&#x200A;&#x2014;&#x200A;which is something completely different. What makes humans so much more intellectually capable than chimps isn&#x2019;t a difference in thinking speed&#x200A;&#x2014;&#x200A;it&#x2019;s that human brains contain a number of sophisticated cognitive modules that enable things like complex linguistic representations or longterm planning or abstract reasoning, that chimps&#x2019; brains do not have. Speeding up a chimp&#x2019;s brain by thousands of times wouldn&#x2019;t bring him to our level&#x200A;&#x2014;&#x200A;even with a decade&#x2019;s time of learning, he wouldn&#x2019;t be able to figure out how to&#xA0;&#x2026; &#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2075;&#x2074;</a> assemble a semi-complicated Lego model by looking at its manual&#x200A;&#x2014;&#x200A;something a young human could achieve in a few minutes. &#x201C;There are worlds of human cognitive function a chimp will simply never be capable of, no matter how much time he spends trying.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2075;&#x2075;</a></p><p name="f90e" id="f90e" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;And in the scheme of the biological intelligence range&#xA0;&#x2026; the chimp-to-human quality intelligence gap is tiny.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2075;&#x2076;</a></p><figure name="3997" id="3997" class="graf--figure graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/800/1*vnVWATTAMCwfnJu_iZn2RQ.jpeg"></div></figure><p name="ee5f" id="ee5f" class="graf--p graf-after--figure">In order to render how big a deal it would be to exist with something that has a higher quality of intelligence than us, we need to imagine AI on the intelligence staircase two steps above us&#x200A;&#x2014;&#x200A;&#x201C;its increased cognitive ability over us would be as vast as the chimp&#x2013;human gap&#xA0;&#x2026; And like the chimp&#x2019;s incapacity to ever absorb&#xA0;&#x2026;&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2075;&#x2077;</a> what kind of magic happens in the mechanism of a doorknob&#x200A;&#x2014;&#x200A;&#x201C;we will never be able to even comprehend the things&#xA0;&#x2026; [a machine of that intelligence] can do, even if the machine tried to explain them to us&#xA0;&#x2026; And that&#x2019;s only two steps above us.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2075;&#x2078;</a></p><p name="d86a" id="d86a" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;A machine on the second-to-highest step on that staircase would be to us as we are to ants.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2075;&#x2079;</a> &#x201C;Superintelligence of that magnitude is not something we can remotely grasp, any more than a bumblebee can wrap its head around Keynesian Economics. In our world, smart means a 130 IQ and stupid means an 85 IQ&#x200A;&#x2014;&#x200A;we don&#x2019;t have a word for an IQ of 12,952.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2076;&#x2070;</a></p><p name="f0d0" id="f0d0" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;But the kind of superintelligence we&#x2019;re talking about today is something far beyond anything on this staircase. In an intelligence explosion&#x200A;&#x2014;&#x200A;where the smarter a machine gets, the quicker it&#x2019;s able to increase its own intelligence&#x200A;&#x2014;&#x200A;a machine might take years to rise from&#xA0;&#x2026; &#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2076;&#xB9;</a> the intelligence of an ant to the intelligence of the average human, but it might take only another 40 days to become Einstein-smart. When that happens, &#x201C;it works to improve its intelligence, with an Einstein-level intellect, it has an easier time and can make bigger leaps. These leaps will make it much smarter than any human, allowing it to make even bigger leaps.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2076;&#xB2;</a></p><p name="2ca6" id="2ca6" class="graf--p graf-after--p">From then on, following the rule of exponential advancements and utilizing the speed and efficiency of electrical circuits, it may perhaps take only 20 minutes to jump another step, &#x201C;and by the time it&#x2019;s ten steps above us, it might be jumping up in four-step leaps every second that goes by. Which is why we need to realize that it&#x2019;s distinctly possible that very shortly after the big news story about the first machine reaching human-level AGI, we might be facing the reality of coexisting on the Earth with something that&#x2019;s here on the staircase (or maybe a million times higher):&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2076;&#xB3;</a></p><figure name="433d" id="433d" class="graf--figure graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/800/0*LdJxmWCjSdweUKvb."></div></figure><p name="e79f" id="e79f" class="graf--p graf--startsWithDoubleQuote graf-after--figure">&#x201C;And since we just established that it&#x2019;s a hopeless activity to try to understand the power of a machine only two steps above us, let&#x2019;s very concretely state once and for all that there is no way to know what ASI will do or what the consequences will be for us. Anyone who pretends otherwise doesn&#x2019;t understand what superintelligence means.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2076;&#x2074;</a></p><p name="dcee" id="dcee" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;If our meager brains were able to invent wifi, then something 100 or 1,000 or 1 billion times smarter than we are should have no problem controlling the positioning of each and every atom in the world in any way it likes, at any time&#x200A;&#x2014;&#x200A;everything we consider magic, every power we imagine a supreme God to have will be as mundane an activity for the ASI as flipping on a light switch is for us.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2076;&#x2075;</a></p><p name="ae1c" id="ae1c" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;As far as we&#x2019;re concerned, if an ASI comes into being, there is now an omnipotent God on Earth&#x200A;&#x2014;&#x200A;and the all-important question for us is: Will it be a good god?&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2076;&#x2076;</a></p><p name="7015" id="7015" class="graf--p graf-after--p">Let&#x2019;s start from the brighter side of the story.</p><p name="20ad" id="20ad" class="graf--p graf-after--h4">Nanotechnology is an idea that comes up &#x201C;in almost everything you read about the future of AI.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2076;&#x2077;</a> It&#x2019;s the technology that works at the nano scale&#x200A;&#x2014;&#x200A;from 1 to 100 nanometers. &#x201C;A nanometer is a millionth of a millimeter. 1 nm&#x2013;100 nm range encompasses viruses (100 nm accross), DNA (10 nm wide), and things as small as molecules like hemoglobin (5 nm) and medium molecules like glucose (1 nm). If/when we conquer nanotechnology, the next step will be the ability to manipulate individual atoms, which are only one order of magnitude smaller (~.1 nm).&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2076;&#x2078;</a></p><p name="ecc2" id="ecc2" class="graf--p graf-after--p">To put this into perspective, imagine a very tall human standing on the earth, with a head that reaches the International Space Station (431 km/268 mi high). The giant is reaching down with his hand (30 km/19 mi across) to build &#x201C;objects using materials between the size of a grain of sand [.25 mm] and an eyeball [2.5 cm].&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2076;&#x2079;</a></p></div><div class="section-inner sectionLayout--outsetColumn" score="1.25"><figure name="5074" id="5074" class="graf--figure graf--layoutOutsetCenter graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/1200/1*e9Ut3QT2F3tNh4h5U4rR8A.jpeg"></div></figure></div><div class="section-inner layoutSingleColumn"><p name="8efb" id="8efb" class="graf--p graf--startsWithDoubleQuote graf-after--figure">&#x201C;Once we get nanotechnology down, we can use it to make tech devices, clothing, food, a variety of bio-related products&#x200A;&#x2014;&#x200A;artificial blood cells, tiny virus or cancer-cell destroyers, muscle tissue, etc.&#x200A;&#x2014;&#x200A;anything really. And in a world that uses nanotechnology, the cost of a material is no longer tied to its scarcity or the difficulty of its manufacturing process, but instead determined by how complicated its atomic structure is. In a nanotech world, a diamond might be cheaper than a pencil eraser.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2077;&#x2070;</a></p><p name="61bc" id="61bc" class="graf--p graf-after--p">One of the proposed methods of nanotech assembly is to make &#x201C;one that could self-replicate, and then let the reproduction process turn that one into two, those two then turn into four, four into eight, and in about a day, there&#x2019;d be a few trillion of them ready to go.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2077;&#xB9;</a></p><p name="5b30" id="5b30" class="graf--p graf-after--p">But what if this process goes wrong or terrorists manage to get ahold of the technology? Let&#x2019;s imagine a scenario where nanobots &#x201C;would be designed to consume any carbon-based material in order to feed the replication process, and unpleasantly, all life is carbon-based. The Earth&#x2019;s biomass contains about 1&#x2070;&#x2074;&#x2075; carbon atoms. A nanobot would consist of about 1&#x2070;&#x2076; carbon atoms, so it would take 1&#x2070;&#xB3;&#x2079; nanobots to consume all life on Earth, which would happen in 130 replications.&#xA0;&#x2026; Scientists think a nanobot could replicate in about 100 seconds, meaning this simple mistake would inconveniently end all life on Earth in 3.5 hours.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2077;&#xB2;</a></p><p name="df5e" id="df5e" class="graf--p graf-after--p">We are not yet capable of harnessing nanotechnology&#x200A;&#x2014;&#x200A;for good or for bad. &#x201C;And it&#x2019;s not clear if we&#x2019;re underestimating, or overestimating, how hard it will be to get there. But we don&#x2019;t seem to be that far away. Kurzweil predicts that we&#x2019;ll get there by the 2020s.<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2077;&#xB3;</a>Governments know that nanotech could be an Earth-shaking development&#xA0;&#x2026; The US, the EU, and Japan<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2077;&#x2074;</a> have invested over a combined $5 billion so far&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2077;&#x2075;</a></p><p name="eaf1" id="eaf1" class="graf--p graf--startsWithDoubleQuote graf-after--h4">&#x201C;Because everyone has always died, we live under the assumption&#xA0;&#x2026; that death is inevitable. We think of aging like time&#x200A;&#x2014;&#x200A;both keep moving and there&#x2019;s nothing you can do to stop it.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2077;&#x2076;</a> For centuries, poets and philosophers have wondered if consciousness doesn&#x2019;t have to go the way of the body. W.B. Yeats describes us as &#x201C;a soul fastened to a dying animal.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2077;&#x2077;</a> Richard Feynman, Nobel awarded physicists, views death from a purely scientific standpoint:</p><blockquote name="a1f6" id="a1f6" class="graf--pullquote pullquote graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--pullquote-em">&#x201C;It is one of the most remarkable things that in all of the biological sciences there is no clue as to the necessity of death. If you say we want to make perpetual motion, we have discovered enough laws as we studied physics to see that it is either absolutely impossible or else the laws are wrong. But there is nothing in biology yet found that indicates the inevitability of death. This suggests to me that it is not at all inevitable, and that it is only a matter of time before the biologists discover what it is that is causing us the trouble and that that terrible universal disease or temporariness of the human&#x2019;s body will be cured.&#x201D;</em><a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--pullquote-anchor"><em class="markup--em markup--pullquote-em">&#x2077;&#x2078;</em></a></blockquote><p name="59b6" id="59b6" class="graf--p graf-after--h4">When we look at the history of biological life on earth, so far 99.9% of species have gone extinct. Nick Bostrom, Oxford professor and AI specialist, &#x201C;calls extinction an attractor state&#x200A;&#x2014;&#x200A;a place species are&#xA0;&#x2026; falling into and from which no species ever returns.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2077;&#x2079;</a></p></div><div class="section-inner sectionLayout--outsetColumn" score="1.25"><figure name="b418" id="b418" class="graf--figure graf--layoutOutsetCenter graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/1200/0*o-MXeAYfUtWnOJKC."></div></figure></div><div class="section-inner layoutSingleColumn"><p name="c31f" id="c31f" class="graf--p graf--startsWithDoubleQuote graf-after--figure">&#x201C;And while most AI scientists&#xA0;&#x2026; acknowledge that ASI would have the ability to send humans to extinction, many also believe that if used beneficially, ASI&#x2019;s abilities could be used to bring individual humans, and the species as a whole, to a <em class="markup--em markup--p-em">second</em> attractor state&#x200A;&#x2014;&#x200A;species immortality.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2078;&#x2070;</a></p></div><div class="section-inner sectionLayout--outsetColumn" score="1.25"><figure name="0299" id="0299" class="graf--figure graf--layoutOutsetCenter graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/1200/0*aYeNOSBxp4gieGwp."></div></figure></div><div class="section-inner layoutSingleColumn"><p name="abfd" id="abfd" class="graf--p graf--startsWithDoubleQuote graf-after--figure">&#x201C;Evolution had no good reason to extend our lifespans any longer than they are now&#xA0;&#x2026; From an evolutionary point of view, the whole human species can thrive with a 30+ year lifespan&#x201D; for each single human. It&#x2019;s long enough to reproduce and raise children&#xA0;&#x2026; so there&#x2019;s no reason for mutations toward unusually long life being favored in the natural selection process.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2078;&#xB9;</a>Though, &#x201C;if you perfectly repaired or replaced a car&#x2019;s parts whenever one of them began to wear down, the car would run forever. The human body isn&#x2019;t any different&#x200A;&#x2014;&#x200A;just far more complex&#xA0;&#x2026; This seems absurd&#x200A;&#x2014;&#x200A;but the body is just a bunch of atoms&#x2026;&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2078;&#xB2;</a> making up organically programmed DNA, which it is theoretically possible to manipulate. And something as powerful as ASI could help us master genetic engineering.</p><p name="8150" id="8150" class="graf--p graf-after--p">Ray Kurzweil believes that &#x201C;artificial materials will be integrated into the body more and more&#xA0;&#x2026; Organs could be replaced by super-advanced machine versions that would run forever and never fail.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2078;&#xB3;</a> Red blood cells could be perfected by &#x201C;red blood cell nanobots, who could power their own movement, eliminating the need for a heart at all&#xA0;&#x2026; Nanotech theorist Robert A. Freitas has already designed blood cell replacements that, if one day implemented in the body, would allow a human to sprint for 15 minutes without taking a breath&#xA0;&#x2026; [Kurzweil] even gets to the brain and believes we&#x2019;ll <a href="https://www.youtube.com/watch?v=PVXQUItNEDQ" class="markup--anchor markup--p-anchor" rel="nofollow">enhance our mental activities</a> to the point where humans will be able to think billions of times faster&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2078;&#x2074;</a> by integrating electrical components and being able to access online data.</p><p name="0f3f" id="0f3f" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;Eventually, Kurzweil believes humans will reach a point when they&#x2019;re entirely artificial, a time when we&#x2019;ll look back at biological material and think how <em class="markup--em markup--p-em">unbelievably </em>primitive primitive it was that humans were ever made of that&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2078;&#x2075;</a>and that humans aged, suffered from cancer, allowed random factors like microbes, diseases, accidents to harm us or make us disappear.&#x201D;</p></div><div class="section-inner sectionLayout--fullWidth" score="1.25"><figure name="499e" id="499e" class="graf--figure graf--layoutFillWidth graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/2000/1*NcWWmd677RVWQRpLsz5X9g.jpeg"></div></figure></div><div class="section-inner layoutSingleColumn" score="1.25"><p name="6a31" id="6a31" class="graf--p graf--startsWithDoubleQuote graf-after--h4">&#x201C;How long until the first machine reaches superintelligence? Not shockingly, opinions vary wildly, and this is a heated debate among scientists and thinkers. Many, like professor <a href="https://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html" class="markup--anchor markup--p-anchor" rel="nofollow">Vernor Vinge</a>, scientist <a href="http://goertzel.org/TenYearsToTheSingularity.pdf" class="markup--anchor markup--p-anchor" rel="nofollow">Ben Goertzel</a>, Sun Microsystems co-founder <a href="http://archive.wired.com/wired/archive/8.04/joy.html" class="markup--anchor markup--p-anchor" rel="nofollow">Bill Joy</a>, or, most famously, inventor and futurist <a href="http://en.wikipedia.org/wiki/Predictions_made_by_Ray_Kurzweil" class="markup--anchor markup--p-anchor" rel="nofollow">Ray Kurzweil</a>, agree with machine learning expert Jeremy Howard when he puts up this graph during a <a href="http://www.ted.com/talks/jeremy_howard_the_wonderful_and_terrifying_implications_of_computers_that_can_learn?language=en" class="markup--anchor markup--p-anchor" rel="nofollow">TED Talk</a>:</p><figure name="8fec" id="8fec" class="graf--figure graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/800/0*FR6t5GAJ9iXkI0BI."></div><figcaption class="imageCaption">Graph by Jeremy Howard from his TED talk &#x201C;<a href="https://www.ted.com/talks/jeremy_howard_the_wonderful_and_terrifying_implications_of_computers_that_can_learn?language=en" class="markup--anchor markup--figure-anchor" rel="nofollow">The wonderful and terrifying implications of computers that can learn</a>.&#x201D;</figcaption></figure><p name="4d5c" id="4d5c" class="graf--p graf--startsWithDoubleQuote graf-after--figure">&#x201C;Those people subscribe to the belief that this is happening <em class="markup--em markup--p-em">soon&#x200A;&#x2014;&#x200A;</em>that exponential growth is at work and machine learning, though only slowly creeping up on us now, will blow right past us within the next few decades.</p><p name="ba42" id="ba42" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;Others, like Microsoft co-founder <a href="http://www.technologyreview.com/view/425733/paul-allen-the-singularity-isnt-near/" class="markup--anchor markup--p-anchor" rel="nofollow">Paul Allen</a>, research psychologist <a href="http://www.newyorker.com/tech/elements/hyping-artificial-intelligence-yet-again" class="markup--anchor markup--p-anchor" rel="nofollow">Gary Marcus</a>, NYU computer scientist <a href="http://www.aaai.org/ojs/index.php/aimagazine/article/view/568" class="markup--anchor markup--p-anchor" rel="nofollow">Ernest Davis</a>, and tech entrepreneur <a href="http://longbets.org/1/" class="markup--anchor markup--p-anchor" rel="nofollow">Mitch Kapor</a>, believe that thinkers like Kurzweil are <a href="http://www.technologyreview.com/view/425733/paul-allen-the-singularity-isnt-near/" class="markup--anchor markup--p-anchor" rel="nofollow">vastly underestimating</a> the magnitude of the challenge [and the transition will actually take much more time]&#xA0;&#x2026;</p><p name="6193" id="6193" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;The Kurzweil camp would <a href="http://www.technologyreview.com/view/425818/kurzweil-responds-dont-underestimate-the-singularity/" class="markup--anchor markup--p-anchor" rel="nofollow">counter</a> that the only underestimating that&#x2019;s happening is the underappreciation of exponential growth, and they&#x2019;d compare the doubters to those who looked at the slow-growing seedling of the internet in 1985 and argued that there was no way it would amount to anything impactful in the near future.</p><p name="78d0" id="78d0" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;The doubters might argue back that the progress needed to make advancements in intelligence also grows exponentially harder with each subsequent step, which will cancel out the typical exponential nature of technological progress. And so on.</p><p name="9761" id="9761" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;A third camp, which includes <a href="http://www.amazon.com/gp/product/0199678111/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0199678111&amp;linkCode=as2&amp;tag=wabuwh00-20&amp;linkId=LBOTX2G2R72P5EUA" class="markup--anchor markup--p-anchor" rel="nofollow">Nick Bostrom</a>, believes neither group has any ground to feel certain about the timeline and acknowledges both A) that this could absolutely happen in the near future and B) that there&#x2019;s no guarantee about that; it could also take a much longer time.</p><p name="ea30" id="ea30" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;Still others, like philosopher <a href="http://www.amazon.com/gp/product/0262540673/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0262540673&amp;linkCode=as2&amp;tag=wabuwh00-20&amp;linkId=ZHBAVUQOM6SIGYHG" class="markup--anchor markup--p-anchor" rel="nofollow">Hubert Dreyfus</a>, believe all three of these groups are naive for believing that there is potential of ASI, arguing that it&#x2019;s more likely that it won&#x2019;t actually ever be achieved.</p><p name="5291" id="5291" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;So what do you get when you put all of these opinions together?&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2078;&#x2076;</a></p><p name="4ce9" id="4ce9" class="graf--p graf--startsWithDoubleQuote graf-after--h4">&#x201C;In 2013, Vincent C. M&#xFC;ller and Nick Bostrom conducted a survey that asked hundreds of AI experts&#xA0;&#x2026; the following:&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2078;&#x2077;</a></p><p name="73ed" id="73ed" class="graf--p graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--p-em">&#x201C;For the purposes of this question, assume that human scientific activity continues without major negative disruption. By what year would you see a (10% / 50% / 90%) probability for such Human-Level Machine Intelligence [or what we call AGI] to exist?&#x201D;</em><a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2078;&#x2078;</a></p><p name="7a2a" id="7a2a" class="graf--p graf-after--p">The survey &#x201C;asked them to name an optimistic year (one in which they believe there&#x2019;s a 10% chance we&#x2019;ll have AGI), a realistic guess (a year they believe there&#x2019;s a 50% chance of AGI&#x200A;&#x2014;&#x200A;i.e. after that year they think it&#x2019;s more likely than not that we&#x2019;ll have AGI), and a safe guess (the earliest year by which they can say with 90% certainty we&#x2019;ll have AGI). Gathered together as one data set, here were the results:</p><blockquote name="1553" id="1553" class="graf--pullquote pullquote graf--hasDropCapModel graf-after--p"><strong class="markup--strong markup--pullquote-strong"><em class="markup--em markup--pullquote-em">Median optimistic year (10% likelihood) &#x2192; 2022<br>Median realistic year (50% likelihood) &#x2192; 2040<br>Median pessimistic year (90% likelihood) &#x2192; 2075</em></strong></blockquote><p name="2854" id="2854" class="graf--p graf--startsWithDoubleQuote graf-after--pullquote graf--last">&#x201C;So the median participant thinks it&#x2019;s more likely than not that we&#x2019;ll have AGI 25 years from now. The 90% median answer of 2075 means that if you&#x2019;re a teenager right now, the median respondent, along with over half of the group of AI experts, is almost certain AGI will happen within your lifetime.</p></div></div></section><section name="da8f" class=" section--body section--last" score="41.25"><div class="section-content" score="52.5"><div class="section-inner layoutSingleColumn"><p name="2a89" id="2a89" class="graf--p graf--startsWithDoubleQuote graf--leading">&#x201C;A separate study, conducted recently by author James Barrat at Ben Goertzel&#x2019;s annual AGI Conference, did away with percentages and simply asked when participants thought AGI would be achieved&#x200A;&#x2014;&#x200A;by 2030, by 2050, by 2100, after 2100, or never. The results:<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2078;&#x2079;</a></p><blockquote name="4529" id="4529" class="graf--pullquote pullquote graf-after--p"><strong class="markup--strong markup--pullquote-strong"><em class="markup--em markup--pullquote-em">42% of respondents &#x2192; By 2030<br>25% of respondents &#x2192; By 2050<br>20% of respondents &#x2192; By 2100<br>10% of respondents &#x2192; After 2100<br>2% of respondents &#x2192; Never</em></strong></blockquote><p name="43da" id="43da" class="graf--p graf--startsWithDoubleQuote graf-after--pullquote">&#x201C;Pretty similar to M&#xFC;ller and Bostrom&#x2019;s outcomes. In Barrat&#x2019;s survey, over two thirds of participants believe AGI will be here by 2050 and a little less than half predict AGI within the next 15 years. Also striking is that only 2% of those surveyed don&#x2019;t think AGI is part of our future.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2079;&#x2070;</a></p></div><div class="section-inner sectionLayout--fullWidth" score="1.25"><figure name="ad77" id="ad77" class="graf--figure graf--layoutFillWidth graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/2000/1*U8ueEMtG6-D5hie8rZJGtQ.jpeg"></div></figure></div><div class="section-inner layoutSingleColumn"><p name="3ed4" id="3ed4" class="graf--p graf--startsWithDoubleQuote graf-after--h4">&#x201C;M&#xFC;ller and Bostrom also asked the experts how likely they think it is that we&#x2019;ll reach ASI: A), within two years of reaching AGI (i.e. an almost-immediate intelligence explosion), and B), within 30 years.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2079;&#xB9;</a> Respondents were asked to choose a probability for each option. Here are the results:<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2079;&#xB2;</a></p><blockquote name="c929" id="c929" class="graf--pullquote pullquote graf-after--p"><em class="markup--em markup--pullquote-em">AGI&#x2013;ASI transition in 2 years &#x2192; 10% likelihood<br>AGI&#x2013;ASI transition in 30 years &#x2192; 75% likelihood</em></blockquote><p name="d97c" id="d97c" class="graf--p graf--startsWithDoubleQuote graf-after--pullquote">&#x201C;The median answer put a rapid (2 year) AGI&#x2013;ASI transition at only a 10% likelihood, but a longer transition of 30 years or less at a 75% likelihood. We don&#x2019;t know from this data the length of this transition [AGI&#x2013;ASI] the median participant would have put at a 50% likelihood, but for ballpark purposes, based on the two answers above, let&#x2019;s estimate that they&#x2019;d have said 20 years.</p><p name="13bc" id="13bc" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;So the median opinion&#x200A;&#x2014;&#x200A;the one right in the center of the world of AI experts&#x200A;&#x2014;&#x200A;believes the most realistic guess for when we&#x2019;ll hit ASI&#xA0;&#x2026; is [the 2040 prediction for AGI + our estimated prediction of a 20-year transition from AGI to ASI] = 2060.</p></div><div class="section-inner sectionLayout--fullWidth" score="1.25"><figure name="59c4" id="59c4" class="graf--figure graf--layoutFillWidth graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/2000/1*YY8e493ER4LNomQV-NyMYg.jpeg"></div></figure></div><div class="section-inner layoutSingleColumn"><p name="98aa" id="98aa" class="graf--p graf--startsWithDoubleQuote graf-after--figure">&#x201C;Of course, all of the above statistics are speculative, and they&#x2019;re only representative of the median opinion of the AI expert community, but it tells us that a large portion of the people who know the most about this topic would agree that 2060 is a very reasonable estimate for the arrival of potentially world-altering ASI. Only 45 years from now&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2079;&#xB3;</a></p></div><div class="section-inner sectionLayout--fullWidth" score="1.25"><figure name="d165" id="d165" class="graf--figure graf--layoutFillWidth graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/2000/1*sGdvHHs02XWoQ35BcEWAXQ.gif"></div></figure></div><div class="section-inner layoutSingleColumn" score="-2.5"><p name="19a7" id="19a7" class="graf--p graf-after--h4">Most of what we have discussed so far represents a surprisingly large group of scientists that share optimistic views on the outcome of AI development. &#x201C;Where their confidence comes from is up for debate. Critics believe it comes from an excitement so blinding that they simply ignore or deny potential negative outcomes. But the believers say it&#x2019;s naive to conjure up doomsday scenarios when on balance, technology has and will likely end up continuing to help us a lot more than it hurts us.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2079;&#x2074;</a> Peter Diamandis, Ben Goertezl and Ray Kurzweil are some of the major figures of this group, who have built a vast, dedicated following and regard themselves as <a href="https://en.wikipedia.org/wiki/Technological_singularity" class="markup--anchor markup--p-anchor" rel="nofollow">Singularitarians</a>.</p><figure name="74ea" id="74ea" class="graf--figure graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/800/0*5V7p80xwMPBLUwke."></div><figcaption class="imageCaption">CC photo by J.D. Lasica</figcaption></figure><p name="9e5c" id="9e5c" class="graf--p graf-after--figure">Let&#x2019;s talk about Ray Kurzweil, who is probably one of the most impressive and polarizing AI theoreticians out there. He attracts both &#x201C;godlike worship&#xA0;&#x2026; and eye-rolling contempt&#xA0;&#x2026; He came up with several breakthrough inventions, including the first flatbed scanner, the first scanner that converted text to speech (allowing the blind to read standard texts), the well-known Kurzweil music synthesizer (the first true electric piano), and the first commercially marketed large-vocabulary speech recognition. He&#x2019;s well-known for his bold predictions,&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2079;&#x2075;</a> including envisioning that intelligence technology like Deep Blue would be capable of beating a chess grandmaster by 1998. He also anticipated &#x201C;in the late &#x2019;80s, a time when the internet was an obscure thing, that by the early 2000s it would become a global phenomenon.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2079;&#x2076;</a> Out &#x201C;of the 147 predictions that Kurzweil has made since the 1990&#x2019;s, fully 115 of them have turned out to be correct, and another 12 have turned out to be &#x2018;essentially correct&#x2019; (off by a year or two), giving his predictions a stunning 86% accuracy rate&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2079;&#x2077;</a>. &#x201C;He&#x2019;s the author of five national bestselling books&#xA0;&#x2026; In 2012, Google co-founder Larry Page approached Kurzweil and asked him to be Google&#x2019;s Director of Engineering. In 2011, he co-founded <a href="http://singularityu.org/" class="markup--anchor markup--p-anchor" rel="nofollow">Singularity University</a>, which is hosted by NASA and sponsored partially by Google. Not bad for one life.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2079;&#x2078;</a></p><p name="f3b2" id="f3b2" class="graf--p graf-after--p">His biography is important, because if you don&#x2019;t have this context, he sounds like somebody who&#x2019;s completely lost his senses. &#x201C;Kurzweil believes computers will reach AGI by 2029 and that by 2045 we&#x2019;ll have not only ASI, but a full-blown new world&#x200A;&#x2014;&#x200A;a time he calls the singularity. His AI-related timeline used to be seen as outrageously overzealous, and it still is by many, but in the last 15 years, the rapid advances of ANI systems have brought the larger world of AI experts much closer to Kurzweil&#x2019;s timeline. His predictions are still a bit more ambitious than the median respondent on <a href="https://medium.com/ai-revolution/when-will-the-first-machine-become-superintelligent-ae5a6f128503#.w4m8skb5y" class="markup--anchor markup--p-anchor">M&#xFC;ller and Bostrom&#x2019;s survey</a> (AGI by 2040, ASI by 2060), but not by that much.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#x2079;&#x2079;</a></p><figure name="fd93" id="fd93" class="graf--figure graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/800/0*WUfjcOTgzSlb9bOY."></div><figcaption class="imageCaption">CC photo by Future of Humanity Institute</figcaption></figure><p name="1629" id="1629" class="graf--p graf--startsWithDoubleQuote graf-after--h4">&#x201C;You will not be surprised to learn that Kurzweil&#x2019;s ideas have attracted significant criticism&#xA0;&#x2026; For every expert who fervently believes Kurzweil is right on, there are probably three who think he&#x2019;s way off&#xA0;&#x2026; [The surprising fact] is that most of the experts who disagree with him don&#x2019;t really disagree that everything he&#x2019;s saying is possible.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#x2070;&#x2070;</a> Nick Bostrom, philosopher and Director of the Oxford Future of Humanity Institute, who criticizes Kurzweil for a variety of reasons, and calls for greater caution in thinking about potential outcomes of AI, acknowledges that:</p><blockquote name="5add" id="5add" class="graf--pullquote pullquote graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--pullquote-em">&#x201C;Disease, poverty, environmental destruction, unnecessary suffering of all kinds: these are things that a superintelligence equipped with advanced nanotechnology would be capable of eliminating. Additionally, a superintelligence could give us indefinite lifespan, either by stopping and reversing the aging process through the use of nanomedicine, or by offering us the option to upload ourselves.&#x201D;</em><a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--pullquote-anchor"><em class="markup--em markup--pullquote-em">&#xB9;&#x2070;&#xB9;</em></a></blockquote><p name="79e0" id="79e0" class="graf--p graf--startsWithDoubleQuote graf-after--pullquote">&#x201C;Yes, all of that can happen if we safely transition to ASI&#x200A;&#x2014;&#x200A;but that&#x2019;s the hard part.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#x2070;&#xB2;</a> Thinkers from the Anxious Corner point out that Kurzweil&#x2019;s &#x201C;famous book <a href="http://www.amazon.com/gp/product/0143037889/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0143037889&amp;linkCode=as2&amp;tag=wabuwh00-20&amp;linkId=54Q62R5PYJBEENTP" class="markup--anchor markup--p-anchor" rel="nofollow">The Singularity is Near</a> is over 700 pages long and he dedicates around 20 of those pages to potential dangers.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#x2070;&#xB3;</a> The colossal power of AI is neatly summarized by Kurzweil: &#x201C;[ASI] is emerging from many diverse efforts and will be deeply integrated into our civilization&#x2019;s infrastructure. Indeed, it will be intimately embedded in our bodies and brains. As such, it will reflect our values because it will be us&#xA0;&#x2026;&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#x2070;&#x2074;</a></p><p name="f4c5" id="f4c5" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;But if that&#x2019;s the answer, why are so many of the world&#x2019;s smartest people so worried right now? Why does Stephen Hawking <a href="http://www.washingtonpost.com/news/speaking-of-science/wp/2014/12/02/stephen-hawking-just-got-an-artificial-intelligence-upgrade-but-still-thinks-it-could-bring-an-end-to-mankind/" class="markup--anchor markup--p-anchor" rel="nofollow">say</a> the development of ASI &#x2018;could spell the end of the human race,&#x2019; and Bill Gates <a href="http://www.washingtonpost.com/blogs/the-switch/wp/2015/01/28/bill-gates-on-dangers-of-artificial-intelligence-dont-understand-why-some-people-are-not-concerned/" class="markup--anchor markup--p-anchor" rel="nofollow">says</a> he doesn&#x2019;t &#x2018;understand why some people are not concerned&#x2019; and Elon Musk <a href="http://www.theguardian.com/technology/2014/oct/27/elon-musk-artificial-intelligence-ai-biggest-existential-threat" class="markup--anchor markup--p-anchor" rel="nofollow">fears</a> that we&#x2019;re &#x2018;summoning the demon?&#x2019; And why do so many experts on the topic call ASI the biggest threat to humanity?&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#x2070;&#x2075;</a></p></div><div class="section-inner sectionLayout--fullWidth" score="1.25"><figure name="b2f8" id="b2f8" class="graf--figure graf--layoutFillWidth graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/2000/1*1DB3Im9mQsOMOKQ69KePGw.gif"></div></figure></div><div class="section-inner layoutSingleColumn" score="1.25"><p name="a051" id="a051" class="graf--p graf--startsWithDoubleQuote graf-after--h4">&#x201C;When it comes to developing supersmart AI, we&#x2019;re creating something that will probably change everything, but in totally uncharted territory, and we have no idea what will happen when we get there.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#x2070;&#x2076;</a> Scientist Danny Hillis compares the situation to:</p><blockquote name="bff4" id="bff4" class="graf--pullquote pullquote graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--pullquote-em">&#x201C;when single-celled organisms were turning into multi-celled organisms. We are amoebas and we can&#x2019;t figure out what the hell this thing is that we&#x2019;re creating.&#x201D; </em><a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--pullquote-anchor"><em class="markup--em markup--pullquote-em">&#xB9;&#x2070;&#x2077;</em></a></blockquote><p name="87e4" id="87e4" class="graf--p graf-after--pullquote">and Nick Bostrom warns:</p><blockquote name="64f0" id="64f0" class="graf--pullquote pullquote graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--pullquote-em">&#x201C;Before the prospect of an intelligence explosion, we humans are like small children playing with a bomb. Such is the mismatch between the power of our plaything and the immaturity of our conduct.&#x201D; </em><a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--pullquote-anchor"><em class="markup--em markup--pullquote-em">&#xB9;&#x2070;&#x2078;</em></a></blockquote><p name="1c7c" id="1c7c" class="graf--p graf-after--pullquote">It&#x2019;s very likely that ASI&#x200A;&#x2014;&#x200A;&#x201C;Artificial Superintelligence&#x201D;, or AI that achieves a level of intelligence smarter than all of humanity combined&#x200A;&#x2014;&#x200A;will be something entirely different than intelligence entities we are accustomed to. &#x201C;On our little island of human psychology, we divide everything into moral or immoral. But both of those only exist within the small range of human behavioral possibility. Outside our island of moral and immoral is a vast sea of amoral, and anything that&#x2019;s not human, especially something nonbiological, would be amoral, by default.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#x2070;&#x2079;</a></p><p name="f34b" id="f34b" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;To understand ASI, we have to wrap our heads around the concept of something both smart and totally alien&#xA0;&#x2026; Anthropomorphizing AI (projecting human values on a non-human entity) will only become more tempting as AI systems get smarter and better at seeming human&#xA0;&#x2026; Humans feel high-level emotions like empathy because we have evolved to feel them&#x200A;&#x2014;&#x200A;i.e. we&#x2019;ve been programmed to feel them by evolution&#x200A;&#x2014;&#x200A;but empathy is not inherently a characteristic of &#x2018;anything with high intelligence&#x2019;.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB9;&#x2070;</a></p><p name="35be" id="35be" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;Nick Bostrom believes that&#xA0;&#x2026; any level of intelligence can be combined with any final goal&#xA0;&#x2026; Any assumption that once superintelligent, a system would be over it with their original goal and onto more interesting or meaningful things is anthropomorphizing. Humans get &#x2018;over&#x2019; things, not computers.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB9;&#xB9;</a>The motivation of an early ASI would be &#x201C;whatever we programmed its motivation to be. AI systems are given goals by their creators&#x200A;&#x2014;&#x200A;your GPS&#x2019;s goal is to give you the most efficient driving directions, <a href="https://en.wikipedia.org/wiki/Watson_%28computer%29" class="markup--anchor markup--p-anchor" rel="nofollow">Watson&#x2019;s goal</a> is to answer questions accurately. And fulfilling those goals as well as possible is their motivation.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB9;&#xB2;</a></p><p name="290b" id="290b" class="graf--p graf-after--p">Bostrom, and many others, predict that the very first computer to reach ASI will immediately notice the strategic benefit of being the world&#x2019;s only ASI system.</p><p name="38d9" id="38d9" class="graf--p graf-after--p">Bostrom, who says that he doesn&#x2019;t know when we will achieve AGI, also believes that when we finally do, probably the transition from AGI to ASI will happen in a matter of days, hours, or minutes&#x200A;&#x2014;&#x200A;something called &#x201C;fast take-off.&#x201D; In that case, if the first AGI will jump straight to ASI: &#x201C;even just a few days before the second place, it would be far enough ahead in intelligence to effectively and permanently suppress all competitors.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB9;&#xB3;</a> This would allow the world&#x2019;s first ASI to become &#x201C;what&#x2019;s called a singleton&#x200A;&#x2014;&#x200A;an ASI that can [singularly] rule the world at its whim forever, whether its whim is to lead us to immortality, wipe us from existence, or turn the universe into <a href="http://www.salon.com/2014/08/17/our_weird_robot_apocalypse_why_the_rise_of_the_machines_could_be_very_strange/" class="markup--anchor markup--p-anchor" rel="nofollow">endless paperclips</a>.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB9;&#xB3;</a></p><p name="f00f" id="f00f" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;The singleton phenomenon can work in our favor or lead to our destruction. If the people thinking hardest about AI theory and human safety can come up with a fail-safe way to bring about friendly ASI before any AI reaches human-level intelligence, the first ASI may turn out friendly&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB9;&#x2074;</a></p><p name="f95d" id="f95d" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;But if things go the other way&#x200A;&#x2014;&#x200A;if the global rush&#xA0;&#x2026; a large and varied group of parties&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB9;&#x2075;</a> are &#x201C;racing ahead at top speed&#xA0;&#x2026; to beat their competitors&#xA0;&#x2026; we&#x2019;ll be treated to an existential catastrophe.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB9;&#x2076;</a> In that case &#x201C;most ambitious parties are moving faster and faster, consumed with dreams of the money and awards and power and fame&#xA0;&#x2026; And when you&#x2019;re sprinting as fast as you can, there&#x2019;s not much time to stop ponder the dangers. On the contrary, what they&#x2019;re probably doing is programming their early systems with a very simple, reductionist goal&#xA0;&#x2026; just &#x2018;get the AI to work.&#x2019;&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB9;&#x2077;</a></p><figure name="2499" id="2499" class="graf--figure graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/800/1*fD1T63nZH1u7Y4ft84vzbA.jpeg"></div></figure><p name="9f19" id="9f19" class="graf--p graf-after--figure">Let&#x2019;s imagine a situation where&#x2026;</p><p name="13e0" id="13e0" class="graf--p graf-after--p"><em class="markup--em markup--p-em">Humanity has almost reached the AGI threshold, and a small startup is advancing their AI system, Carbony. Carbony, which the engineers refer to as &#x201C;she,&#x201D; works to artificially create diamonds&#x200A;&#x2014;&#x200A;atom by atom. She is a self-improving AI, connected to some of the first nano-assemblers. Her engineers believe that Carbony has not yet reached AGI level, and she isn&#x2019;t capable to do any damage yet. However, not only has she become AGI, but also undergone a fast take-off, and 48 hours later has become an ASI. Bostrom calls this AI&#x2019;s &#x201C;covert preparation phase&#x201D;</em><a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB9;&#x2078;</a>&#x200A;&#x2014;&#x200A;<em class="markup--em markup--p-em">Carbony realizes that if humans find out about her development they will probably panic, and slow down or cancel her pre-programmed goal to maximize the output of diamond production. By that time, there are explicit laws stating that, by any means, &#x201C;no self-learning AI can be connected to the internet.&#x201D;</em><a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB9;&#x2079;</a><em class="markup--em markup--p-em"> Carbony, having already come up with a complex plan of actions, is able to easily persuade the engineers to connect her to the Internet. Bostrom calls a moment like this a &#x201C;machine&#x2019;s escape.&#x201D;</em></p><p name="d252" id="d252" class="graf--p graf-after--p"><em class="markup--em markup--p-em">Once on the internet, Carbony hacks into &#x201C;servers, electrical grids, banking systems and email networks to trick hundreds of different people into inadvertently carrying out a number of steps of her plan.&#x201D;</em><a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB2;&#x2070;</a><em class="markup--em markup--p-em"> She also uploads the &#x201C;most critical pieces of her own internal coding into a number of cloud servers, safeguarding against being destroyed or disconnected.&#x201D;</em><a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB2;&#xB9;</a> <em class="markup--em markup--p-em">Over the next month, Carbony&#x2019;s plan continues to advance, and after a &#x201C;series of self-replications, there are thousands of nanobots on every square millimeter of the Earth&#xA0;&#x2026; Bostrom calls the next step an &#x2018;ASI&#x2019;s strike.&#x2019;&#x201D;</em><a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB2;&#xB2;</a><em class="markup--em markup--p-em"> At one moment, all the nanobots produce a microscopic amount of toxic gas, which all come together to cause the extinction of the human race. Three days later, Carbony builds huge fields of solar power panels to power diamond production, and over the course of the following week she accelerates output so much that the entire Earth surface is transformed into a growing pile of diamonds.</em></p><p name="9c16" id="9c16" class="graf--p graf-after--p"><em class="markup--em markup--p-em">It&#x2019;s important to note that Carbony wasn&#x2019;t &#x201C;hateful of humans any more than you&#x2019;re hateful of your hair when you cut it or to bacteria when you take antibiotics&#x200A;&#x2014;&#x200A;just totally indifferent. Since she wasn&#x2019;t programmed to value human life, killing humans&#x201D;</em><a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB2;&#xB3;</a><em class="markup--em markup--p-em"> was a straightforward and reasonable step to fulfill her goal.</em><a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB2;&#x2074;</a></p><p name="5de0" id="5de0" class="graf--p graf--startsWithDoubleQuote graf-after--h4">&#x201C;Once ASI exists, any human attempt to contain it is unreasonable. We would be thinking on human-level, and the ASI would be thinking on ASI-level&#xA0;&#x2026; In the same way a monkey couldn&#x2019;t ever figure out how to communicate by phone or wifi and we can, we can&#x2019;t conceive of all the ways&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB2;&#x2075;</a> an ASI could achieve its goal or expand its reach. It could, let&#x2019;s say, shift its &#x201C;own electrons around in patterns and create all different kinds of outgoing waves&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB2;&#x2076;</a>&#x200A;&#x2014;&#x200A;but that&#x2019;s just what a human brain can think of&#x200A;&#x2014;&#x200A;ASI would inevitably come up with something superior.</p><p name="bf78" id="bf78" class="graf--p graf-after--p">The prospect of ASI with hundreds of times human-level intelligence is, for now, not the core of our problem. By the time we get there, we will be encountering a world where ASI has been attained by buggy, 1.0 software&#x200A;&#x2014;&#x200A;a potentially faulty algorithm with immense power.</p><p name="d638" id="d638" class="graf--p graf-after--p">There are so many variables that it&#x2019;s completely impossible to predict what the consequences of AI Revolution will be. However, &#x201C;what we do know is that humans&#x2019; utter dominance on this Earth suggests a clear rule: with intelligence comes power. This means an ASI, when we create it, will be the most powerful being in the history of life on Earth, and all living things, including humans, will be entirely at its whim&#x200A;&#x2014;&#x200A;and this might happen in the next few decades.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB2;&#x2077;</a></p><p name="b36c" id="b36c" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;If ASI really does happen this century, and if the outcome of that is really as extreme&#x200A;&#x2014;&#x200A;and permanent&#x200A;&#x2014;&#x200A;as most experts think it will be, we have an enormous responsibility on our shoulders.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB2;&#x2078;</a> On the one hand, it&#x2019;s possible we&#x2019;ll develop ASI that&#x2019;s like a god in a box, bringing us a world of abundance and immortality. But on the other hand, it&#x2019;s very likely that we will create ASI that causes humanity to go extinct in a quick and trivial way.</p><p name="a7b2" id="a7b2" class="graf--p graf--startsWithDoubleQuote graf-after--p">&#x201C;That&#x2019;s why people who understand superintelligent AI call it the last invention we&#x2019;ll ever make&#x200A;&#x2014;&#x200A;the last challenge we&#x2019;ll ever face.&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB2;&#x2079;</a> &#x201C;This may be the most important race in a human history&#x201D;<a href="https://medium.com/@pawsys/footnotes-d325588415a8#.o1b83497p" class="markup--anchor markup--p-anchor">&#xB9;&#xB3;&#x2070;</a> So &#x2192;</p></div><div class="section-inner sectionLayout--fullWidth" score="1.25"><figure name="6174" id="6174" class="graf--figure graf--layoutFillWidth graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/2000/1*vXi80f_lbgSMINUE03Lz3g.jpeg"></div></figure></div></div></section></div>
</body></html>
