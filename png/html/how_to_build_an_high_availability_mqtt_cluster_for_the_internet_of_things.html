<!DOCTYPE html><html><head><title>How to Build an High Availability 
MQTT Cluster for the Internet of Things</title></head><body>
<h1>How to Build an High Availability 
MQTT Cluster for the Internet of Things</h1><p><a href="https://medium.com/@lelylan/how-to-build-an-high-availability-mqtt-cluster-for-the-internet-of-things-8011a06bd000#.zc7ouz3xl" target="_new">Original URL</a></p>
<p><blockquote>Create a scalable MQTT infrastructure using Node.js, Redis, HAProxy and nscale to make the deployment phase a piece of cake &#x263A;</blockquote></p>
<div score="32.5"><section name="3455" class=" section--body section--topCenter section-image--aspectRatioViewport is-imageBackgrounded is-backgrounded is-darkBackgrounded section--first" score="48.75"><div class="section-doubleWidthTable u-table u-ignoreBlock" score="8.75"><div class="u-tableCell u-verticalAlignTop u-ignoreBlock" score="2.5"><div class="section-doubleWidthTable u-table u-ignoreBlock" score="21.25"><div class="section-contentCell u-tableCell u-ignoreBlock" score="45.0"><div class="section-content" score="31.25"><div class="section-inner layoutSingleColumn"><p name="56bb" id="56bb" class="graf--p graf-after--h3 graf--last">Create a scalable MQTT infrastructure using Node.js, Redis, HAProxy and nscale to make the deployment phase a piece of cake &#x263A;</p></div></div></div></div></div></div></section><section name="1b49" class=" section--body" score="41.25"><div class="section-content" score="32.5"><div class="section-inner layoutSingleColumn" score="-8.75"><p name="1341" id="1341" class="graf--p graf-after--h3">In this article I&#x2019;ll show you how to creare a scalable MQTT cluster for the Internet of Things. Everything comes from the work made in <a href="http://github.com/lelylan/lelylan" class="markup--anchor markup--p-anchor" rel="nofollow">Lelylan</a>. If useful to you and your work, think about giving us a star on <a href="https://github.com/lelylan/lelylan/" class="markup--anchor markup--p-anchor" rel="nofollow">Github</a>. It will help us to reach more developers.</p><p name="271e" id="271e" class="graf--p graf-after--h3">In a professional Internet of Things environment the availability and the scalability of your services is a key factor you need to take care of. For MQTT environments this means your broker needs a stable connection, always-on functionality and the capability of updating your private cloud infrastructure while it&#x2019;s running in production. In this article we&#x2019;ll share step by step all we&#x2019;ve learned on building such an environment for Lelylan.</p><figure name="db31" id="db31" class="graf--figure graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><a href="http://www.hivemq.com/building-a-high-availability-mqtt-cluster/" class="graf-imageAnchor"><img class="graf-image" src="https://cdn-images-1.medium.com/max/800/1*O1Gunc-vIbcJJ0prKIVHgw.png"></a></div><figcaption class="imageCaption">Devices connecting to a load balancer, forwarding all connections to two MQTT servers. Image copyright to HiveMQ.</figcaption></figure><p name="e63b" id="e63b" class="graf--p graf-after--figure">The main benefit of such a setup is that if one of your MQTT servers is not available, the still available brokers can handle the traffic. In other words, if one of the two (or more) nodes stop working the load balancer will reroute all incoming traffic to the working cluster node and you won&#x2019;t have any interruptions on the client side.</p><p name="7fb6" id="7fb6" class="graf--p graf-after--p">We also wanted to simplify the deployment process. Using nscale was easy to reach the final result where we can deploy on 2 (or more) MQTT servers using just the following couple of commands.</p><pre name="ea8c" id="ea8c" class="graf--pre graf-after--p">$ nsd cont buildall<br>$ nsd rev dep head</pre><p name="9f79" id="9f79" class="graf--p graf-after--h3">Follow the list of the used tools to reach the final result.</p><p name="0a67" id="0a67" class="graf--p graf-after--p"><a href="https://github.com/mcollina/mosca" class="markup--anchor markup--p-anchor" rel="nofollow"><strong class="markup--strong markup--p-strong">Mosca</strong></a><strong class="markup--strong markup--p-strong">.</strong> A Node.js MQTT server/broker. It&#x2019;s MQTT 3.1 compliant and it supports QoS 0 and QoS 1, together with the storage options for offline packets, and subscriptions.</p><p name="1770" id="1770" class="graf--p graf-after--p"><a href="http://www.haproxy.org/" class="markup--anchor markup--p-anchor" rel="nofollow"><strong class="markup--strong markup--p-strong">HAProxy</strong></a>. A free, fast and reliable solution offering high availability, load balancing and proxying for TCP and HTTP based applications. It&#x2019;s suited for very high traffic web sites.</p><p name="b132" id="b132" class="graf--p graf-after--p"><a href="https://www.docker.com/" class="markup--anchor markup--p-anchor" rel="nofollow"><strong class="markup--strong markup--p-strong">Docker</strong></a>. Docker is an open platform for developers and sysadmins to build, ship, and run distributed applications enabling apps to be quickly assembled from components and eliminating the friction between development and production environments.</p><p name="0368" id="0368" class="graf--p graf-after--p"><a href="http://nscale.nearform.com/" class="markup--anchor markup--p-anchor" rel="nofollow"><strong class="markup--strong markup--p-strong">Nscale</strong></a>. An open source project that makes it simple to configure, build and deploy a set of connected containers to constitute a working platform for distributed applications (using nscale you can easily formalize a process for deploying micro service based systems).</p><p name="b0fd" id="b0fd" class="graf--p graf-after--p"><a href="http://redis.io/" class="markup--anchor markup--p-anchor" rel="nofollow"><strong class="markup--strong markup--p-strong">Redis</strong></a><strong class="markup--strong markup--p-strong">. </strong>An open source, BSD licensed, advanced key-value cache and store.</p><p name="682e" id="682e" class="graf--p graf-after--h3 graf--last">Here the steps we&#x2019;re going to follow to crete, piece by piece, an high availability MQTT cluster for the Internet of Things.</p></div></div></section><section name="2085" class=" section--body" score="41.25"><div class="section-content" score="32.5"><div class="section-inner layoutSingleColumn" score="12.0"><ol class="postList"><li name="81f4" id="81f4" class="graf--li graf--first"><em class="markup--em markup--li-em">Setting up the MQTT server.</em></li><li name="2b73" id="2b73" class="graf--li graf-after--li"><em class="markup--em markup--li-em">Dockerizing our MQTT server.</em></li><li name="1d10" id="1d10" class="graf--li graf-after--li"><em class="markup--em markup--li-em">Adding HAProxy as load balancer.</em></li><li name="a265" id="a265" class="graf--li graf-after--li"><em class="markup--em markup--li-em">Making MQTT secure with SSL.</em></li><li name="b3d1" id="b3d1" class="graf--li graf-after--li"><em class="markup--em markup--li-em">Configuring nscale to automate the deployment workflow.</em></li><li name="3cd2" id="3cd2" class="graf--li graf-after--li graf--last"><em class="markup--em markup--li-em">Final Considerations</em></li></ol></div></div></section><section name="4ada" class=" section--body section--last" score="41.25"><div class="section-content" score="32.5"><div class="section-inner layoutSingleColumn" score="-39.75"><p name="0481" id="0481" class="graf--p graf-after--h3">MQTT<strong class="markup--strong markup--p-strong"> </strong>is a machine-to-machine (M2M)/&#x201C;Internet of Things&#x201D; connectivity protocol. It was designed as an extremely lightweight publish/subscribe messaging protocol and it is useful for connections with remote locations where a small code footprint is required and network bandwidth is at a premium.</p><figure name="25ca" id="25ca" class="graf--figure graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/800/1*H2Xs_wmVT1eH-rjp3rKfyQ.png"></div></figure><p name="611e" id="611e" class="graf--p graf-after--figure">The first time we looked for an MQTT solution was two years ago. We were searching for a secure (auth based), customisable (communicating with our REST API) and easy to use solution (we knew Node.js). We found in <a href="https://github.com/mcollina/mosca" class="markup--anchor markup--p-anchor" rel="nofollow">Mosca</a> the right solution and, after two years, we&#x2019;re happy with our choice &#x263A;</p><blockquote name="eb22" id="eb22" class="graf--blockquote graf-after--p">The key metrics influencing your MQTT server choice could be different from ours. If so, check out <a href="https://github.com/mqtt/mqtt.github.io/wiki/Server%20support" class="markup--anchor markup--blockquote-anchor" rel="nofollow">this list</a> of MQTT servers and their capabilities.</blockquote><p name="62ea" id="62ea" class="graf--p graf-after--h4">We&#x2019;re not going to describe every single line of code, but we&#x2019;ll show you two main sections, showing how simple can be setting up an MQTT server.</p><blockquote name="f3eb" id="f3eb" class="graf--blockquote graf-after--p">The code we use to run MQTT server on Lelylan is available on <a href="https://github.com/lelylan/mqtt/" class="markup--anchor markup--blockquote-anchor" rel="nofollow">Github</a>.</blockquote><p name="516f" id="516f" class="graf--p graf-after--blockquote"><strong class="markup--strong markup--p-strong">Setting up the MQTT server</strong></p><p name="7d19" id="7d19" class="graf--p graf-after--p">The code below is used to start the MQTT server. First we configure the pub/sub settings using Redis, we pass the pub/sub settings object to our server and we are done.</p><figure name="9038" id="9038" class="graf--figure graf--iframe graf-after--p" score="-13.75"><figcaption class="imageCaption">Node.js code needed to run a simple MQTT server</figcaption></figure><blockquote name="ef45" id="ef45" class="graf--blockquote graf-after--figure">If you ask yourself, why Redis is needed as pub/sub solution, read the Q1 on <a href="https://github.com/mcollina/mosca/wiki/FAQ-%28Frequently-asked-questions%29" class="markup--anchor markup--blockquote-anchor" rel="nofollow">FAQ</a>. Being short we need it to enable a communication channel between the MQTT server and other <a href="http://martinfowler.com/articles/microservices.html" class="markup--anchor markup--blockquote-anchor" rel="nofollow"><em class="markup--em markup--blockquote-em">microservices</em></a> composing Lelylan.</blockquote><p name="9e3d" id="9e3d" class="graf--p graf-after--blockquote"><strong class="markup--strong markup--p-strong">Authenticating the physical objects</strong></p><p name="888b" id="888b" class="graf--p graf-after--p">With Mosca you can authorize a client defining three methods, each of them used to restrict the accessible topics for a specific clients.</p><pre name="9eea" id="9eea" class="graf--pre graf-after--p">#authenticate<br>#authorizePublish<br>#authorizeSubscribe</pre><p name="67d6" id="67d6" class="graf--p graf-after--pre">In Lelylan we use the <em class="markup--em markup--p-em">authenticate method </em>to verify the client username and password. If the authentication is successful, the <em class="markup--em markup--p-em">device_id</em> is saved in the client object<em class="markup--em markup--p-em">, </em>and used later on to authorize (or not) the publish and subscribe functionalities.</p><figure name="34f5" id="34f5" class="graf--figure graf--iframe graf-after--p" score="-13.75"></figure><blockquote name="715e" id="715e" class="graf--blockquote graf-after--figure">If you want to learn more about MQTT and Lelylan check out the <a href="http://dev.lelylan.com/makers#mqtt" class="markup--anchor markup--blockquote-anchor" rel="nofollow">dev center</a>.</blockquote><p name="478e" id="478e" class="graf--p graf-after--h3"><a href="https://docker.com/" class="markup--anchor markup--p-anchor" rel="nofollow">Docker</a> is an awesome tool to deploy production systems. It allows you to isolate your code in a clean system environment by defining a <a href="https://docs.docker.com/reference/builder/" class="markup--anchor markup--p-anchor" rel="nofollow">Dockerfile</a>, an installation &#x201C;recipe&#x201D; used to initialize a system environment.</p><figure name="ad8f" id="ad8f" class="graf--figure graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><a href="http://docker.com" class="graf-imageAnchor"><img class="graf-image" src="https://cdn-images-1.medium.com/max/800/1*7a8Qffxkg7WuePBZUebYSw.png"></a></div><figcaption class="imageCaption">Docker. An awesome tool to deploy production systems</figcaption></figure><p name="189b" id="189b" class="graf--p graf-after--h4"><strong class="markup--strong markup--p-strong">Container definition</strong></p><p name="1ecf" id="1ecf" class="graf--p graf-after--p">To build a container around our application, we first need to create a file named <em class="markup--em markup--p-em">Dockerfile</em>. In here we&#x2019;ll place all the needed commands Docker uses to initialize the desired environment.</p><figure name="6286" id="6286" class="graf--figure graf--iframe graf-after--p" score="-13.75"></figure><p name="4be6" id="4be6" class="graf--p graf-after--figure">In the Dockerfile used to create a container around the MQTT server we ask for a specific Node.js version (<em class="markup--em markup--p-em">FROM node:0.10-onbuild)</em>, add all files of the repo (<em class="markup--em markup--p-em">ADD&#xA0;./&#xA0;.)</em>, install the node packages (<em class="markup--em markup--p-em">RUN npm install)</em>, expose the port 1883 (<em class="markup--em markup--p-em">EXPOSE 1883) </em>and finally run the node app (<em class="markup--em markup--p-em">ENTRYPOINT [&#x201C;node&#x201D;, &#x201C;app.js&#x201D;]). </em>That&#x2019;s all.</p><p name="d719" id="d719" class="graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Run the Docker Image</strong></p><p name="640f" id="640f" class="graf--p graf-after--p">Once we have a Dockerfile, we can build a docker container (if you haven&#x2019;t Docker installed, <a href="http://docs.docker.com/installation/#installation" class="markup--anchor markup--p-anchor" rel="nofollow">do so</a> - it supports all existing platforms, even Windows &#x263A;). Once you have docker installed, we can build the container.</p><pre name="335b" id="335b" class="graf--pre graf-after--p"># building a container<br>$ docker build -t lelylan/mqtt</pre><p name="3a01" id="3a01" class="graf--p graf-after--pre">Which will eventually output</p><pre name="d11e" id="d11e" class="graf--pre graf-after--p">Successfully built lelylan/mqtt</pre><p name="8f67" id="8f67" class="graf--p graf-after--pre">Once we have built the container, we can run it to get a working image.</p><pre name="60d2" id="60d2" class="graf--pre graf-after--p">docker run -p 1883:1883 -d lelylan/mqtt</pre><p name="46fb" id="46fb" class="graf--p graf-after--pre">And we&#x2019;re done! We now can make requests to our MQTT server.</p><blockquote name="083e" id="083e" class="graf--blockquote graf-after--p">When starting with Docker, it&#x2019;s easy to make little confusion between containers and images. Read out what <a href="http://docs.docker.com/terms/container" class="markup--anchor markup--blockquote-anchor" rel="nofollow">both</a> of <a href="http://docs.docker.com/terms/image/" class="markup--anchor markup--blockquote-anchor" rel="nofollow">them</a> means to make your mind clearer.</blockquote><pre name="a663" id="a663" class="graf--pre graf-after--blockquote"># OSX<br>$ http://$(boot2docker ip):1883</pre><pre name="9d9f" id="9d9f" class="graf--pre graf-after--pre"># Linux<br>$ <a href="http://localhost:80" class="markup--anchor markup--pre-anchor">http://localhost:1883</a></pre><blockquote name="88d9" id="88d9" class="graf--blockquote graf-after--pre"><em class="markup--em markup--blockquote-em">If you&#x2019;re using OS X we&#x2019;re using boot2docker which is actually a Linux VM, we need to use the $DOCKER_HOST environment variable to access the VM&#x2019;s localhost, otherwise, if you&#x2019;re using Linux use localhost.</em></blockquote><p name="f037" id="f037" class="graf--p graf-after--blockquote"><strong class="markup--strong markup--p-strong">Other commands we were using a lot</strong></p><p name="c541" id="c541" class="graf--p graf-after--p">While learning how to use Docker, we wrote down a common to use list of commands. They all are basic, but we think it&#x2019;s good to have a reference to look at when needed.</p><pre name="81b1" id="81b1" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">Container related commands</strong></pre><pre name="0c92" id="0c92" class="graf--pre graf-after--pre"># build and run a container without a tag<br>$ docker build .<br>$ docker run -p 80:1883 &lt;CONTAINER_ID&gt;</pre><pre name="fa6a" id="fa6a" class="graf--pre graf-after--pre"># build and run a container using a tag<br>$ docker build -t &lt;USERNAME&gt;/&lt;PROJECT_NAME&gt;:&lt;V1&gt;<br>$ docker run -p 80:1883 -d &lt;USERNAME&gt;/&lt;PROJECT_NAME&gt;:&lt;V1&gt;</pre><pre name="1171" id="1171" class="graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">Image related commands</strong></pre><pre name="a4a9" id="a4a9" class="graf--pre graf-after--pre"># Run interactively into the image<br>$ docker run -i &lt;IMAGE_ID&gt; /bin/bash</pre><pre name="7531" id="7531" class="graf--pre graf-after--pre"># Run image with environment variables (place at the beginning)<br>$ docker run -e "VAR=VAL" -p 80:1883 &lt;IMAGE_ID&gt;</pre><pre name="fd0d" id="fd0d" class="graf--pre graf-after--pre"># list all running images<br>$ docker ps</pre><pre name="92e2" id="92e2" class="graf--pre graf-after--pre"># List all running and not running images<br># (useful to see also images that exited because of an error).<br>$ docker ps -a</pre><pre name="e2ea" id="e2ea" class="graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">Kill images</strong></pre><pre name="f7d1" id="f7d1" class="graf--pre graf-after--pre"># Kill all images<br>docker ps -a -q | xargs docker rm -f</pre><pre name="fe8c" id="fe8c" class="graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">Log related commands</strong></pre><pre name="0e51" id="0e51" class="graf--pre graf-after--pre"># See logs for a specific image<br>docker logs &lt;IMAGE_ID&gt;</pre><pre name="ff22" id="ff22" class="graf--pre graf-after--pre"># See logs using the tail mode<br>docker logs -f &lt;IMAGE_ID&gt;</pre><p name="a536" id="a536" class="graf--p graf-after--h3">At this point we have a dockerized MQTT server being able to receive connections from any physical object (client). The missing thing is that it doesn&#x2019;t scale, not yet &#x263A;.</p><p name="6543" id="6543" class="graf--p graf-after--p">Here comes <a href="http://www.haproxy.org" class="markup--anchor markup--p-anchor" rel="nofollow">HAProxy</a>, a popular TCP/HTTP load balancer and proxying solution used to improve the performance and the reliability of a server environment, distributing the workload across multiple servers. It is written in C and has a reputation for being fast and efficient.</p><p name="7b72" id="7b72" class="graf--p graf-after--h4">Before showing how we used HAProxy, there are some concepts you need to know when using a load balancing.</p><blockquote name="e181" id="e181" class="graf--blockquote graf-after--p">If curious, you can find a lot of useful info in <a href="https://www.digitalocean.com/community/tutorials/an-introduction-to-haproxy-and-load-balancing-concepts" class="markup--anchor markup--blockquote-anchor" rel="nofollow">this article</a> written by Mitchell Anicas</blockquote><p name="7726" id="7726" class="graf--p graf-after--blockquote"><strong class="markup--strong markup--p-strong">Access Control List (ACL)</strong></p><p name="8c93" id="8c93" class="graf--p graf-after--p">ACLs are used to test some condition and perform an action (e.g. select a server, or block a request) based on the test result. Use of ACLs allows flexible network traffic forwarding based on a different factors like pattern-matching or the number of connections to a backend.</p><pre name="2da2" id="2da2" class="graf--pre graf-after--p"># This ACL matches if the path of user&#x2019;s request begins with <em class="markup--em markup--pre-em">/blog<br></em># (this would match a request of <em class="markup--em markup--pre-em">http://example.org/blog/entry-1)</em><br>acl url_blog path_beg /blog</pre><p name="abaa" id="abaa" class="graf--p graf-after--h4">A backend is a set of servers that receives forwarded requests. Generally speaking, adding more servers to your backend will increase your potential load capacity and reliability by spreading the load over them. In the following example there is a backend configuration, with two web servers listening on port 80.</p><pre name="fc10" id="fc10" class="graf--pre graf-after--p">backend web-backend<br> balance roundrobin<br> server web1 web1.example.org:80 check<br> server web2 web2.example.org:80 check</pre><p name="1194" id="1194" class="graf--p graf-after--h4">A frontend defines how requests are be forwarded to backends. Frontends are defined in the <em class="markup--em markup--p-em">frontend </em>section of the HAProxy configuration and they put together IP addresses, ACLs and backends. In the following example, if a user requests <em class="markup--em markup--p-em">example.com/blog</em>, it&#x2019;s forwarded to the <em class="markup--em markup--p-em">blog </em>backend, which is a set of servers that run a blog application. Other requests are forwarded to <em class="markup--em markup--p-em">web-backend</em>, which might be running another application.</p><pre name="ecc2" id="ecc2" class="graf--pre graf-after--p">frontend http<br> bind *:80<br> mode http</pre><pre name="4b54" id="4b54" class="graf--pre graf-after--pre"> acl url_blog path_beg /blog<br> use_backend blog-backend if url_blog</pre><pre name="77af" id="77af" class="graf--pre graf-after--pre"> default_backend web-backend</pre><p name="6090" id="6090" class="graf--p graf-after--h4">The code we used to run the HAProxy server on Lelylan is defined by a Dockerfile and a configuration file describing how requests are handled.</p><blockquote name="b5bc" id="b5bc" class="graf--blockquote graf-after--p">The code we use to run HAProxy is available on <a href="https://github.com/lelylan/haproxy-mqtt" class="markup--anchor markup--blockquote-anchor" rel="nofollow">Github</a></blockquote><p name="4265" id="4265" class="graf--p graf-after--blockquote"><strong class="markup--strong markup--p-strong">Get your HAProxy container from Docker Hub</strong></p><p name="1960" id="1960" class="graf--p graf-after--p">To get started download the HAProxy container from the public <a href="https://registry.hub.docker.com/" class="markup--anchor markup--p-anchor" rel="nofollow">Docker Hub Registry</a> (it contains an automated build ready to be used).</p><pre name="e202" id="e202" class="graf--pre graf-after--p">$ docker pull dockerfile/haproxy</pre><p name="d097" id="d097" class="graf--p graf-after--pre">At this point run the HAProxy container.</p><pre name="205d" id="205d" class="graf--pre graf-after--p">$ docker run -d -p 80:80 dockerfile/haproxy</pre><p name="bfbd" id="bfbd" class="graf--p graf-after--pre">The HAProxy container accepts a configuration file as data volume option (as you can see in the example below), where <em class="markup--em markup--p-em">&lt;override-dir&gt;</em> is an absolute path of a directory that contains <em class="markup--em markup--p-em">haproxy.cfg (</em>custom config file) and <em class="markup--em markup--p-em">errors/ (</em>custom error responses).</p><pre name="6a19" id="6a19" class="graf--pre graf-after--p"># Run HAProxy image with a custom configuration file<br>$ docker run -d -p 1883:1883 \<br> -v &lt;override-dir&gt;:/haproxy-override dockerfile/haproxy</pre><blockquote name="cfa4" id="cfa4" class="graf--blockquote graf-after--pre">This is perfect to test out a configuration file</blockquote><p name="fc42" id="fc42" class="graf--p graf-after--blockquote"><strong class="markup--strong markup--p-strong">HAProxy Configuration</strong></p><p name="4be2" id="4be2" class="graf--p graf-after--p">Follows the configuration for our MQTT servers, where HAProxy listens for all requests coming to port 1883, forwarding them to two MQTT servers (mosca_1 and mosca_2) using the <em class="markup--em markup--p-em">leastconn</em> balance mode (selects the server with the least number of connections).</p><figure name="aa47" id="aa47" class="graf--figure graf--iframe graf-after--p" score="-13.75"></figure><blockquote name="f111" id="f111" class="graf--blockquote graf-after--figure">2. To see the final configurations used by Lelylan checkout <a href="https://github.com/lelylan/haproxy-mqtt/blob/master/haproxy.cfg" class="markup--anchor markup--blockquote-anchor" rel="nofollow">haproxy.cfg</a> on Github. 1. During the HAProxy introduction we described the ACL, backend and frontend concepts. Here we used listen, a shorter but less expressive way to define all these concepts together. We used it because of some problems we had using backend and frontend. If you find out a working configuration using them, let <a href="http://twitter.com/lelylan" class="markup--anchor markup--blockquote-anchor" rel="nofollow">us know</a>.</blockquote><p name="83ec" id="83ec" class="graf--p graf-after--blockquote">To try out the new configuration (useful on development), override the default ones by using the data volume option. In the following example we override <em class="markup--em markup--p-em">haproxy-override</em> with the configuration file defined in <em class="markup--em markup--p-em">/root/haproxy-override/</em>.</p><pre name="11d5" id="11d5" class="graf--pre graf-after--p">$ docker run -d -p 80:80 1883:1883 \<br> -v <strong class="markup--strong markup--pre-strong">/root/haproxy-override</strong>:/haproxy-override<br> dockerfile/haproxy</pre><p name="1bce" id="1bce" class="graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Create your HAProxy Docker Container</strong></p><p name="464d" id="464d" class="graf--p graf-after--p">Once we have a working configuration, we can create a new HAProxy container using it. All we need to do is to define a Dockerfile loading the HAProxy container (<em class="markup--em markup--p-em">FROM dockerfile/haproxy) </em>to which we replace the configuration file defined in /etc/haproxy/haproxy.cfg (<em class="markup--em markup--p-em">ADD haproxy.cfg /etc/haproxy/haproxy.cfg).</em> We then restart the HAProxy server (<em class="markup--em markup--p-em">CMD [&#x201C;bash&#x201D;, &#x201C;/haproxy-start&#x201D;]</em>) and expose the desired ports (80/443/1883/8883).</p><figure name="3984" id="3984" class="graf--figure graf--iframe graf-after--p" score="-13.75"></figure><blockquote name="0b93" id="0b93" class="graf--blockquote graf-after--figure">NOTE. We restart HAProxy, not simply start, because when loading the initial HAProxy container, HAProxy is already running. This means that when we change the configuration file, we need to give a fresh restart to load it.</blockquote><p name="34dc" id="34dc" class="graf--p graf-after--blockquote"><strong class="markup--strong markup--p-strong">Extra tips for HAProxy</strong></p><p name="3f8f" id="3f8f" class="graf--p graf-after--p">When having troubles with HAProxy, read the logs! HAProxy uses <a href="http://www.rsyslog.com/" class="markup--anchor markup--p-anchor" rel="nofollow">rsyslog</a>, a rocket-fast system for log<strong class="markup--strong markup--p-strong"> </strong>processing, used by default in Ubuntu.</p><pre name="824d" id="824d" class="graf--pre graf-after--p"># HAProxy log configuration file<br>$ vi /etc/rsyslog.d/haproxy.conf</pre><pre name="28ed" id="28ed" class="graf--pre graf-after--pre"># Files where you can find the HAProxy logs<br>$ tail -f /var/lib/haproxy/dev/log<br>$ tail -f /var/log/haproxy.log</pre><p name="5bdf" id="5bdf" class="graf--p graf-after--h3">We now have a scalable MQTT infrastructure where all requests are proxied by HAProxy to two (or more) MQTT servers. The next step is to make the communication secure using SSL.</p><blockquote name="f53e" id="f53e" class="graf--blockquote graf-after--p">Native SSL support was implemented in HAProxy 1.5.x, which was released as a stable version in June 2014.</blockquote><p name="c0cc" id="c0cc" class="graf--p graf-after--h4">SSL (Secure Sockets Layer) is the accepted standard for encrypted communication between a server and a client ensuring that all data passed between the server and client remain private and integral.</p><p name="dd2f" id="dd2f" class="graf--p graf-after--h4">First of all you need an SSL certificate. To implement SSL with HAProxy, the SSL certificate and key pair must be in the proper format: <em class="markup--em markup--p-em">PEM</em>.</p><p name="d431" id="d431" class="graf--p graf-after--p">In most cases, you simply combine your SSL certificate (.crt or&#xA0;.cer file provided by a certificate authority) and its respective private key (.key file, generated by you). Assuming that the certificate file is called <em class="markup--em markup--p-em">lelylan.com.crt</em>, and your private key file is called <em class="markup--em markup--p-em">lelylan.com.key</em>, here is an example of how to combine the files creating the PEM file <em class="markup--em markup--p-em">lelylan.com.pem</em>.</p><pre name="7ca2" id="7ca2" class="graf--pre graf-after--p">cat lelylan.com.crt lelylan.com.key &gt; lelylan.com.pem</pre><blockquote name="2291" id="2291" class="graf--blockquote graf-after--pre">As always, be sure to secure any copies of your private key file, including the PEM file (which contains the private key).</blockquote><p name="ec76" id="ec76" class="graf--p graf-after--h4">Once we&#x2019;ve created our SSL certificate, we can&#x2019;t save it in a public repo. You know, security &#x263A;. What we have to do is to place it in the HAProxy server, making it accessible form Docker through data volumes.</p><p name="f021" id="f021" class="graf--p graf-after--p"><strong class="markup--strong markup--p-strong">What is Docker data volumes?</strong></p><p name="bba9" id="bba9" class="graf--p graf-after--p">A data volume<em class="markup--em markup--p-em"> </em>is a specially-designated directory within one or more containers that provide useful features shared data. You can add a data volume to a container using the -v flag to share any file/folder, using -v multiple times to mount multiple data volumes (we already used it when loading a configuration file for the HAProxy container).</p><p name="d3ee" id="d3ee" class="graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Using data volumes to share an SSL certificate.</strong></p><p name="f79d" id="f79d" class="graf--p graf-after--p">To share our SSL certificate, we placed it in <em class="markup--em markup--p-em">/certs</em> (in the HAProxy server), making it accessible through the /certs folder when running the Docker Container.</p><pre name="53e4" id="53e4" class="graf--pre graf-after--p">$ docker run -d -p 80:80 -p 443:443 -p 1883:1883 -p 8883:8883 \<br> -v /certs:/certs<br> -v /root/haproxy-override:/haproxy-override</pre><blockquote name="71bd" id="71bd" class="graf--blockquote graf-after--pre">Don&#x2019;t forget to open the port 8883 (the default one for secure MQTT connections)</blockquote><p name="dc57" id="dc57" class="graf--p graf-after--blockquote"><strong class="markup--strong markup--p-strong">Loading the SSL certificate</strong></p><p name="c46f" id="c46f" class="graf--p graf-after--p">Once we have the SSL certificate available through Docker data volume, we can access it during through the HAProxy configuration file. All we need to do is to add one line of code to map the requests coming to the 8883 port to the SSL certificate placed in <em class="markup--em markup--p-em">/certs</em> and named <em class="markup--em markup--p-em">lelylan.pem</em>.</p><figure name="7b32" id="7b32" class="graf--figure graf--iframe graf-after--p" score="-13.75"></figure><p name="6054" id="6054" class="graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">We&#x2019;re done!</strong></p><p name="c52d" id="c52d" class="graf--p graf-after--p">At this point we have a Secure, High Availability MQTT Cluster for the Internet of Things. Below, you can see an image representing the final result.</p><figure name="06c5" id="06c5" class="graf--figure graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><a href="http://www.hivemq.com/building-a-high-availability-mqtt-cluster/" class="graf-imageAnchor"><img class="graf-image" src="https://cdn-images-1.medium.com/max/800/1*O1Gunc-vIbcJJ0prKIVHgw.png"></a></div><figcaption class="imageCaption">Devices connecting to a load balancer, forwarding all connections to two MQTT servers. Image copyright to HiveMQ.</figcaption></figure><p name="68a5" id="68a5" class="graf--p graf-after--figure">At this point, there&#x2019;s one thing to make the architecture complete: we need a simple way to deploy it.</p><p name="5576" id="5576" class="graf--p graf-after--h3">To make this possible we&#x2019;ll use <a href="http://nscale.nearform.com" class="markup--anchor markup--p-anchor" rel="nofollow">nscale</a>, an open source project to configure, build and deploy a set of connected containers.</p><blockquote name="2276" id="2276" class="graf--blockquote graf-after--p">While we&#x2019;ll describe some of the most important commands used by nscale, <a href="https://github.com/nearform/nscale-workshop" class="markup--anchor markup--blockquote-anchor" rel="nofollow">here</a> you can find a guide describing step by step how nscale works.</blockquote><p name="4bda" id="4bda" class="graf--p graf-after--h4"><a href="https://www.digitalocean.com/?refcode=0e3d36693e16" class="markup--anchor markup--p-anchor" rel="nofollow">Digital Ocean</a> is a simple cloud hosting, built for developers. For our deployment solution&#xA0;, all the droplets we&#x2019;ll use, are based on Ubuntu and have Docker already installed.</p><figure name="2fff" id="2fff" class="graf--figure graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/800/1*vmtoLnk83QKvbuej0K9JMQ.png"></div><figcaption class="imageCaption">Droplet definition</figcaption></figure><blockquote name="1670" id="1670" class="graf--blockquote graf-after--figure">Do not have a Digital Ocean account? Sign up through <a href="https://www.digitalocean.com/?refcode=0e3d36693e16" class="markup--anchor markup--blockquote-anchor" rel="nofollow">this link</a> and get 10$ credit.</blockquote><p name="945c" id="945c" class="graf--p graf-after--blockquote">The first thing we had to do was to create 5 droplets, each of them dedicated to a specific app: 1 management machine (where the nscale logic will live), 1 HAProxy load balancer, 2 MQTT Mosca servers and 1 Redis server.</p><figure name="8405" id="8405" class="graf--figure graf-after--p" score="-12.5"><div class="aspectRatioPlaceholder is-locked" score="6.25"><img class="graf-image" src="https://cdn-images-1.medium.com/max/800/1*C_NhlKIiOWKxh8zGzpH9vg.png"></div><figcaption class="imageCaption">List of Droplets created in Digital Ocean for this tutorial</figcaption></figure><blockquote name="a425" id="a425" class="graf--blockquote graf-after--figure">List of Droplets created for this tutorial on Digital Ocean.</blockquote><p name="313f" id="313f" class="graf--p graf-after--h4">We&#x2019;re now ready to install nscale into the <em class="markup--em markup--p-em">management machine</em> defined on Digital Ocean. We could also have used our local machine, but having a dedicated server for this, make it simple for all team members to deploy new changes.</p><p name="da51" id="da51" class="graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Installation</strong></p><p name="8cc1" id="8cc1" class="graf--p graf-after--p">Install Node.js via nvm (Node Version Manager).</p><pre name="3f54" id="3f54" class="graf--pre graf-after--p"><em class="markup--em markup--pre-em">curl </em><a href="https://raw.githubusercontent.com/creationix/nvm/v0.18.0/install.sh" class="markup--anchor markup--pre-anchor" rel="nofollow"><em class="markup--em markup--pre-em">https://raw.githubusercontent.com/creationix/nvm/v0.18.0/install.sh</em></a><em class="markup--em markup--pre-em"> | bash</em></pre><p name="4aae" id="4aae" class="graf--p graf-after--pre">Logoff, login and run the following commands.</p><pre name="79c1" id="79c1" class="graf--pre graf-after--p"># install needed dependencies<br>apt-get update<br>apt-get install build-essential</pre><pre name="0391" id="0391" class="graf--pre graf-after--pre"># install node and npm<br>nvm install v0.10.33<br>nvm alias default v0.10.33<br>npm install npm@latest -g --unsafe-perm</pre><pre name="8971" id="8971" class="graf--pre graf-after--pre"># install nscale<br>npm install nscale -g --unsafe-perm</pre><blockquote name="32eb" id="32eb" class="graf--blockquote graf-after--pre">The installation could take a while, it&#x2019;s normal &#x263A;</blockquote><p name="9f4a" id="9f4a" class="graf--p graf-after--blockquote"><strong class="markup--strong markup--p-strong">Github user configuration</strong></p><p name="6149" id="6149" class="graf--p graf-after--p">To use nscale you need to configure GIT.</p><pre name="5be7" id="5be7" class="graf--pre graf-after--p">git config --global user.name "&lt;YOUR_NAME&gt;"<br>git config --global user.email "&lt;YOUR_EMAIL&gt;"</pre><p name="150a" id="150a" class="graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Create your first nscale project</strong></p><p name="e3e8" id="e3e8" class="graf--p graf-after--p">Once all the configurations are done, login into nscale.</p><pre name="1d78" id="1d78" class="graf--pre graf-after--p">$ nsd login</pre><p name="7946" id="7946" class="graf--p graf-after--pre">At this point we can create our first nscale project, where you&#x2019;ll be asked to set a <em class="markup--em markup--p-em">name</em> and a <em class="markup--em markup--p-em">namespace (</em>we used the same name for both of them<em class="markup--em markup--p-em">).</em></p><pre name="8d14" id="8d14" class="graf--pre graf-after--p">$ nsd sys create <br>1. Set a name for your project: &lt;NAME&gt;<br>2. Set a namespace for your project: &lt;NAMESPACE&gt;</pre><p name="fd4d" id="fd4d" class="graf--p graf-after--pre">This command will result into an automatically generated project folder with the following structure (don&#x2019;t worry about all the files you see; the only ones we need to take care of are <em class="markup--em markup--p-em">definition/services.js </em>and <em class="markup--em markup--p-em">system.js).</em></p><pre name="278e" id="278e" class="graf--pre graf-after--p">|&#x2014; definitions<br>| |&#x2014; machines.js<br>| `&#x2014; services.js *<br>|&#x2014; deployed.json<br>|&#x2014; map.js<br>|&#x2014; npm-debug.log<br>|&#x2014; README.md<br>|&#x2014; sudc-key<br>|&#x2014; sudc-key.pub<br>|&#x2014; system.js *<br>|&#x2014; timeline.json<br>`&#x2014; workspace<br>...</pre><p name="4fb7" id="4fb7" class="graf--p graf-after--pre">At this point use the list command to see if the new nscale project is up and running. If everything is fine, you&#x2019;ll see the project name and Id.</p><pre name="758a" id="758a" class="graf--pre graf-after--p">$ nsd sys list<br>Name Id<strong class="markup--strong markup--pre-strong"> </strong><br>lelylan-mqtt 6b4b4e3f-f22e-4516-bffb-e1a8daafb3ea</pre><p name="3522" id="3522" class="graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Secure access (from nscale to other servers)</strong></p><p name="20a8" id="20a8" class="graf--p graf-after--p">To access all servers nscale will configure, it needs a new ssh key for secure authentication solution with no passphrase.</p><pre name="a3a3" id="a3a3" class="graf--pre graf-after--p">ssh-keygen -t rsa</pre><p name="0047" id="0047" class="graf--p graf-after--pre">Type no passphrase, and save it with your project name. In our case we called it lelyan-key (remember that the new ssh key needs to live in the nscale project root, not in ~/.ssh/). Once the ssh key is created, setup the public key in all the servers nscale needs to configure: <em class="markup--em markup--p-em">haproxy</em>, <em class="markup--em markup--p-em">mosca 1</em>, <em class="markup--em markup--p-em">mosca 2</em> and <em class="markup--em markup--p-em">redis</em>.</p><p name="7afd" id="7afd" class="graf--p graf-after--p">This can be done through the Digital Ocean dashboard or by adding the nscale public key to the <em class="markup--em markup--p-em">authorized_keys</em> with the following command.</p><pre name="061d" id="061d" class="graf--pre graf-after--p">cat lelylan-key.pub | \<br> ssh &lt;USER&gt;@&lt;IP-SERVER&gt; "cat ~/.ssh/authorized_keys"</pre><blockquote name="b987" id="b987" class="graf--blockquote graf-after--pre">If some problems occur, connect first to the server through SSH<br>ssh &lt;USER&gt;@&lt;IP-SERVER&gt;</blockquote><p name="4914" id="4914" class="graf--p graf-after--blockquote"><strong class="markup--strong markup--p-strong">SSH Agent Forwarding</strong></p><p name="169b" id="169b" class="graf--p graf-after--p">One more thing you need to do on your management server (where the nscale project is defined), is to set the <a href="https://developer.github.com/guides/using-ssh-agent-forwarding/" class="markup--anchor markup--p-anchor" rel="nofollow">SSH Agent Forwarding</a>. This allows you to use your local SSH keys instead of leaving keys sitting on your server.</p><pre name="bafb" id="bafb" class="graf--pre graf-after--p"># ~/.ssh/config<br>Host *<br> ForwardAgent yes</pre><blockquote name="99bf" id="99bf" class="graf--blockquote graf-after--pre">There is an <a href="https://github.com/nearform/nscale/issues/47" class="markup--anchor markup--blockquote-anchor" rel="nofollow">open issue</a> on this for nscale. If you do not set this up the deployment with nscale will not work out.</blockquote><p name="1515" id="1515" class="graf--p graf-after--h4">We can now start configuring nscale, starting from the nscale analyzer, which defines the authorizations settings used to access the target machines. To make this possible edit <em class="markup--em markup--p-em">~/.nscale/config/config.json</em> by setting the <em class="markup--em markup--p-em">specific</em> object from:</p><pre name="8a14" id="8a14" class="graf--pre graf-after--p">{<br> ...<br> "modules": {<br> ...<br> "analysis": {<br> "require": "nscale-local-analyzer",<br> "specific": {<br> }<br> }<br> ...<br>}</pre><p name="eb72" id="eb72" class="graf--p graf-after--pre">to:</p><pre name="bd44" id="bd44" class="graf--pre graf-after--p">{<br> ...<br> "modules": {<br> ...<br> "analysis": {<br> "require": "nscale-direct-analyzer",<br> "specific": {<br> <strong class="markup--strong markup--pre-strong">"user": "root",<br> "identityFile": "/root/lelylan/lelylan-key"</strong><br> }<br> }<br> }</pre><blockquote name="04c1" id="04c1" class="graf--blockquote graf-after--pre">Adjust this config if you named your project and your key differently.</blockquote><p name="3eff" id="3eff" class="graf--p graf-after--blockquote">All we did was to populate the <em class="markup--em markup--p-em">specific</em> object with the <em class="markup--em markup--p-em">user</em> (root) and the <em class="markup--em markup--p-em">identity file</em> (ssh key<em class="markup--em markup--p-em">) (</em>this step will likely not be needed in a next release).</p><p name="8d0a" id="8d0a" class="graf--p graf-after--h4">In nscale we can define different processes, where every process is a Docker container identified by a name, a Github repo (with the container source code) and a set of arguments Docker uses to run the image.</p><figure name="9128" id="9128" class="graf--figure graf--iframe graf-after--p" score="-13.75"></figure><blockquote name="9908" id="9908" class="graf--blockquote graf-after--figure">If you noticed that redis has not a Github repo, contgrats! At this point of the article shouldn&#x2019;t be easy&#x263A;. For Redis we do not need the Github repo as we directly use the redis image defined in Docker Hub.</blockquote><p name="b0bf" id="b0bf" class="graf--p graf-after--blockquote">In this case we have 3 different type of processes: <em class="markup--em markup--p-em">haproxy, mqtt </em>and<em class="markup--em markup--p-em"> redis.</em></p><p name="db0b" id="db0b" class="graf--p graf-after--h4">Now that we&#x2019;ve defined the processes we want to run, we can tell nscale where each of them should live on Digital Ocean through the <em class="markup--em markup--p-em">system.js </em>definition.</p><figure name="7800" id="7800" class="graf--figure graf--iframe graf-after--p" score="-13.75"></figure><p name="5efb" id="5efb" class="graf--p graf-after--figure">As you can see, <em class="markup--em markup--p-em">system.js</em> defines every machine setup. For each of them, we define the running processes (you need to use one between the ones previously defined in <em class="markup--em markup--p-em">services.js</em>), the machine IP address, the user that can log in and and the ssh key name used to authorize the access.</p><p name="d298" id="d298" class="graf--p graf-after--p"><strong class="markup--strong markup--p-strong">What if I want to add a new MQTT server</strong></p><p name="4524" id="4524" class="graf--p graf-after--p">Add a new machine to the nscale <em class="markup--em markup--p-em">system.js</em> definition, the new server to the HAproxy configuration and you&#x2019;re ready to go.</p><p name="215a" id="215a" class="graf--p graf-after--p"><strong class="markup--strong markup--p-strong">It&#x2019;s deploying time&#x263A;</strong></p><p name="cc43" id="cc43" class="graf--p graf-after--p">We can now compile, build and deploy our infrastructure.</p><pre name="ad4b" id="ad4b" class="graf--pre graf-after--p"># Compile the nscale project<br>nsd sys comp direct</pre><pre name="475e" id="475e" class="graf--pre graf-after--pre"># Build all containers<br># (grab a cup of coffee, while nscale build everything)<br>nsd cont buildall</pre><pre name="8098" id="8098" class="graf--pre graf-after--pre"># Deploy the latest revision on Digital Ocean<br>nsd rev dep head</pre><blockquote name="220e" id="220e" class="graf--blockquote graf-after--pre">While we described the configurations needed to deploy on Digital Ocean, nscale is also good to run all services locally.</blockquote><p name="4f47" id="4f47" class="graf--p graf-after--blockquote"><strong class="markup--strong markup--p-strong">You&#x2019;re done!</strong></p><p name="340c" id="340c" class="graf--p graf-after--p">Once the setup is done, with the previous three commands, we&#x2019;re ready to deploy an high availability MQTT cluster for the Internet of Things, adding new MQTT servers and scaling our infrastructure in a matter of minutes.</p><p name="a897" id="a897" class="graf--p graf-after--h2">This article comes from the work I&#x2019;ve made in Lelylan, an Open Source Cloud Platform for the Internet of Things. If you find this article useful, give us a star on <a href="https://github.com/lelylan/lelylan/" class="markup--anchor markup--p-anchor" rel="nofollow">Github</a> (it will help to reach more developers).</p><p name="face" id="face" class="graf--p graf-after--h4">In this article we showed how to build an high availability MQTT cluster for the Internet of Things. All of the code we use in production is now released as Open Source as follow.</p><ul class="postList"><li name="bc8d" id="bc8d" class="graf--li graf-after--p"><a href="https://github.com/lelylan/haproxy-mqtt" class="markup--anchor markup--li-anchor" rel="nofollow">Lelylan MQTT HAProxy</a> (TCP load balancer)</li><li name="ac4c" id="ac4c" class="graf--li graf-after--li"><a href="https://github.com/lelylan/mqtt" class="markup--anchor markup--li-anchor" rel="nofollow">Lelylan MQTT Server</a> (Mosca implementation)</li></ul><p name="70fd" id="70fd" class="graf--p graf-after--li">We&#x2019;ll soon release also the nscale project (right now it contains some sensible information and we need to remove them from the repo).</p><blockquote name="6c58" id="6c58" class="graf--blockquote graf-after--p">Many thanks to <a href="http://www.nearform.com/" class="markup--anchor markup--blockquote-anchor" rel="nofollow">nearForm</a> and <a href="http://www.matteocollina.com/" class="markup--anchor markup--blockquote-anchor" rel="nofollow">Matteo Collina</a> (author of Mosca and part of the nscale team) for helping us answering any question we had about nscale and the MQTT infrastructure.</blockquote><p name="51c7" id="51c7" class="graf--p graf-after--blockquote">Building, testing and securing such an infrastructure took several months of work. We really hope that releasing it as Open Source will help you guys on building MQTT platforms in a shorter time.</p><p name="8c2e" id="8c2e" class="graf--p graf-after--h4">Not satisfied? If you want to learn more about some of the topics we talked about, read out the following articles!</p></div></div></section></div>
</body></html>
