<!DOCTYPE html><html><head><title>Directed graph traversal, orderings and applications to data-flow analysis</title></head><body>
<h1>Directed graph traversal, orderings and applications to data-flow analysis</h1><p><a href="http://eli.thegreenplace.net/2015/directed-graph-traversal-orderings-and-applications-to-data-flow-analysis/" target="_new">Original URL</a></p>
<p><blockquote>October 16, 2015 at 05:45 Tags Programming , Python , Compilation When traversing trees with DFS, orderings are easy to define: we have pre-order, which visits a node before recursing into its&hellip;</blockquote></p>
<div><div class="entry-content">
 <div class="panel">
 <div class="panel-body">
<footer class="post-info">
 <span class="published">
 <i class="fa fa-calendar"></i>
 <time> October 16, 2015 at 05:45</time>
 </span>
<span class="label label-default">Tags</span>
 <a href="http://eli.thegreenplace.net/tag/programming">Programming</a>
 ,
 <a href="http://eli.thegreenplace.net/tag/python">Python</a>
 ,
 <a href="http://eli.thegreenplace.net/tag/compilation">Compilation</a>
</footer> </div>
 </div>
 <p>When traversing trees with DFS, orderings are easy to define: we have pre-order,
which visits a node before recursing into its children; in-order, which visits a
node in-between recursing into its children; post-order, which visits a node
after recursing into its children.</p>
<p>However, for directed graphs, these orderings are not as natural and slightly
different definitions are used. In this article I want to discuss the various
directed graph orderings and their implementations. I also want to mention some
applications of directed graph traversals to data-flow analysis.</p>
<p>Directed graphs are my focus here, since these are most useful in the
applications I'm interested in. When a directed graph is known to have no
cycles, I may refer to it as a DAG (directed acyclic graph). When cycles are
allowed, undirected graphs can be simply modeled as directed graphs where each
undirected edge turns into a pair of directed edges.</p>
<div class="section" id="depth-first-search-and-pre-order">
<h2>Depth-first search and pre-order</h2>
<p>Let's start with the basis algorithm for everything discussed in this article -
depth-first search (DFS). Here is a simple implementation of DFS in Python (the
full code is <a class="reference external" href="https://github.com/eliben/code-for-blog/blob/master/2015/traversals.py">available here</a>):</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">dfs</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="n">visitor</span><span class="p">):</span>
 <span class="sd">"""DFS over a graph.</span>

<span class="sd"> Start with node 'root', calling 'visitor' for every visited node.</span>
<span class="sd"> """</span>
 <span class="n">visited</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
 <span class="k">def</span> <span class="nf">dfs_walk</span><span class="p">(</span><span class="n">node</span><span class="p">):</span>
 <span class="n">visited</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
 <span class="n">visitor</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
 <span class="k">for</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">successors</span><span class="p">(</span><span class="n">node</span><span class="p">):</span>
 <span class="k">if</span> <span class="ow">not</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">:</span>
 <span class="n">dfs_walk</span><span class="p">(</span><span class="n">succ</span><span class="p">)</span>
 <span class="n">dfs_walk</span><span class="p">(</span><span class="n">root</span><span class="p">)</span>
</pre></div>
<p>This is the baseline implementation, and we'll see a few variations on it to
implement different orderings and algorithms. You may think that, due to the way
the algorithm is structured, it implements pre-order traversal. It certainly
looks like it. In fact, <em>pre-preder traversal on graphs is defined as the order
in which the aforementioned DFS algorithm visited the nodes</em>. However, there's a
subtle but important difference from tree pre-order. Whereas in trees, we may
assume that in pre-order traversal we always see a node before all its
successors, this isn't true for graph pre-order. Consider this graph:</p>
<img alt="Directed Graph" class="align-center" src="http://eli.thegreenplace.net/images/2015/dgraph1.png">
<p>If we print the nodes in the order visited by DFS, we may get something like: A,
C, B, D, E, T. So B comes before T, even though B is T's successor <a class="footnote-reference" href="http://eli.thegreenplace.net/2015/directed-graph-traversal-orderings-and-applications-to-data-flow-analysis/#id9" id="id1">[1]</a>.</p>
<p>We'll soon see that other orderings <em>do</em> provide some useful guarantees.</p>
</div>
<div class="section" id="post-order-and-reverse-post-order">
<h2>Post-order and reverse post-order</h2>
<p>To present other orderings and algorithms, we'll take the <tt class="docutils literal">dfs</tt> function above
and tweak it slightly. Here's a post-order walk. It has the same general
structure as <tt class="docutils literal">dfs</tt>, but it manages additional information (<tt class="docutils literal">order</tt> list) and
doesn't call a visitor function:</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">postorder</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">root</span><span class="p">):</span>
 <span class="sd">"""Return a post-order ordering of nodes in the graph."""</span>
 <span class="n">visited</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
 <span class="n">order</span> <span class="o">=</span> <span class="p">[]</span>
 <span class="k">def</span> <span class="nf">dfs_walk</span><span class="p">(</span><span class="n">node</span><span class="p">):</span>
 <span class="n">visited</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
 <span class="k">for</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">successors</span><span class="p">(</span><span class="n">node</span><span class="p">):</span>
 <span class="k">if</span> <span class="ow">not</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">:</span>
 <span class="n">dfs_walk</span><span class="p">(</span><span class="n">succ</span><span class="p">)</span>
 <span class="n">order</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
 <span class="n">dfs_walk</span><span class="p">(</span><span class="n">root</span><span class="p">)</span>
 <span class="k">return</span> <span class="n">order</span>
</pre></div>
<p>This algorithm adds a node to the <tt class="docutils literal">order</tt> list when its traversal is fully
finished; that is, when all its outgoing edges have been visited. Unlike
pre-order, here it's actually ensured - in the absence of cycles - that for two
nodes V and W, if there is a path from W to V in the graph, then V comes before
W in the list <a class="footnote-reference" href="http://eli.thegreenplace.net/2015/directed-graph-traversal-orderings-and-applications-to-data-flow-analysis/#id10" id="id2">[2]</a>.</p>
<p>Reverse post-order (RPO) is exactly what its name implies. It's the reverse of
the list created by post-order traversal. In reverse post-order, if there is a
path from V to W in the graph, V appears before W in the list. Note that this is
actually a useful guarantee - we see a node before we see any other nodes
reachable from it; for this reason, RPO is useful in many algorithms.</p>
<p>Let's see the orderings produced by pre-order, post-order and RPO for our sample
DAG:</p>
<ul class="simple">
<li>Pre-order: A, C, B, D, E, T</li>
<li>Post-order: D, B, E, C, T, A</li>
<li>RPO: A, T, C, E, B, D</li>
</ul>
<p>This example should help dispel a common confusion about these traversals - <em>RPO
is not the same as pre-order</em>. While pre-order is simply the order in which DFS
visits a graph, RPO actually guarantees that we see a node before all of its
successors (again, this is in the absence of cycles, which we'll deal with
later). So if you have an algorithm that needs this guarantee and you could
simply use pre-order on trees, when you're dealing with DAGs it's RPO, not
pre-order, that you're looking for.</p>
</div>
<div class="section" id="topological-sort">
<h2>Topological sort</h2>
<p>In fact, the RPO of a DAG has another name - <em>topological sort</em>. Indeed, listing
a DAG's nodes such that a node comes before all its successors is precisely what
sorting it topologically means. If nodes in the graph represent operations and
edges represent dependencies between them (an edge from V to W meaning that V
must happen before W) then topological sort gives us an order in which we can
run the operations such that all the dependencies are satisfied (no operation
runs before its dependencies).</p>
</div>
<div class="section" id="dags-with-multiple-roots">
<h2>DAGs with multiple roots</h2>
<p>So far the examples and algorithms demonstrated here show graphs that have a
single, identifiable root node. This is not always the case for realistic
graphs, though it <em>is</em> most likely the case for graphs used in compilation
because a program has a single entry function (for call graphs) and a function
has a single entry instruction or basic block (for control-flow and data-flow
analyses of functions).</p>
<p>Once we leave the concept of "one root to rule them all" behind, it's
not even clear how to traverse a graph like the example used in the article
so far. Why start from node A? Why not B? And how would the traversal look if we
did start from B? We'd then only be able to discover B itself and D, and would
have to restart to discover other nodes.</p>
<p>Here's another graph, where not all nodes are connected with each other. This
graph has no pre-defined root <a class="footnote-reference" href="http://eli.thegreenplace.net/2015/directed-graph-traversal-orderings-and-applications-to-data-flow-analysis/#id11" id="id3">[3]</a>. How do we still traverse all of it in a
meaningful way?</p>
<img alt="Directed Multigraph" class="align-center" src="http://eli.thegreenplace.net/images/2015/multidgraph1.png">
<p>The idea is a fairly simple modification of the DFS traversal shown earlier. We
pick an arbitrary unvisited node in the graph, treat it as a root and start
dutifully traversing. When we're done, we check if there are any unvisited nodes
remaining in the graph. If there are, we pick another one and restart. So on and
so forth until all the nodes are visited:</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">postorder_unrooted</span><span class="p">(</span><span class="n">graph</span><span class="p">):</span>
 <span class="sd">"""Unrooted post-order traversal of a graph.</span>

<span class="sd"> Restarts traversal as long as there are undiscovered nodes. Returns a list</span>
<span class="sd"> of lists, each of which is a post-order ordering of nodes discovered while</span>
<span class="sd"> restarting the traversal.</span>
<span class="sd"> """</span>
 <span class="n">allnodes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
 <span class="n">visited</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
 <span class="n">orders</span> <span class="o">=</span> <span class="p">[]</span>
 <span class="k">def</span> <span class="nf">dfs_walk</span><span class="p">(</span><span class="n">node</span><span class="p">):</span>
 <span class="n">visited</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
 <span class="k">for</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">successors</span><span class="p">(</span><span class="n">node</span><span class="p">):</span>
 <span class="k">if</span> <span class="ow">not</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">:</span>
 <span class="n">dfs_walk</span><span class="p">(</span><span class="n">succ</span><span class="p">)</span>
 <span class="n">orders</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
 <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">allnodes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">visited</span><span class="p">):</span>
 <span class="c"># While there are still unvisited nodes in the graph, pick one at random</span>
 <span class="c"># and restart the traversal from it.</span>
 <span class="n">remaining</span> <span class="o">=</span> <span class="n">allnodes</span> <span class="o">-</span> <span class="n">visited</span>
 <span class="n">root</span> <span class="o">=</span> <span class="n">remaining</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
 <span class="n">orders</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
 <span class="n">dfs_walk</span><span class="p">(</span><span class="n">root</span><span class="p">)</span>
 <span class="k">return</span> <span class="n">orders</span>
</pre></div>
<p>To demonstrate this approach, <tt class="docutils literal">postorder_unrooted</tt> returns not just a single
list of nodes ordered in post-order, but a list of lists. Each list is a
post-order ordering of a set of nodes that were visited together in one
iteration of the <tt class="docutils literal">while</tt> loop. Running on the new sample graph, I get this:</p>
<div class="highlight"><pre>[
 ['d', 'b', 'e', 'c'],
 ['j', 'f'],
 ['r', 'k'],
 ['p', 'q'],
 ['t', 'x']
]
</pre></div>
<p>There's a slight problem with this approach. While relative ordering between
entirely unconnected pieces of the graph (like K and and X) is undefined, the
ordering within each connected piece <em>may</em> be defined. For example, even though
we discovered T and X separately from D, B, E, C, there <em>is</em> a natural ordering
between them. So a more sophisticated algorithm would attempt to amend this by
merging the orders when that makes sense. Alternatively, we can look at all the
nodes in the graph, find the ones without incoming edges and use these as roots
to start from.</p>
</div>
<div class="section" id="directed-graphs-with-cycles">
<h2>Directed graphs with cycles</h2>
<p>Cycles in directed graphs present a problem for many algorithms, but there are
important applications where avoiding cycles is unfeasible, so we have to deal
with them. Here's a sample graph with a couple of cycles:</p>
<img alt="Directed Graph with cycles" class="align-center" src="http://eli.thegreenplace.net/images/2015/cycles.png">
<p>Cycles break almost all of the nice-and-formal definitions of traversals stated
so far in the article. In a graph with cycles, there is - by definition - no
order of nodes where we can say that one comes before the other. Nodes can be
visited before all their outgoing edges have been visited in post-order.
Topological sort is simply undefined on graphs with cycles.</p>
<p>Out post-order search will still <em>run</em> and terminate, visiting the whole graph,
but the order it will visit the nodes is just not as clearly defined. Here's
what we get from <tt class="docutils literal">postorder</tt>, starting with X as root:</p>
<div class="highlight"><pre>['m', 'g', 'd', 'e', 'c', 'b', 't', 'x']
</pre></div>
<p>This is a perfectly valid post-order visit on a graph with cycles, but something
about it bothers me. Note that M is returned before G and D. True, this is just
how it is with cycles <a class="footnote-reference" href="http://eli.thegreenplace.net/2015/directed-graph-traversal-orderings-and-applications-to-data-flow-analysis/#id12" id="id4">[4]</a>, but can we do better? After all, there's no actual
path from G and D to M, while a path in the other direction exists. So could
we somehow "approximate" a post-order traversal of a graph with cycles, such
that at least some high-level notion of order stays consistent (outside actual
cycles)?</p>
</div>
<div class="section" id="strongly-connected-components">
<h2>Strongly Connected Components</h2>
<p>The answer to the last question is yes, and the concept that helps us here is
<a class="reference external" href="https://en.wikipedia.org/wiki/Strongly_connected_component">Strongly Connected Components</a> (SCCs,
hereafter). A graph with cycles is partitioned into SCCs, such that every
component is strongly connected - every node within it is reachable from every
other node. In other words, every component is a loop in the graph; we can then
create a DAG of components <a class="footnote-reference" href="http://eli.thegreenplace.net/2015/directed-graph-traversal-orderings-and-applications-to-data-flow-analysis/#id13" id="id6">[5]</a>. Here's our loopy graph again, with the SCCs
identified. All the nodes that don't participate in loops can be considered as
single-node components of themselves:</p>
<img alt="Directed Graph with cycles and SCCs" class="align-center" src="http://eli.thegreenplace.net/images/2015/cycles-scc.png">
<p>Having this decomposition of the graph availabe, we can now once again run
meaningful post-order visits on the SCCs and even sort them topologically.</p>
<p>There are a number of efficient algorithms available for decomposing a graph
into SCCs; I will leave this topic to some other time.</p>
</div>
<div class="section" id="color-dfs-and-edge-classification">
<h2>3-color DFS and edge classification</h2>
<p>As we've seen above, while our <tt class="docutils literal">postorder</tt> function manages to visit all nodes
in a graph with cycles, it doesn't do it in a sensical order and doesn't even
detect cycles. We'll now examine a variation of the DFS algorithm that keeps
track of more information during traversal, which helps it analyze cyclic graphs
with more insight.</p>
<p>This version of graph DFS is actually something you will often find in books and
other references; it colors every node white, grey or black, depending on how
much traversal was done from it at any given time. This is why I call it the
"3-color" algorithm, as opposed to the basic "binary" or "2-color" algorithm
presented here earlier (any node is either in the "visited" set or not).</p>
<p>The following function implements this. The <tt class="docutils literal">color</tt> dict replaces the
<tt class="docutils literal">visited</tt> set and tracks three different states for each node:</p>
<ol class="arabic simple">
<li>Node not in the dict: not discovered yet ("white").</li>
<li>Node discovered but not finished yet ("grey")</li>
<li>Node is finished - all its outgoing edges were finished ("black")</li>
</ol>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">postorder_3color</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">root</span><span class="p">):</span>
 <span class="sd">"""Return a post-order ordering of nodes in the graph.</span>

<span class="sd"> Prints CYCLE notifications when graph cycles ("back edges") are discovered.</span>
<span class="sd"> """</span>
 <span class="n">color</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
 <span class="n">order</span> <span class="o">=</span> <span class="p">[]</span>
 <span class="k">def</span> <span class="nf">dfs_walk</span><span class="p">(</span><span class="n">node</span><span class="p">):</span>
 <span class="n">color</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="o">=</span> <span class="s">'grey'</span>
 <span class="k">for</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">successors</span><span class="p">(</span><span class="n">node</span><span class="p">):</span>
 <span class="k">if</span> <span class="n">color</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">succ</span><span class="p">)</span> <span class="o">==</span> <span class="s">'grey'</span><span class="p">:</span>
 <span class="k">print</span> <span class="s">'CYCLE: {0}--&gt;{1}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">succ</span><span class="p">)</span>
 <span class="k">if</span> <span class="n">succ</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">color</span><span class="p">:</span>
 <span class="n">dfs_walk</span><span class="p">(</span><span class="n">succ</span><span class="p">)</span>
 <span class="n">order</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
 <span class="n">color</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="o">=</span> <span class="s">'black'</span>
 <span class="n">dfs_walk</span><span class="p">(</span><span class="n">root</span><span class="p">)</span>
 <span class="k">return</span> <span class="n">order</span>
</pre></div>
<p>If we run it on the loopy graph, we get the same order as the one returned by
<tt class="docutils literal">postorder</tt>, with the addition of:</p>
<div class="highlight"><pre>CYCLE: m--&gt;c
CYCLE: g--&gt;d
</pre></div>
<p>The edges between M and C and between G and D are called <em>back edges</em>. This
falls under the realm of <em>edge classification</em>. In addition to back edges,
graphs can have tree edges, cross edges and forward edges. All of these can be
discovered during a DFS visit. Back edges are the most important for our current
discussion since they help us identify cycles in the graph.</p>
</div>
<div class="section" id="data-flow-analysis">
<h2>Data-flow analysis</h2>
<p><em>This section is optional if you only wanted to learn about graph graversals. It
assumes non-trivial background on compilation</em>.</p>
<p>In compilation, data-flow analysis is an important technique used for many
optimizations. The compiler analyzes the control-flow graph (CFG) of a program,
reasoning about how values can potentially change <a class="footnote-reference" href="http://eli.thegreenplace.net/2015/directed-graph-traversal-orderings-and-applications-to-data-flow-analysis/#id14" id="id7">[6]</a> through its basic blocks.</p>
<p>Without getting into the specifics of data-flow analysis problems and
algorithms, I want to mention a few relevant observations that bear strong
relation to the earlier topics of this post. Broadly speaking, there are two
kinds of data-flow problems: <em>forward</em> and <em>backward</em> problems. In <em>forward</em>
problems, we use information learned about basic blocks to analyze their
successors. In <em>backward</em> problems, it's the other way around - information
learned about basic blocks is used to analyze their predecessors.</p>
<p>Therefore, it shouldn't come as a surprise that the most efficient way to run
forward data-flow analyses is in RPO. In the absence of cycles, RPO (topological
order) makes sure we've seen all of a node's predecessors before we get
to it. This means we can perform the analysis in a single pass over the graph.</p>
<p>With cycles in the graph, this is no longer true, but RPO still guarantees the
fastest convergence - in graphs with cycles data-flow analysis is iterative
until a fixed point is reached <a class="footnote-reference" href="http://eli.thegreenplace.net/2015/directed-graph-traversal-orderings-and-applications-to-data-flow-analysis/#id15" id="id8">[7]</a>.</p>
<p>For a similar reason, the most efficient way to run backward data-flow analysis
is post-order. In the absence of cycles, postorder makes sure that we've seen
all of a node's successors before we get to it.</p>
<p>One final note: some resources recommend to use RPO on a reverse CFG (CFG with
all its edges inverted) instead of post-order on the original graph for backward
data-flow. If your initial reaction is to question whether the two are
equivalent - that's not a bad guess, though it's wrong. With cycles, the two
orders can be subtly different. Consider this graph, for example:</p>
<img alt="ABCD graph" class="align-center" src="http://eli.thegreenplace.net/images/2015/abcd_graph.png">
<p>Assuming A is the entry node, post-order would return: D, C, B, A. Now let's
invert all the edges:</p>
<img alt="ABCD graph with inverted nodes" class="align-center" src="http://eli.thegreenplace.net/images/2015/abcd_graph_rev.png">
<p>Here D would be the entry node. RPO on this graph is: D, B, C, A. This is
not the same as post-order on the original graph - the order of the nodes in
the cycle is different.</p>
<p>So here's a puzzle: why is RPO on the reverse graph recommended by some
resources over post-order?</p>
<p>If I had to guess, I'd say that looking at the sample graph in this section,
it makes some sense to examine B before C, because more of its successors were
already visited. If we visit C before B, we don't know much about successors yet
because B wasn't visited - and B is the only successor of C. But if we visit B
before C, at least D (a successor of B in the original graph) was already
visited. This may help faster convergence. If you have additional ideas, please
let me know.</p>








</div>

 </div>
 

 </div>
</body></html>
