<!DOCTYPE html><html><head><title>Setting Up Your Own PaaS and CI/CD Pipeline</title></head><body>
<h1>Setting Up Your Own PaaS and CI/CD Pipeline</h1><p><a href="https://deis.com/blog/2016/paas-continuous-integration-deployment" target="_new">Original URL</a></p>
<p><blockquote>Docker and the ecosystem around it have done some great things for developers, but from an operational standpoint, it's mostly just the same old issues with a fresh coat of paint. Real change happens&hellip;</blockquote></p>
<div><article>
 <p>Docker and the ecosystem around it have done some great things for developers, but from an operational standpoint, it's mostly just the same old issues with a fresh coat of paint. Real change happens when we change our perspective from <em>Infrastructure</em> (as a Service) to <em>Platform</em> (as a Service), and when the ultimate deployment artifact is a running application instead of a virtual machine.</p>

<p>Even Kubernates still feels a lot like IaaS - just with containers instead of virtual machines. To be fair, there are already some platforms out there that shift the user experience towards the application (Cloud Foundry and Heroku come to mind), but many of them have a large operations burden, or are provided in a SaaS model only.</p>

<p>In the Docker ecosystem we are starting to see more of these types of platforms, the first of which was <a href="https://github.com/progrium/dokku">Dokku</a> which started as a single machine <a href="http://heroku.com">Heroku</a> replacement written in about 100 lines of Bash. Building on top of that work other, richer systems like <a href="http://Deis.io">Deis</a> and <a href="http://flynn.io">Flynn</a> have emerged, as well as custom solutions built in-house, like Yelp's <a href="https://github.com/Yelp/PaaSta">PaaSta</a>.</p>

<p>Actions speak louder than words, so I decided to document (and demonstrate) a platform built from the ground up (using Open Source projects) and then deploy an application to it via a Continuous Integration/Deployment (CI/CD) pipeline.</p>

<p>You could (and probably would) use a public cloud provider for some (or all) of this stack; however, I wanted to demonstrate that a system like this can be built and run internally, as not everybody is able to use the public cloud.</p>

<a name="read-more" class="read-more-anchor"></a>

<p>As I wrote this I discovered that while figuring out the right combination of tools to run was a fun process, the really interesting stuff was building the actual CI/CD pipeline to deploy and run the application itself. This means that while I'll briefly describe the underlying infrastructure, I will not be providing a detailed installation guide.</p>

<h2>Infrastructure</h2>

<p>While an IaaS is not strictly necessary here (I could run Deis straight on bare metal), it makes sense to use something like <a href="http://www.openstack.org/">OpenStack</a> as it provides the ability to request services via API and use tooling like <a href="https://terraform.io/">Terraform</a>. I installed OpenStack across across a set of physical machines using <a href="https://www.blueboxcloud.com/">Blue Box's</a> <a href="https://github.com/blueboxgroup/ursula">Ursula</a>.</p>

<p>Next the PaaS itself. I have familiarity with <a href="http://Deis.io/">Deis</a> already and I really like its (Heroku-esque) user experience. I deployed a three node Deis cluster on OpenStack using the <a href="https://terraform.io/">Terraform</a> instructions <a href="https://github.com/paulczar/Deis/tree/openstack_provision_script/contrib/openstack">here</a>.</p>

<p>I also deployed an additional three <a href="https://coreos.com">CoreOS</a> nodes using <a href="https://terraform.io/">Terraform</a> on which I ran <a href="http://jenkins-ci.org/">Jenkins</a> using the standard <a href="https://hub.docker.com/_/jenkins/">Jenkins Docker image</a>.</p>

<p>Finally, there is a three-node Percona database cluster running on the CoreOS nodes, itself fronted by a load balancer, both of which use <a href="https://coreos.com/etcd/">etcd</a> for auto-discovery. Docker images are available for both the <a href="https://github.com/paulczar/docker-percona_galera">cluster</a> and the <a href="https://hub.docker.com/r/paulczar/maxscale/">load balancer</a>.</p>

<h2>Ghost</h2>

<p>The application I chose to demo is the <a href="https://ghost.org/download/">Ghost blogging platform</a>. I chose it because it's a fairly simple app with well-known backing service (MySQL). The source, including my <code>Dockerfile</code> and customizations, can be found in the <a href="https://github.com/paulczar/ci-demo">paulczar/ci-demo</a> GitHub repository.</p>

<p>The hostname and database credentials of the MySQL load balancer are passed into Ghost via <a href="http://12factor.net/config">environment variables</a> (injected by Deis) to provide a suitable database <a href="http://12factor.net/backing-services">backing service</a>.</p>

<p>For development, I wanted to follow the <a href="https://guides.github.com/introduction/flow/">GitHub Flow</a> methodology as much as possible. My merge/deploy steps are a bit different, but the basic flow is the same. This allows me to use GitHub's notification system to trigger Jenkins jobs when Pull Requests are created or merged.</p>

<p>I used the Deis CLI to create two applications: <a href="http://ghost.ci-demo.paulcz.net">ghost</a> from the code in the <code>master</code> branch, and <a href="http://stage-ghost.ci-demo.paulcz.net">stage-ghost</a> from the code in the <code>development</code> branch. These are my <code>production</code> and <code>staging</code> environments, respectively.</p>

<p>Both the <code>development</code> and <code>master</code> branches are protected with GitHub settings that restrict changes from being pushed directly to the branch. Furthermore, any Pull Requests need to pass tests before they can be merged.</p>

<h2>Deis</h2>

<p>Deploying applications with Deis is quite easy and very similar to deploying applications to Heroku. As long as your git repo has a <code>Dockerfile</code> (or supports being discovered by the <a href="https://devcenter.heroku.com/articles/cedar">cedar</a> tooling), Deis will figure out what needs to be done to run your application.</p>

<p>Deploying an application with Deis is incredibly simple:</p>

<ol>
<li> First you use <code>deis create</code> to create an application (on success the Deis CLI will add a remote git endpoint).</li>
<li> Then you run <code>git push deis master</code> which pushes your code and triggers Deis to build and deploy your application.</li>
</ol>
<figure class="highlight"><pre><code class="language-text">$ git clone https://github.com/deis/example-go.git
$ cd example-go
$ deis login http://deis.xxxxx.com
$ deis create helloworld 
Creating Application... ...
done, created helloworld
Git remote deis added
$ git push deis master

Counting objects: 39, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (38/38), done.
Writing objects: 100% (39/39), 5.17 KiB | 0 bytes/s, done.
Total 39 (delta 12), reused 0 (delta 0)

-----&gt; Building Docker image
remote: Sending build context to Docker daemon 5.632 kB
&lt;&lt;&lt;&lt;&lt;&lt;&lt; SNIP &gt;&gt;&gt;&gt;&gt;&gt;&gt;
-----&gt; Launching... 
 done, helloworld:v2 deployed to Deis
 http://helloworld.ci-demo.paulcz.net
</code></pre></figure>
<h2>Jenkins</h2>

<p>After running the Jenkins Docker container I had to do a few things to prepare it:</p>

<ol>
<li> Run <code>docker exec -ti jenkins bash</code> to enter the container and install the Deis CLI tool and run <code>deis login</code> which saves a session file so that I don't have to login on every job.</li>
<li> Add the <a href="https://github.com/janinko/ghprb">GitHub Pull Request Builder</a> (GHPRB) plugin.</li>
<li> Secure it with a password.</li>
<li> Run <code>docker commit</code> to commit the state of the Jenkins container.</li>
</ol>

<p>I also had to create the jobs to perform the actual work. The GHPRB plugin made this fairly simple and most of the actual jobs were variations of the same script:</p>
<figure class="highlight"><pre><code class="language-text">#!/bin/bash

APP="ghost"
git checkout master

git remote add deis ssh://git@deis.ci-demo.paulcz.net:2222/${APP}.git
git push deis master | tee deis_deploy.txt
</code></pre></figure>
<h2>Continuous Integration / Deployment</h2>

<h3>Local Development</h3>

<p>Docker's <code>docker-compose</code> is a great tool for quickly building development environments (combined with Docker Machine it can deploy locally, or to the cloud of your choice). I have placed a <code>docker-compose.yml</code> file in the git repo to launch a <code>mysql</code> container for the database, and a <code>ghost</code> container:</p>
<figure class="highlight"><pre><code class="language-text">ghost:
 build: .
 ports:
 - 5000:5000
 volumes:
 - .:/ghost
 environment:
 URL: http://localhost:5000
 DB_USER: root
 DB_PASS: ghost
 links:
 - mysql
mysql:
 image: percona
 ports:
 - "3306:3306"
 environment:
 MYSQL_ROOT_PASSWORD: ghost
 MYSQL_DATABASE: ghost
</code></pre></figure>
<p>I also included an <code>aliases</code> file with some useful aliases for common tasks:</p>
<figure class="highlight"><pre><code class="language-text">alias dc="docker-compose"
alias npm="docker-compose run --rm --no-deps ghost npm install --production"
alias up="docker-compose up -d mysql &amp;&amp; sleep 5 &amp;&amp; docker-compose up -d --force-recreate ghost"
alias test="docker run -ti --entrypoint='sh' --rm test /app/test"
alias build="docker-compose build"
</code></pre></figure>
<p>Running the development environment locally is as simple as cloning the repo and calling a few commands from the <code>aliases</code> file. The following examples show how I added <a href="https://www.npmjs.com/package/ghost-s3-storage">s3 support for storing images</a>:</p>
<figure class="highlight"><pre><code class="language-text">$ git clone https://github.com/paulczar/ci-demo.git
$ cd ci-demo
$ . ./aliases
$ npm
&gt; sqlite3@3.0.8 install /ghost/node_modules/sqlite3
&gt; node-pre-gyp install --fallback-to-build
...
...
$ docker-compose run --rm --no-deps ghost npm install --save ghost-s3-storage
ghost-s3-storage@0.2.2 node_modules/ghost-s3-storage
&#x251C;&#x2500;&#x2500; when@3.7.4
&#x2514;&#x2500;&#x2500; aws-sdk@2.2.17 (xmlbuilder@0.4.2, xml2js@0.2.8, sax@0.5.3)
$ up
</code></pre></figure>
<p>Docker Compose v1.5 allows variable substitution so I can pull AWS credentials from environment variables which means they don't need to be saved to git and each dev can use their own bucket etc. This is done by simply adding these lines to the <a href="https://github.com/paulczar/ci-demo/blob/development/docker-compose.yml">docker-compose.yml</a> file in the <code>environment</code> section:</p>
<figure class="highlight"><pre><code class="language-text">ghost:
 environment:
 S3_ACCESS_KEY_ID: ${S3_ACCESS_KEY_ID}
 S3_ACCESS_KEY: ${S3_ACCESS_KEY}
</code></pre></figure>
<p>I then added the appropriate environment variables to my shell and ran <code>up</code> to spin up a local development environment of the application. Once it was running I was able to confirm that the plugin was working by uploading the following image to the s3 bucket via the Ghost image upload mechanism:</p>

<p><img src="https://deis.com/images/blog-images/paas-ci-ghost_blog-1447652183265.png" alt=""></p>

<h3>Pull Request</h3>

<p>All new work is done in feature branches. Pull Requests are made to the <code>development</code> branch of the git repo which Jenkins watches using the github pull request plugin (GHPR). The development process looks a little something like this:</p>
<figure class="highlight"><pre><code class="language-text">$ git checkout -b s3_for_images
Switched to a new branch 's3_for_images'
</code></pre></figure>
<p><a href="https://github.com/paulczar/ci-demo/commit/90afc7ae266343709d7daed40a5f49de862905c5">Here</a> I added the s3 module and edited the appropriate sections of the Ghost code. Following the GitHub flow I then created a Pull Request for this new feature.</p>
<figure class="highlight"><pre><code class="language-text">$ git add .
$ git commit -m 'use s3 to store images'
[s3_for_images 55e1b3d] use s3 to store images
 8 files changed, 170 insertions(+), 2 deletions(-)
 create mode 100644 content/storage/ghost-s3/index.js
$ git push origin s3_for_images 
Counting objects: 14, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (12/12), done.
Writing objects: 100% (14/14), 46.57 KiB | 0 bytes/s, done.
Total 14 (delta 5), reused 0 (delta 0)
To git@github.com:paulczar/ci-demo.git
 articles _articles bin CAs devops Documents dotfiles gethtml go hnews jason js netdata start-thesrc thesrc ucii [new branch] s3_for_images -&gt; s3_for_images
</code></pre></figure>
<p><img src="https://deis.com/images/blog-images/paas-ci-github_show_pr_testing-1448031318823.png" alt=""></p>

<p>Jenkins will be notified when a developer opens a new Pull Request against the development branch and will kick off tests. Jenkins will then create and deploy an ephemeral application in Deis named for the Pull Request ID (PR-11-ghost).</p>

<p><img src="https://deis.com/images/blog-images/paas-ci-jenkins_pr_testing-1448031335825.png" alt=""></p>

<p>The ephemeral environment can be viewed at http://pr-xx-ghost.ci-demo.paulczar.net by anyone wishing to review the Pull Request. Subsequent updates to the PR will update the deployed application.</p>

<p>We can run some manual tests specific to the feature being developed (such as uploading photos) once the URL to the ephemeral application is live.</p>

<h4>Staging</h4>

<p>Jenkins will see that a Pull Request is merged into the development branch and will perform two jobs:</p>

<ol>
<li> Delete the <code>ephemeral</code> environment for Pull Request as it is no longer needed.</li>
<li> Create and deploy a new release of the contents of the <code>development</code> branch to the <code>staging</code> environment in Deis (http://stage-ghost.ci-demo.paulczar.net).</li>
</ol>

<p><img src="https://deis.com/images/blog-images/paas-ci-ci_staging_deploy-1448031350720.png" alt=""></p>

<p><img src="https://deis.com/images/blog-images/paas-ci-stage_ghost-1448031723495.png" alt=""></p>

<p><em>Originally when I started building this demo I had assumed that being able to perform actions on PR merges/closes would be simple, but I quickly discovered that <strong>none of the CI tools, that I could find, supported performing actions on PR close</strong>. Thankfully I was able to find a useful <a href="http://chloky.com/github-json-payload-in-jenkins/">blog</a> post that described how to set up a custom job with a webhook that could process the GitHub payload.</em></p>

<h4>Production</h4>

<p>Promoting the build from <code>staging</code> to <code>production</code> is a two step process:</p>

<ol>
<li><p>The user who wishes to promote it creates a pull request from the development branch to the master branch. Jenkins will see this and kick off some final tests.</p>

<p><img src="https://deis.com/images/blog-images/paas-ci-PR_to_master-1448031582932.png" alt=""></p></li>
<li><p>Another user then has to merge that pull request which will fire off a Jenkins job to push the code to Deis which cuts a new release and deploys it to the <code>production</code> environment (http://ghost.ci-demo.paulczar.net).</p>

<p><img src="https://deis.com/images/blog-images/paas-ci-ci_prod_deploy-1448031629520.png" alt=""></p></li>
</ol>

<h2>Conclusion</h2>

<p>Coming from an operations background, I thought that figuring out how to build and run a PaaS from the metal up would be a really interesting learning exercise. It was! What I didn't expect to discover, however, was that actually running an application on that PaaS would be so compelling. Figuring out the development workflow and CI/CD pipeline was an eye-opener as well.</p>

<p>That said, the most interesting outcome of this exercise was increased empathy: the process of building and using this platform placed me directly in the shoes of the very developers I support. It further demonstrated that by changing the focus of the user experience to that person's core competency (the operator running the platform, and the developer using the platform) we allow the developer to "own" their application in production without them needing to worry about VMs, firewall rules, config management code, etc.</p>

<p>I also (re-)learned that while many of us default to cloud services such as AWS, Heroku, and Travis CI, there are solid alternatives that can be run in-house. I was also somewhat surprised at how powerful (and simple) Jenkins can be (even if it is still painful to automate).</p>

<p><em>This post <a href="http://sysadvent.blogspot.com/2015/12/day-16-merry-paasmas-and-very.html">originally appeared</a> on the <a href="http://sysadvent.blogspot.com/">Sysadvent blog</a>, and was edited by <a href="https://twitter.com/phrawzty">Dan Phrawzt</a>.</em></p>

 </article>
 </div>
</body></html>
