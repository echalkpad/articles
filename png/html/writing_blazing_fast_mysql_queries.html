<!DOCTYPE html><html><head><title>Writing Blazing Fast MySQL Queries</title></head><body>
<h1>Writing Blazing Fast MySQL Queries</h1><p><a href="http://code.tutsplus.com/tutorials/writing-blazing-fast-mysql-queries--cms-25085" target="_new">Original URL</a></p>
<p><blockquote>The differences between well written SQL and not are vast, and in production on a high-demand site they cause serious repercussions in performance and reliability of service. In this guide I will&hellip;</blockquote></p>
<div><div class="post-body__content"><p>The differences between well written SQL and not are vast, and in production on a high-demand site they cause serious repercussions in performance and reliability of service. In this guide I will discuss how to write fast queries and what factors contribute to making them run slow.</p>

<h2>Why MySQL?</h2>
<p>Today there is a lot of talk about Big Data and new technologies. NoSQL and cloud-based solutions are great, but a lot of popular web software (such as WordPress, phpBB, Drupal, VBulletin Forum software, etc.) still runs on MySQL. Migration to these newer solutions may not be as simple as just optimizing the configuration you already have in production. Besides, the performance of MySQL is very good, especially the <a href="https://www.percona.com/">Percona version</a>.</p>

<p>Don&#x2019;t make the common mistake of throwing more and more computing power at dealing with the problem of slow queries and high server loads, rather than actually addressing the root underlying issues. Adding CPU power, SSDs or RAM is a form of optimization if you like, but it&#x2019;s not what I will be talking about here. Also, without an optimized site, as you grow with the hardware gains the issues will multiply exponentially. So it is not a solid long-term solution.</p>

<p>Being good at SQL is always a vital tool for a web developer, and with the fix being often as simple as just adding an index or slightly modifying how the table is being used, it really does help to know how to use your RDBMS well. In this case we are focusing on a popular open-source database often used in conjunction with PHP, and that is MySQL.</p>

<h3>Who&#x2019;s This Guide For?</h3>
<p>Web developers, Database Architects / DBAs and System Administrators that are familiar with MySQL. If you are not familiar with MySQL as a newbie, then this guide is most probably not going to make much sense, but I will try to keep it as informative as possible for newcomers to MySQL.</p>

<h3>Back Up First</h3>
<p>I recommend trying the steps provided on your own MySQL database (back up everything first of course!). If you don&#x2019;t have any database to work on, example create database schemas are provided where applicable.</p>

<p>Backing up MySQL is easy with the <code class="inline">mysqldump</code> command line utility:</p>

<pre class="brush: bash noskimlinks noskimwords">$ mysqldump myTable &gt; myTable-backup.sql
</pre>

<p>You can learn <a href="https://dev.mysql.com/doc/refman/5.1/en/mysqldump.html">more about mysqldump</a>.</p>

<h3>What Makes a Query Slow?</h3>
<p>In brief and in no order of importance, the following all play significant factors in query and server performance:</p>

<ul>
 <li>table indexes</li>
 <li>
<code class="inline">Where</code> clause (and usage of internal MySQL functions such as <code class="inline">IF</code> and <code class="inline">DATE</code> for example)</li>
 <li>sorting with <code class="inline">Order By</code>
</li>
 <li>frequency of concurrent requests</li>
 <li>storage engine type (InnoDB, MyISAM, Memory, Blackhole)</li>
 <li>not using Percona edition</li>
 <li>server configuration variables (tuning my.cnf / my.ini)</li>
 <li>large result sets (&gt;1,000 rows)</li>
 <li>non-persistent connections</li>
 <li>sharding / cluster configuration</li>
 <li>poor table design</li>
</ul>

<p>We will address all of these areas within this guide. Also, if you are not already using it, please install <a href="https://www.percona.com/software/mysql-database/percona-server">Percona</a>, which is a drop-in replacement for MySQL that will bring a serious performance increase. To see a benchmark of Percona vs. MySQL, look at <a href="https://www.percona.com/software/mysql-database/percona-server/benchmarks">this comparison</a>.</p>

<h3>What Are Indexes?</h3>
<p>Indexes are used by MySQL to find rows with specific column values quickly, for example inside a <code class="inline">WHERE</code>. Without an index, MySQL must begin with the first row and then read through the entire table to find the relevant rows. The larger the table, the more this costs.</p>

<p>If the table has an index for the columns in question, MySQL can quickly determine the position to seek to in the middle of the data file without having to look at all the data. This is much faster than reading every row sequentially.</p>

<h2>Non-Persistent Connections?</h2>
<p>When your scripting language connects with the database, if you have configured persistent connections then it will be able to re-use an existing connection without having to create a new one. This is optimal for production usage and must be enabled.</p>

<p>PHP users can read more in the <a href="http://php.net/manual/en/features.persistent-connections.php">PHP Manual</a>.</p>

<h3>Reducing the Frequency of Concurrent Requests</h3>
<p>The fastest, most effective way I have found to fix this is via utilising a key-value pair store such as <code class="inline">Memcached</code> or <code class="inline">Redis</code>.</p>

<p>With <code class="inline">Memcache</code> you can simply cache your query contents with the following, for example:</p>

<pre class="brush: php noskimlinks noskimwords">&lt;?php
$cache = new Memcache;
$cache-&gt;connect('localhost',11211);
$cacheResult = $cache-&gt;get('key-name');
if($cacheResult){
 //.. no need to query
 $result = $cacheResult;
} else {
	//.. run your query
 $mysqli = mysqli('p:localhost','username','password','table'); //prepend p: to hostname for persistancy
 $sql = 'SELECT articles _articles bin CAs devops Documents dotfiles gethtml go hnews jason js netdata start-thesrc thesrc ucii FROM posts 
 		LEFT JOIN userInfo using (UID) WHERE posts.post_type = 'post' || posts.post_type = 'article' 
 ORDER BY column LIMIT 50';
 $result = $mysqli-&gt;query($sql);
 $memc-&gt;set('key-name', $result-&gt;fetch_array(), MEMCACHE_COMPRESSED,86400);
}

//Pass the $cacheResult to template
$template-&gt;assign('posts', $cacheResult);

?&gt;
</pre>

<p>Now the example <code class="inline">LEFT JOIN</code> query will only be run once every 86,400 seconds (24 hours), thus taking a huge amount of load away from the MySQL server and reducing the concurrent connections.</p>

<p>Note: Prepend <code class="inline">p:</code> to your host argument in MySQLi for persistent connections.</p>

<h3>Sharding / Clustering</h3>
<p>When your data gets big or demand for your service ramps up, panic can set in. A quick fix to ensure your service stays online can be sharding. But I do not recommend that, because sharding inherently seems to make data structures overly complicated. And as explained very eloquently in this <a href="https://www.percona.com/blog/2009/08/06/why-you-dont-want-to-shard/">article from the Percona blog</a>, <em>don&#x2019;t shard.</em></p>

<h3>Poor Table Design</h3>
<p>Creating database schemas isn&#x2019;t too hard when you accept some golden rules, such as working with the limitations and being aware of what will be efficient. Storing images in the database as <code class="inline">blob</code> datatypes, for example, is highly discouraged; storing a filename in a <code class="inline">varchar</code> datatype column is far superior.</p>

<p>Ensuring that the design is correct for the required usage is paramount in creating your app. Keep specific data separated (e.g. categories and posts) and ensure many-to-one or one-to-many relationships can be easily linked with IDs. Utilising the <code class="inline">FOREIGN KEY</code> facility of MySQL is ideal for cascading data contingency between tables.</p>

<p>When building your table, try to remember the following:</p>

<ul>
 <li>Use the minimum you need to get the job done; be sparse and to the point.</li>
 <li>Don&#x2019;t expect MySQL to do your business logic or be programmatic&#x2014;that should be done really before insertion by your scripting language. For example, if you need to randomise a list, do the randomisation of an array in PHP, not in an <code class="inline">ORDER BY</code> in MySQL.</li>
 <li>Use a <code class="inline">UNIQUE</code> index type for unique datasets and utilise <code class="inline">ON DUPLICATE KEY UPDATE</code> to keep a datetime or unix timestamp updated for example of the last time the row was checked.</li>
 <li>Use an <code class="inline">INT</code> datatype for integer numericals. If you don&#x2019;t specify the length, MySQL will calculate what is required itself.</li>
</ul>

<h2>The Fundamentals of Optimization</h2>
<p>To effectively optimize, we must look at three fundamental data sets regarding your application:</p>

<ol>
 <li>Analysis (slow query logging, auditing, query and table design analysis)</li>
 <li>Performance requirements (how many users, what is the demand)</li>
 <li>Constraints of technology (hardware speed, asking too much of MySQL)</li>
</ol>

<p>Analysis can be done in several ways. Firstly we will take the most direct route to looking under the bonnet of MySQL queries. The first tool in your optimization toolbox is <code class="inline">EXPLAIN</code>. Utilising this in your query prior to the <code class="inline">SELECT</code> will give you the following output:</p>

<pre class="brush: sql noskimlinks noskimwords">mysql&gt; EXPLAIN SELECT articles _articles bin CAs devops Documents dotfiles gethtml go hnews jason js netdata start-thesrc thesrc ucii FROM `wp_posts` WHERE `post_type`='post';
+----+-------------+----------+------+------------------+------------------+---------+-------+------+-------------+
| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |
+----+-------------+----------+------+------------------+------------------+---------+-------+------+-------------+
| 1 | SIMPLE | wp_posts | ref | type_status_date | type_status_date | 82 | const | 2 | Using where |
+----+-------------+----------+------+------------------+------------------+---------+-------+------+-------------+
1 row in set (0.00 sec)
</pre>

<p>The columns listed each hold useful information about the query being executed. The columns you need to pay close attention to are <code class="inline">possible_keys</code> and <code class="inline">Extra</code>.</p>

<p><code class="inline">possible_keys</code> will display the indexes that the MySQL engine has available to use for the query. Sometimes you need to force an index to ensure the query is executed in the fastest manner.</p>

<p>The <code class="inline">Extra</code> column will show whether a conditional <code class="inline">WHERE</code> or <code class="inline">ORDER BY</code> was used. Most important to note is if <code class="inline">Using Filesort</code> appears. Consider the following example:</p>

<pre class="brush: sql noskimlinks noskimwords">EXPLAIN SELECT main_text
FROM posts
WHERE user = 'myUsername' &amp;&amp;
status = '1' &amp;&amp; (
 status_spam_user = 'no_spam'
 || (
 status_spam_user = 'neutral' &amp;&amp;
 status_spam_system = 'neutral'
 )
)
ORDER BY datum DESC
LIMIT 6430 , 10
</pre>

<p>This type of query can get to disk because of the conditional where, which is happening if we look at the <code class="inline">EXPLAIN</code>:</p>

<pre class="brush: sql noskimlinks noskimwords">id select_type table type possible_keys key key_len ref rows Extra
1 SIMPLE posts ref index_user,index_status index_user 32 const 7800 Using where; Using filesort
</pre>

<p>So this query has the possibility to use two indexes and currently it is hitting disk because of the <code class="inline">Using filesort</code> in the <code class="inline">Extra</code>.</p>

<p>What <code class="inline">Using Filesort</code> is doing is defined here from the MySQL manual:</p>

<blockquote>
 <p>&#x201C;MySQL must do an extra pass to find out how to retrieve the rows in sorted order. The sort is done by going through all rows according to the join type and storing the sort key and pointer to the row for all rows that match the WHERE clause. The keys then are sorted and the rows are retrieved in sorted order.&#x201D;</p>
</blockquote>

<p>This extra pass will slow your app up and must be avoided at all costs. Another crucial <code class="inline">Extra</code> result to avoid is <code class="inline">Using temporary</code>, which means MySQL had to create a temporary table for the query. Obviously this is a hideous usage of MySQL and must be avoided at all costs unless you cannot optimize any further due to the data requirements. In this case the query should be cached in Redis or Memcache and not run by the users.</p>

<p>To fix the problem with <code class="inline">Using Filesort</code> we must ensure MySQL uses an <code class="inline">INDEX</code>. It has several <code class="inline">possible_keys</code> to choose from, but MySQL can only use one index in the final query. Although Indexes can be composites of several columns, the inverse is not true, although you can provide hints to the MySQL optimizer as to which indexes you have created.</p>

<h3>Index Hints</h3>
<p>MySQL&#x2019;s optimizer will use statistics based on the queries&#x2019; tables to select the best index for the scope of the query. It does so based on its built-in optimizer&#x2019;s statistical logic, although with multiple choices this cannot always be correct without hinting. To ensure the correct key is used (or not used), utilize the <code class="inline">FORCE INDEX</code>, <code class="inline">USE INDEX</code> and <code class="inline">IGNORE INDEX</code> keywords in your query. You can read more about index hinting in the <a href="http://dev.mysql.com/doc/refman/5.1/en/index-hints.html">MySQL manual</a>.</p>

<p>To look at the table keys, use the command <code class="inline">SHOW INDEX</code>.</p>

<p>You can specify multiple hints for the optimizer to use, for example:</p>

<pre class="brush: sql noskimlinks noskimwords">SELECT articles _articles bin CAs devops Documents dotfiles gethtml go hnews jason js netdata start-thesrc thesrc ucii FROM table1 USE INDEX (col1_index,col2_index)
 WHERE col1=1 AND col2=2 AND col3=3;
 ```
 
Running an `EXPLAIN` will show you which index was used in the final outcome. So to fix the previous example we will add the `USE INDEX` as so:

```sql
EXPLAIN SELECT main_text
FROM posts USE INDEX (index_user)
WHERE user = 'myUsername' &amp;&amp;
status = '1' &amp;&amp; (
 status_spam_user = 'no_spam'
 || (
 status_spam_user = 'neutral' &amp;&amp;
 status_spam_system = 'neutral'
 )
)
ORDER BY datum DESC
LIMIT 6430 , 10
</pre>

<p>Now that MySQL has the <code class="inline">index_status</code> from the table to use, the query is fixed.</p>

<pre class="brush: sql noskimlinks noskimwords">id select_type table type possible_keys key key_len ref rows Extra
1 SIMPLE posts ref index_user,index_status index_user 32 const 7800 Using where
</pre>

<p>Alongside <code class="inline">EXPLAIN</code> is the <code class="inline">DESCRIBE</code> keyword. With <code class="inline">DESCRIBE</code> you can view a table&#x2019;s information as follows:</p>

<pre class="brush: sql noskimlinks noskimwords">mysql&gt; DESCRIBE City;
+------------+----------+------+-----+---------+----------------+
| Field | Type | Null | Key | Default | Extra |
+------------+----------+------+-----+---------+----------------+
| Id | int(11) | NO | PRI | NULL | auto_increment |
| Name | char(35) | NO | | | |
| Country | char(3) | NO | UNI | | |
| District | char(20) | YES | MUL | | |
| Population | int(11) | NO | | 0 | |
+------------+----------+------+-----+---------+----------------+
</pre>

<h3>Adding Indexes</h3>
<p>You create indexes in MySQL with the <code class="inline">CREATE INDEX</code> syntax. There are a few flavours of index. <code class="inline">FULLTEXT</code> is used for full-text searching purposes, and then there is the <code class="inline">UNIQUE</code> type for ensuring data is kept unique.</p>

<p>To add an index to your table, use the following syntax for example:</p>

<pre class="brush: sql noskimlinks noskimwords">mysql&gt; CREATE INDEX idx_start_of_username ON `users` (username(10));
</pre>

<p>This will create an index on the table <code class="inline">users</code>, which will use the first 10 letters of the username column, which is a varchar data type.</p>

<p>In this case, any lookups requiring a <code class="inline">WHERE</code> sort on the username with the match being in the first 10 characters would be the same as a lookup of the entire table.</p>

<h4>Composite Indexes</h4>
<p>Indexes have a huge effect on the speed it takes to return the query data. Just setting a primary key and unique index is generally not enough&#x2014;composite keys are where the real tuning niche lies in MySQL, and most often this requires some A/B checking with <code class="inline">EXPLAIN</code>.</p>

<p>For example, if we need to reference two columns within our <code class="inline">WHERE</code> conditional, a composite key would be ideal.</p>

<pre class="brush: sql noskimlinks noskimwords">mysql&gt; CREATE INDEX idx_composite ON users (username, active);
</pre>

<p>Here this key is being created on the <code class="inline">username</code> column from the prior example and the column <code class="inline">active</code>, an <code class="inline">ENUM</code> data type that signifies whether the user account is active. So now when querying the data for <code class="inline">WHERE</code> the username is valid and account is <code class="inline">active = 1</code>, the dataset is now optimized to handle this better.</p>

<h2>How Fast Is Your MySQL?</h2>
<p>Enable profiling to take a closer look at your MySQL queries. This can be done at run time via <code class="inline">set profiling=1</code>, and then executing your query and looking at the result of <code class="inline">show profiles</code>.</p>

<p>With PDO here&#x2019;s a snippet of code that does just that:</p>

<pre class="brush: php noskimlinks noskimwords">$db-&gt;query('set profiling=1'); 
$db-&gt;query('select headline, body, tags from posts');
$rs = $db-&gt;query('show profiles');
$db-&gt;query('set profiling=0'); // Disable profiling after the query has been run

$records = $rs-&gt;fetchAll(PDO::FETCH_ASSOC); // Get the results from profiling

$errmsg = $rs-&gt;errorInfo()[2]; //Catch any errors here
</pre>

<p>If you are not using PDO, the same can be done with <code class="inline">mysqli</code> as so:</p>

<pre class="brush: php noskimlinks noskimwords">$db = new mysqli($host,$username,$password,$dbname);

$db-&gt;query('set profiling=1');
$db-&gt;query('select headline, body, tags from posts');
if ($result = $db-&gt;query("SHOW profiles", MYSQLI_USE_RESULT)) {
 while ($row = $result-&gt;fetch_row()) {
 var_dump($row);
 }
 $result-&gt;close();
}

if ($result = $db-&gt;query("show profile for query 1", MYSQLI_USE_RESULT)) {
 while ($row = $result-&gt;fetch_row()) {
 var_dump($row);
 }
 $result-&gt;close();
}

$db-&gt;query('set profiling=0');
</pre>

<p>This will return to you the profiling data, which will include the execution time in the second value of the associative array:</p>

<pre class="brush: php noskimlinks noskimwords">array(3) { 
	[0]=&gt; string(1) "1" 
 [1]=&gt; string(10) "0.00024300" 
 [2]=&gt; string(17) "select headline, body, tags from posts" 
 }
</pre>
<p>The query took 0.00024300 seconds to complete. That&#x2019;s fast enough to not worry about. But when numbers ramp up, we must take a deeper look.</p>

<p>As a working example, get to know your app. Place a check for a <code class="inline">DEBUG</code> constant in your application&#x2019;s database abstraction layer / frameworks database driver, and then you can start auditing by enabling a profile case and outputting the result with a <code class="inline">var_dump</code> / <code class="inline">print_r</code>. Now you will be able to browse and profile your website&#x2019;s pages with ease!</p>

<h2>Fully Auditing Your App</h2>

<p>To do a full audit of your queries, enable logging. Some developers I have worked with worry that this is a double-sided problem in that enabling the logging slightly affects performance, and so the stats you record will be slightly lower than in reality. Whilst this is true, many benchmarks show it&#x2019;s not too much of a difference.</p>

<p>To enable logging in MySQL version 5.1.6, you use the global <code class="inline">log_slow_queries</code> and can specify a file with <code class="inline">slow_query_log_file</code> global. This can be done in the runtime prompt as so:</p>

<pre class="brush: bash noskimlinks noskimwords">set global log_slow_queries = 1;
set global slow_query_log_file = /dev/slow_query.log;
</pre>

<p>You can set this persistently in the <code class="inline">/etc/my.cnf</code> or <code class="inline">my.ini</code> configuration file for your server.</p>

<pre class="brush: bash noskimlinks noskimwords">log_slow_queries = 1; 
slow_query_log_file = /dev/slow_query.log;
</pre>

<p>After making this change, you must restart the MySQL server, e.g. <code class="inline">service mysql restart</code> on Linux systems.</p>

<p>In the newer MySQL 5.6.1, <code class="inline">log_slow_queries</code> is deprecated and <code class="inline">slow_query_log</code> is used instead. Enabling <code class="inline">TABLE</code> as output type allows for a much nicer debugging experience and can be done as follows in MySQL 5.6.1 and later:</p>

<pre class="brush: bash noskimlinks noskimwords">log_output = TABLE;
log_queries_not_using_indexes = 1;
long_query_time = 1
</pre>

<p><code class="inline">long_query_time</code> specifies the number of seconds a slow query is classified as. The default is 10 and the minimum 0. It can take millisecond values by specifying a float; here I have set it to 1 second. So any query taking longer than 1 second is going to get logged in the <code class="inline">TABLE</code> output format.</p>

<p>This will log to the <code class="inline">mysql.slow_log</code> and <code class="inline">mysql.general_log</code> tables within <code class="inline">MySQL</code>.</p>

<p>To disable logging, set <code class="inline">log_output</code> to <code class="inline">NONE</code>.</p>

<p><code class="inline">log_queries_not_using_indexes</code> is a useful boolean that, when enabled in conjunction with the slow query log, means that only queries that are expected to retrieve all rows are logged.</p>

<p>This option does not always mean that no index is used. For example, when a query uses a full index scan, this would be logged because the index would not limit the number of rows.</p>

<h3>Logging in Production?</h3>
<p>Enabling logging on a production site with traffic will pretty much always have to be done for a short period, whilst monitoring the load to ensure it doesn&#x2019;t affect service. If you are under heavy load and need an urgent fix, start by addressing the problem at the prompt with <code class="inline">SHOW PROCESSLIST</code> or via the <code class="inline">information_schema.PROCESSLIST</code> table directly, e.g. <code class="inline">select articles _articles bin CAs devops Documents dotfiles gethtml go hnews jason js netdata start-thesrc thesrc ucii from information_schema.PROCESSLIST;</code>.</p>

<p>Logging all queries in production can tell you a lot and is a good practice for research purposes when you are auditing a project, but leaving it running for days on end will often not give you any more usable data than at most 48 hours would do (on average, at least capture the peak times of usage to have a good look at the queries and get some ideas of frequency).</p>

<p>Note: if you run a site that experiences surges of peak traffic and then periods of not much at all (such as a sports website during on and off season), be logical with how you look at logging. Don&#x2019;t assume the site is working fast. Do audit and most importantly set up some graphing.</p>

<h3>Logging and Percona&#x2019;s pt-query-digest</h3>
<p>Percona has some great tools bundled with it, and <code class="inline">pt-query-digest</code> is a command-line tool for analyzing query logs, the processlist or tcpdumps.</p>

<p>You can use <code class="inline">pt-query-digest</code> in the following ways:</p>

<p>Analyze a *.log file (outputted from your slow query logging for example):</p>

<pre class="brush: bash noskimlinks noskimwords">$ pt-query-digest slow.log
</pre>

<p>Report on the slowest queries from host1 in real time (very useful!):</p>

<pre class="brush: bash noskimlinks noskimwords">$ pt-query-digest --processlist h=host1
</pre>

<p>Use tcpdump to report the slowest queries from MySQL protocol data:</p>

<pre class="brush: bash noskimlinks noskimwords">$ tcpdump -s 65535 -x -nn -q -tttt -i any -c 1000 port 3306 &gt; mysql.tcp.txt

$ pt-query-digest --type tcpdump mysql.tcp.txt
</pre>

<p>Finally we can save slow query data from one host to another for later review. Here we save the query digest for slow.log to host2:</p>

<pre class="brush: bash noskimlinks noskimwords">$ pt-query-digest --review h=host2 --no-report slow.log
</pre>

<p>To learn how to fully use the <code class="inline">pt-query-digest</code> tool of Percona, read the <a href="https://www.percona.com/doc/percona-toolkit/2.2/pt-query-digest.html">manual page</a>.</p>

<h3>Graphing MySQL and Server Performance</h3>
<figure class="post_image">
<img src="https://www.percona.com/doc/percona-monitoring-plugins/1.0/_images/mysql_innodb_row_operations.png" alt="InnoDB Row Operations">
</figure>

<p>This graph of InnoDB Row Operations shows the row operations InnoDB has performed: updates, reads, deletes and inserts.</p>

<p>This is a big topic indeed and I will just touch on it enough in this guide to get you started with MySQL monitoring. It&#x2019;s important to note in general, however, that monitoring of all your website&#x2019;s services is ideal to really know what your performance and usages are.</p>

<p>To achieve this I recommend setting up a <code class="inline">RRDTool</code>-based solution such as <code class="inline">Cacti</code> with a MySQL configuration. Get a <a href="https://www.percona.com/doc/percona-monitoring-plugins/1.0/cacti/mysql-templates.html">template for Cacti</a> from the guys at Percona.</p>

<p>Once you have got Cacti set up and can start to analyse your app, allow some time to pass so that the graphs can build up. After a few days you will start to see the day and night rhythms of your traffic and see how busy the server does truly get.</p>

<p>If you are looking for automated alerts and triggers, look into configuring <a href="https://mmonit.com/">monit</a>, an open-source proactive monitor for Unix systems. With monit you can create rules for your server and ensure you are alerted when the load rises so you can catch it while it happens.</p>

<h3>Slow Query Log</h3>
<p>Logging all slow queries that take more than a second to complete can tell us something, but also knowing which queries are executing hundreds of times is equally important. Even if those queries are short to execute, the overhead of high requests still takes its toll on the server.</p>

<p>That&#x2019;s why staying around when you update something and put it live is the most crucial time for any new database work and changes. We always have a policy on my teams to never sync new feature database changes after a Wednesday on a live project. It must be done at the start of the week, at latest Tuesday, so that all teams can monitor and provide support accordingly.</p>

<p>Before going live with new queries, you must benchmark with a load-testing tool such as <code class="inline">ab</code>. When you run the benchmark you must be viewing the <code class="inline">SHOW PROCESSLIST</code>, and also enabling logging and be monitoring with system tools like <code class="inline">top</code>, <code class="inline">free</code> and <code class="inline">iostat</code>. This is a crucial step before putting any new query into a live production. But it is not a 100% acid test because live traffic can behave far differently to a computed benchmark.</p>

<p>To benchmark with <code class="inline">ab</code>, ensure you have the package installed, e.g.:</p>

<pre class="brush: bash noskimlinks noskimwords">#centos users
$ sudo yum install ab
#debian / ubuntu users
$ sudo apt-get install ab
</pre>

<p>Now you can start by testing your app, for example:</p>

<pre class="brush: bash noskimlinks noskimwords">$ ab -k -c 350 -n 20000 my-domain.com/
</pre>

<p>The <code class="inline">-k</code> means to <code class="inline">keep-alive</code> the connection, and the <code class="inline">-c 350</code> is the number of concurrent connections, i.e. the number of people/clients that will hit the site at once. Finally the <code class="inline">-n 20000</code> is the number of requests that will be made to <code class="inline">my-domain.com</code>.</p>

<p>So by running the command above, you will be hitting http://my-domain.com/ with 350 simultaneous connections until 20,000 requests are met, and this will be done using the keep alive header.</p>

<p>After the process finishes the 20,000 requests, you will receive feedback on stats. This will tell you how well the site performed under the stress you put it when using the parameters above. This is a good way to know in an automated sense if your query has changed anything.</p>

<h3>Benchmarking Hot vs. Cold</h3>
<p>Request amount and server load have a huge impact on performance, and query time can be affected due to this. In all you should enable the slow query log to catch this in production, and as a rule for development you must ensure all queries are executing in fractions of a millisecond (0.0xx or faster) on an idle server.</p>

<p>Implementing <code class="inline">Memcache</code> will have a dramatic impact on your load requirements and will be used to seriously offload resources that were being used up processing queries. Ensure you are using <code class="inline">Memcached</code> effectively and benchmark your app with a hot cache (preloaded with values) vs. a cold one.</p>

<p>To avoid stepping out into production with an empty cache, a pre-loader script is a good way of ensuring the cache will be read and you won&#x2019;t get a huge number of requests all coming in at once when returning from a downtime due to over-capacity failures.</p>

<h2>Fixing Slow Queries</h2>
<p>So having enabled logging, you&#x2019;ve now found some slow queries in your app. Let&#x2019;s get to fixing them! For example purposes, I will demonstrate various common problems you will encounter and the logic to fix them.</p>

<p>If you haven&#x2019;t found any slow queries yet, then maybe check what your settings where for the <code class="inline">long_query_time</code> if you are using the query logging method. Otherwise, having checked all your queries with profiling (<code class="inline">set profiling=1</code>), make a list of the queries which are taking longer than fractions of a millisecond to complete (0.000x seconds) and let&#x2019;s start on those.</p>

<h3>Common Problems</h3>
<p>Here are six common problems I run into when optimizing MySQL queries:</p>

<h4>1. <code class="inline">ORDER BY</code> using filesort.</h4>

<pre class="brush: sql noskimlinks noskimwords">mysql&gt; explain select articles _articles bin CAs devops Documents dotfiles gethtml go hnews jason js netdata start-thesrc thesrc ucii from products where products.price &gt; 4 and products.stock &gt; 0 order by name;
+----+-------------+----------+------+---------------+------+---------+------+------+-----------------------------+
| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |
+----+-------------+----------+------+---------------+------+---------+------+------+-----------------------------+
| 1 | SIMPLE | products | ALL | NULL | NULL | NULL | NULL | 1142 | Using where; Using filesort |
+----+-------------+----------+------+---------------+------+---------+------+------+-----------------------------+
</pre>

<p>Avoiding filesort on this is impossible because of the <code class="inline">ORDER BY name</code>. No matter what index permutation you use, the best you will get is <code class="inline">Using where; Using Filesort</code> in your <code class="inline">Extra</code> column. To optimize this, save the result in Memcache, or do ordering in your application&#x2019;s logic layer.</p>

<h4>2. Using <code class="inline">ORDER BY</code> on <code class="inline">WHERE</code> and a <code class="inline">LEFT JOIN</code>
</h4>

<p><code class="inline">ORDER BY</code> has a significant toll on queries. For example, the following is a basic <code class="inline">LEFT JOIN</code> of a <code class="inline">products</code> table and <code class="inline">categories</code> table by means of an integer ID. When ordering is removed, so is the filesorting.</p>

<pre class="brush: sql noskimlinks noskimwords">mysql&gt; explain select products.* from products use index (idx_price) left join categories using (catID) where products.price &gt; 4 and catID = 4 ORDER BY stock ASC limit 10;
+----+-------------+------------+-------+---------------+---------+---------+-------+------+-----------------------------+
| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |
+----+-------------+------------+-------+---------------+---------+---------+-------+------+-----------------------------+
| 1 | SIMPLE | products | ALL | idx_price | NULL | NULL | NULL | 986 | Using where; Using filesort |
| 1 | SIMPLE | categories | const | PRIMARY | PRIMARY | 4 | const | 1 | Using index |
+----+-------------+------------+-------+---------------+---------+---------+-------+------+-----------------------------+
2 rows in set (0.00 sec)

mysql&gt; explain select products.* from products use index (idx_price) left join categories using (catID) where products.price &gt; 4 and catID = 4;
+----+-------------+------------+-------+---------------+---------+---------+-------+------+-------------+
| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |
+----+-------------+------------+-------+---------------+---------+---------+-------+------+-------------+
| 1 | SIMPLE | products | ALL | idx_price | NULL | NULL | NULL | 986 | Using where |
| 1 | SIMPLE | categories | const | PRIMARY | PRIMARY | 4 | const | 1 | Using index |
+----+-------------+------------+-------+---------------+---------+---------+-------+------+-------------+
2 rows in set (0.00 sec)
</pre>

<p>When it can be avoided, try not to use an <code class="inline">ORDER BY</code>. If it absolutely must be used, order on an index key only.</p>

<h4>3. <code class="inline">Order By</code> on a temp column</h4>

<p>Just don&#x2019;t do it. If you are needing to aggregate your results, do that in your application logic; don&#x2019;t do the filtering or ordering on a temporary table inside MySQL. It&#x2019;s going to be very resource intensive.</p>

<h4>4. Not using a <code class="inline">FULLTEXT</code> index</h4>

<p>Using a <code class="inline">LIKE</code> query is by far the slowest way to perform a full-text match on your data. Implement a full-text search and reap the benefits of this brilliant feature of MySQL as so:</p>

<pre class="brush: sql noskimlinks noskimwords">mysql&gt; SELECT articles _articles bin CAs devops Documents dotfiles gethtml go hnews jason js netdata start-thesrc thesrc ucii FROM articles
 -&gt; WHERE MATCH (title,body) AGAINST ('database');
+----+-------------------+------------------------------------------+
| id | title | body |
+----+-------------------+------------------------------------------+
| 5 | MySQL vs. YourSQL | In the following database comparison ... |
| 1 | MySQL Tutorial | DBMS stands for DataBase ... |
+----+-------------------+------------------------------------------+
2 rows in set (0.00 sec)
</pre>

<h4>5. Selecting huge numbers of rows needlessly</h4>

<p>Forgetting a <code class="inline">LIMIT</code> on a query can significantly change the lookup time over large datasets (over a million rows).</p>

<h4>6. Over-joining instead of just making a composite table or view</h4>

<p>When it gets to three or four levels of <code class="inline">LEFT JOIN</code>, you should ask yourself: &#x201C;Am I doing this right?&#x201D; If you have a reasonable argument for why this query must be so, for example it only appears in an admin screen in low demand or in usage of a larger statistical view that can be cached, then proceed. But if you are needing to access your data frequently with large numbers of joins, you should look at how compositing columns together into a new table may be more beneficial, or creating a <a href="https://dev.mysql.com/doc/refman/5.0/en/views.html">view</a>.</p>

<h2>Conclusions</h2>
<p>We have discussed the fundamentals of optimization and the tools we have at our disposal to perform the work. We must audit with profiling, and use the <code class="inline">pt-query-digest</code> tool and <code class="inline">EXPLAIN</code> first to see what is really going on, and then from there we can design better.</p>

<p>We also looked at several example cases and common pitfalls you can run into when using MySQL. Using index hinting we can ensure MySQL selects the right indexes for the job and does not get confused, especially if there are multiple queries on the same table. 
To continue your reading on this topic, check out the <a href="http://www.percona.com">Percona project</a> and <a href="https://www.percona.com/blog/">MySQL Performance blog</a> for more information.</p>
</div></div>
</body></html>
