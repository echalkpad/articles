<!DOCTYPE html><html><head><title>LogZoom, a fast and lightweight substitute for Logstash</title></head><body>
<h1>LogZoom, a fast and lightweight substitute for Logstash</h1><p><a href="https://packetzoom.com/blog/logzoom-a-fast-and-lightweight-substitute-for-logstash.html" target="_new">Original URL</a></p>
<p><blockquote>Date Fri 08 April 2016 By Stan Hu Tags elasticsearch / golang / fluentd / logstash Today, we at PacketZoom are proud to release our open source tool LogZoom, a fast, lightweight, and reliable log&hellip;</blockquote></p>
<div><div class="entry-content">
 <div class="panel">
 <p class="panel-body">
<footer class="post-info">
 <span class="label label-default">Date</span>
 <span class="published">
 <i class="fa fa-calendar"></i><time datetime="2016-04-08T00:00:00+02:00"> Fri 08 April 2016</time>
 </span>


 <span class="label label-default">By</span>
 <i class="fa fa-user"></i> Stan Hu




<span class="label label-default">Tags</span>
	elasticsearch
 /
	golang
 /
	fluentd
 /
	logstash
 
</footer> </p>
 </div>
 

<img alt="LogZoom Logo" src="https://packetzoom.com/blog/images/LogZoom-small.png">
<p>Today, we at PacketZoom are proud to release our open source tool LogZoom,
a fast, lightweight, and reliable log data indexer written in Go. If you've
ever considered using Logstash, Fluentd, or some other tool for log
aggregation, you may want to consider using LogZoom instead.</p>
<p>Here are a number of resources for getting up and running with LogZoom:</p>
<ul>
<li><a href="https://github.com/packetzoom/logzoom">Home page</a></li>
<li><a href="https://github.com/packetzoom/logzoom/releases">Binary release for Ubuntu 14.04</a></li>
<li><a href="https://github.com/packetzoom/logzoom/tree/master/examples">Example configuration files</a></li>
</ul>


<h3>Before LogZoom: Logstash and Fluentd</h3>
<p>At PacketZoom, we serve millions of URLs a day, and we gather metrics about
each of those transfers to help improve our service to customers. To
centralize and insert all this data into multiple databases, we first tried
<a href="https://www.elastic.co/products/logstash">Logstash</a>. This worked for a while,
but when we wanted to make our pipeline more fault-tolerant, Logstash required
us to <a href="https://www.elastic.co/guide/en/logstash/current/deploying-and-scaling.html">run multiple
processes</a>. That
in of itself was fine, but Logstash, which runs under a JRuby VM, often would
dominate memory and CPU consumption on our machine, particularly when network
disconnections and other errors occurred. We did not like the idea of adding
more JVMs and tuning more esoteric JVM parameters, so we started looking for
alternatives.</p>
<p>Hoping for better results, we then switched to
<a href="http://www.fluentd.org">Fluentd</a>, opting to take advantage of the <a href="https://docs.treasuredata.com/articles/td-agent-high-availability">built-in
buffering
capabilities</a>
and the third-party plugins available. However, we ran into all sorts of
reliability and scalability issues with Fluentd:</p>

<p>As our data grew, Fluentd would often peg the CPU at 100% utilization. A
<code>perf</code> trace suggested that the Ruby VM was spending a lot of time garbage
collecting. As a result, Fluentd could not keep up with the flow of data,
leading to runaway growth in its inbound buffers.</p>
<p>We saw that Elastic had released
<a href="https://www.elastic.co/products/beats/filebeat">Filebeat</a>, a completely
rewrite of Logstash Forwarder in Go. We liked the efficiency of Filebeat, but
only Logstash supported it. The Ruby factor kept us from switching back to
Logstash. Plus, some of the Logstash plugins lacked features we wanted
(e.g. insertion to timestamped S3 buckets).</p>
<p>We kept wondering: why wasn't there a Go server to receive data sent from a Go
client? Programs written in Go tend to be fast, compact, efficient, not to
mention highly concurrent. The single binary that the Go compiler outputs is
also a nice touch, reducing the need for external libraries and other
dependencies.</p>
<p>That's why we decided to create LogZoom. To handle our stream of structured
data, we looked around for other Go tools that would handle the Lumberjack
protocol and found <a href="https://github.com/hailocab/logslam">Hailo's logslam</a>.
We took the source code and made a number of improvements.</p>
<h3>What does LogZoom do?</h3>
<p>Like Logstash, LogZoom receives JSON data from Filebeat via the <a href="https://github.com/elastic/libbeat/issues/279">Lumberjack
v2</a> protocol and inserts the
data into different outputs. For example, let's say your application generated
a JSON line for every event:</p>
<div class="highlight"><pre><span class="p">{</span><span class="nt">"@timestamp"</span><span class="p">:</span><span class="s2">"2016-03-31T22:23:14+0000"</span><span class="p">,</span> <span class="nt">"url"</span><span class="p">:</span> <span class="s2">"http://www.google.com"</span><span class="p">}</span>
<span class="p">{</span><span class="nt">"@timestamp"</span><span class="p">:</span><span class="s2">"2016-03-31T22:25:14+0000"</span><span class="p">,</span> <span class="nt">"url"</span><span class="p">:</span> <span class="s2">"http://www.bing.com"</span><span class="p">}</span>
<span class="p">{</span><span class="nt">"@timestamp"</span><span class="p">:</span><span class="s2">"2016-03-31T22:26:14+0000"</span><span class="p">,</span> <span class="nt">"url"</span><span class="p">:</span> <span class="s2">"http://www.yahoo.com"</span><span class="p">}</span>
</pre></div>


<p>As the diagram shows, you can then run a single process of LogZoom to
receive this data and insert to Elasticsearch, S3, etc:</p>
<img alt="LogZoom Basic Diagram" src="https://packetzoom.com/blog/images/logzoom.png">
<p>Unlike Logstash, however, LogZoom does not attempt to manipulate data in
any shape or form. JSON data that arrives from Filebeat is directly sent to
outputs as-is.</p>
<p>Many users commonly use Logstash by adding a grok filter, <a href="https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html">"currently the best
way in logstash to parse crappy unstructured log
data."</a>
LogZoom currently does NOT support this use case; it is designed for
software applications that generate structured data directly.</p>
<p>For example, if you are trying to use Kibana, a frontend to Elasticsearch, you
may need the <code>@timestamp</code> field, which Logstash typically inserts for
you. With LogZoom, your application must generate this field in each JSON
log line. The advantages of using this approach:</p>
<ol>
<li>
<p>LogZoom doesn't have to decode the JSON, insert a new field, and encode
 the JSON again. Logstash and Fluentd spend a fair amount of CPU
 time doing this.</p>
</li>
<li>
<p>The application explicitly defines the semantics of <code>@timestamp</code>. When we
 used Logstash, we were confused that each record was stamped when the entry
 was received by the central Logstash process, not when it was generated by
 the client. This caused great confusion, as we would often see large gaps
 in data when the data was just marked with the wrong timestamp.</p>
</li>
</ol>
<h3>What outputs does LogZoom support?</h3>
<p>In our case, we store data into a number of places for analysis, including:</p>
<ul>
<li>Elasticsearch</li>
<li>Amazon S3</li>
<li>Redshift (via S3)</li>
</ul>
<p>Some people ask: Why do you need both Elasticsearch and Redshift? There are a
number of reasons. Elasticsearch and Kibana make it incredibly easy to
visualize real-time data and filter it with with just a few clicks. Redshift
allows us to make adhoc queries, such as calculating the 95th percentile of
throughput for each of our customer's apps. To get data loaded into Redshift,
we need to send it to S3 first. S3 also provides an archive for data.</p>
<p>One of the limitations we found with both Logstash and Fluentd was that if
indexing into Elasticsearch slowed, the whole data pipeline would also slow.
In our experiences with Elasticsearch 1.7, insertion rates can fluctuate
seemingly randomly, especially when replicas are in use. Because of this,
Fluentd input buffers could grow to the point where S3 inserts would be gated
by how fast Elasticsearch operated. The only way to recover would be to
restart the process, which would cause in-memory data to be dropped
completely.</p>
<p>One of the design goals of LogZoom was to avoid these pitfalls by ensuring
that each data path operates independently. Even if insertions to any database
got slow, the rest of the system would run at full speed. For our use case, we
created two separate pipelines: one for S3 and the other for Elasticsarch.</p>
<h3>Reliability with RedisMQ</h3>
<p>In the simplest case, you can run one process of LogZoom and use it to
directly insert data into multiple outputs. However, if that process crashes
or starts running slowly, you can lose data. To avoid bottlenecks and increase
system reliability, you can add queues into the data pipeline. LogZoom
supports Redis for queueing, using the <a href="https://github.com/adjust/redismq.git">RedisMQ
library</a>. LogZoom's minimal CPU and
memory footprint makes it possible to launch multiple instances easily.</p>
<p>This reliability comes at a price: when data arrives from the client, a copy
of each data gets inserted into a queue for each data pipeline. We thought
this tradeoff was acceptable because in the steady-state case, we expect
processing to keep up, and most of the queues should be small. We use third-party
tools (e.g. Datadog) to monitor the size of these queues. The diagram
below shows how we use LogZoom:</p>
<p><img alt="LogZoom High Availability Diagram" src="https://packetzoom.com/blog/images/logzoom-ha.png"></p>
<p>The left part of this diagram shows how LogZoom consumes input from
Filebeat processes and stores the data into Redis queues. The right part shows
how multiple LogZoom processes consume input from these queues.</p>
<p>To accomplish this, we configured three different instances of LogZoom
running under <a href="http://supervisord.org">Supervisor</a>:</p>
<ol>
<li>Filebeat Input: Reads from Filebeat and copies incoming data to each Redis queue</li>
<li>S3 Output: Pulls from its queue and writes to S3 buckets</li>
<li>Elasticsearch Output: Pulls from its queue and inserts to Elasticsearch</li>
</ol>
<p>The first LogZoom process is critical for receiving input from clients and
inserting the data into the pipeline queues. If this process is not running,
none of the other processes can do any useful work.</p>
<h3>Results</h3>
<p>Our whole team is much happier now that we don't have to deal with alerts
caused by Fluentd and Logstash issues. Our Filebeat and LogZoom setup has
been running reliably for months now. Each LogZoom process typically
consumes less than 10% of the CPU. The LogZoom input process, which has to
receive the flood of data from all our servers, consumes about 150 MB RAM. The
two other processes consume less than 40 MB RAM. Taken together, these results
are a dramatic improvement over our experience with Logstash and Fluentd.</p>
<h3>Getting up and running with LogZoom</h3>
<p>Visit the <a href="https://github.com/packetzoom/logzoom">home page</a> for the latest
news and documentation. If you are running Ubuntu 14.04, you can download the
<a href="https://github.com/packetzoom/logzoom/releases">binary release here</a>.</p>
<p>Assuing you have a Go compiler installed, you can also compile and run the
software:</p>
<div class="highlight"><pre>$ go get github.com/packetzoom/logzoom
$ go build
</pre></div>


<p>Once you have the binary, you just need a YAML configration file. For example,
this <code>logzoom.yml</code> configuration file will receive data over SSL from Filebeat
and write to a local Elasticsearch instance:</p>
<div class="highlight"><pre><span class="nn">---</span>
<span class="l l-Scalar l-Scalar-Plain">inputs</span><span class="p p-Indicator">:</span>
 <span class="l l-Scalar l-Scalar-Plain">filebeat</span><span class="p p-Indicator">:</span>
 <span class="l l-Scalar l-Scalar-Plain">host</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0.0.0:5000</span>
 <span class="l l-Scalar l-Scalar-Plain">ssl_crt</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/etc/filebeat/logstash-forwarder.crt</span>
 <span class="l l-Scalar l-Scalar-Plain">ssl_key</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/etc/filebeat/logstash-forwarder.key</span>
<span class="l l-Scalar l-Scalar-Plain">outputs</span><span class="p p-Indicator">:</span>
 <span class="l l-Scalar l-Scalar-Plain">elasticsearch</span><span class="p p-Indicator">:</span>
 <span class="l l-Scalar l-Scalar-Plain">hosts</span><span class="p p-Indicator">:</span>
 <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">http://localhost:9200</span>
 <span class="l l-Scalar l-Scalar-Plain">index</span><span class="p p-Indicator">:</span> <span class="s">"logstash"</span>
 <span class="l l-Scalar l-Scalar-Plain">index_type</span><span class="p p-Indicator">:</span> <span class="s">"logzoom"</span>
 <span class="l l-Scalar l-Scalar-Plain">gzip_enabled</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
 <span class="l l-Scalar l-Scalar-Plain">info_log_enabled</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
 <span class="l l-Scalar l-Scalar-Plain">error_log_enabled</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
</pre></div>


<p>You can then run:</p>
<div class="highlight"><pre>logzoom -config=logzoom.yml
</pre></div>


<p>More examples are <a href="https://github.com/packetzoom/logzoom/tree/master/examples">included
here</a>.</p>
<p>See <a href="https://github.com/packetzoom/logzoom/blob/master/README.md">README.md</a> for more details.
We welcome pull requests.</p>
<h3>Thanks</h3>
<p>We thank Hailo for releasing Logslam, the perfect foundation for LogZoom.</p>
 </div>
 
 </div>
</body></html>
