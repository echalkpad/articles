<!DOCTYPE html><html><head><title>Title:
Recurrent Neural Networks Hardware Implementation on FPGA</title></head><body>
<h1>Title:
Recurrent Neural Networks Hardware Implementation on FPGA</h1><p><a href="http://arxiv.org/abs/1511.05552v1" target="_new">Original URL</a></p>
<p><blockquote>Full-text links: PDF Other formats Current browse context: cs.NE &lt;&#xA0;prev&#xA0;|&#xA0;next&#xA0;&gt;</blockquote></p>
<div><div id="content">



<div id="abs">
<div class="extra-services">

<div class="full-text">
<span class="descriptor">Full-text links:</span>

<ul>
<li><a href="http://arxiv.org/pdf/1511.05552v1" accesskey="f">PDF</a></li>
<li><a href="http://arxiv.org/format/1511.05552v1">Other formats</a></li>
</ul>
<div class="abs-license"><a href="http://creativecommons.org/licenses/by/4.0/" title="Rights to this article"><img src="http://arxiv.org/icons/licenses/by-4.0.png"></a></div>
</div>

<div class="browse">
<h3>Current browse context:</h3>
<p class="current">cs.NE</p>
<div class="prevnext"><span class="arrow"><a href="http://arxiv.org/prevnext?site=arxiv.org&amp;id=1511.05552&amp;context=cs.NE&amp;function=prev" accesskey="p" title="previous in cs.NE (accesskey p)">&lt;&#xA0;prev</a></span>&#xA0;|&#xA0;<span class="arrow"><a href="http://arxiv.org/prevnext?site=arxiv.org&amp;id=1511.05552&amp;context=cs.NE&amp;function=next" accesskey="n" title="next in cs.NE (accesskey n)">next&#xA0;&gt;</a></span>
<br></div>
<div class="list"><a href="http://arxiv.org/list/cs.NE/new">new</a>&#xA0;| <a href="http://arxiv.org/list/cs.NE/recent">recent</a>&#xA0;| <a href="http://arxiv.org/list/cs.NE/1511">1511</a></div><h3>Change to browse by:</h3><div class="switch">
<a href="http://arxiv.org/abs/1511.05552?context=cs">cs</a>
</div>

</div>
<div class="extra-ref-cite">
<h3>References &amp; Citations</h3><ul><li><a href="http://adsabs.harvard.edu/cgi-bin/bib_query?arXiv:1511.05552">NASA ADS</a></li>
</ul>

</div>
<div class="bookmarks">
<div class="what-is-this">
<h3>Bookmark</h3> (<a href="http://arxiv.org/help/social_bookmarking">what is this?</a>)
</div>
<a href="http://arxiv.org/ct?url=http%3A%2F%2Fwww.citeulike.org%2Fposturl%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1511.05552%26title%3DRecurrent%2520Neural%2520Networks%2520Hardware%2520Implementation%2520on%2520FPGA%26authors%3D&amp;v=24080dde" title="Bookmark on CiteULike"><img src="http://static.arxiv.org/icons/social/citeulike.png" alt="CiteULike logo"></a>
<a href="http://arxiv.org/ct?url=http%3A%2F%2Fwww.bibsonomy.org%2FBibtexHandler%3FrequTask%3Dupload%26url%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1511.05552%26description%3DRecurrent%2520Neural%2520Networks%2520Hardware%2520Implementation%2520on%2520FPGA&amp;v=2502a53f" title="Bookmark on BibSonomy"><img src="http://static.arxiv.org/icons/social/bibsonomy.png" alt="BibSonomy logo"></a>
<a href="http://arxiv.org/ct?url=http%3A%2F%2Fwww.mendeley.com%2Fimport%2F%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1511.05552&amp;v=ad291bcb" title="Bookmark on Mendeley"><img src="http://static.arxiv.org/icons/social/mendeley.png" alt="Mendeley logo"></a>
<a href="http://arxiv.org/ct?url=http%3A%2F%2Fdel.icio.us%2Fpost%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1511.05552%26description%3DRecurrent%2520Neural%2520Networks%2520Hardware%2520Implementation%2520on%2520FPGA&amp;v=cda221c5" title="Bookmark on del.icio.us"><img src="http://static.arxiv.org/icons/social/delicious.png" alt="del.icio.us logo"></a>
<a href="http://arxiv.org/ct?url=http%3A%2F%2Fdigg.com%2Fsubmit%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1511.05552%26title%3DRecurrent%2520Neural%2520Networks%2520Hardware%2520Implementation%2520on%2520FPGA&amp;v=1f9c8d3c" title="Bookmark on Digg"><img src="http://static.arxiv.org/icons/social/digg.png" alt="Digg logo"></a>
<a href="http://arxiv.org/ct?url=http%3A%2F%2Freddit.com%2Fsubmit%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1511.05552%26title%3DRecurrent%2520Neural%2520Networks%2520Hardware%2520Implementation%2520on%2520FPGA&amp;v=e56f4334" title="Bookmark on Reddit"><img src="http://static.arxiv.org/icons/social/reddit.png" alt="Reddit logo"></a>
<a href="http://arxiv.org/ct?url=http%3A%2F%2Fsciencewise.info%2Fbookmarks%2Fadd%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1511.05552&amp;v=818b0957" title="Bookmark on ScienceWISE"><img src="http://static.arxiv.org/icons/social/sciencewise.png" alt="ScienceWISE logo"></a>

</div>
</div>

<div class="leftcolumn">


<div class="authors"><span class="descriptor">Authors:</span>
<a href="http://arxiv.org/find/cs/1/au:+Chang_A/0/1/0/all/0/1">Andre Xian Ming Chang</a>, 
<a href="http://arxiv.org/find/cs/1/au:+Martini_B/0/1/0/all/0/1">Berin Martini</a>, 
<a href="http://arxiv.org/find/cs/1/au:+Culurciello_E/0/1/0/all/0/1">Eugenio Culurciello</a></div>
<p class="dateline">(Submitted on 17 Nov 2015)</p>
<blockquote class="abstract mathjax">
<span class="descriptor">Abstract:</span> Recurrent Neural Networks (RNNs) have the ability to retain memory and learn
data sequences, and are a recent breakthrough of machine learning. Due to the
recurrent nature of RNNs, it is sometimes hard to parallelize all its
computations on conventional hardware. CPUs do not currently offer large
parallelism, while GPUs offer limited parallelism due to branching in RNN
models. In this paper we present a hardware implementation of Long-Short Term
Memory (LSTM) recurrent network on the programmable logic Zynq 7020 FPGA from
Xilinx. We implemented a RNN with 2 layers and 128 hidden units in hardware and
it has been tested using a character level language model. The implementation
is more than $21\times$ faster than the ARM CPU embedded on the Zynq 7020 FPGA.
This work can potentially evolve to a RNN co-processor for future mobile
devices.
</blockquote>

<div class="metatable">
<table summary="Additional metadata">
<tr>
<td class="tablecell label">Comments:
</td>
<td class="tablecell comments">9 pages, 9 figures, International Conference on Learning Representations (ICLR)</td>
</tr>
<tr>
<td class="tablecell label">Subjects:
</td>
<td class="tablecell subjects"><span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span></td>
</tr>
<tr>
<td class="tablecell label">
Cite&#xA0;as:
</td>
<td class="tablecell arxivid"><a href="http://arxiv.org/abs/1511.05552">arXiv:1511.05552</a> [cs.NE]</td>
</tr>
<tr>
<td class="tablecell label">&#xA0;</td>
<td class="tablecell arxividv">(or <span class="arxivid"><a href="http://arxiv.org/abs/1511.05552v1">arXiv:1511.05552v1</a> [cs.NE]</span> for this version)</td>
</tr>
</table>
</div>
<div class="submission-history">
<h2>Submission history</h2>
From: Andre Xian Ming Chang [<a href="https://arxiv.org/show-email/5d6bd836/1511.05552">view email</a>]
<br>
<b>[v1]</b> Tue, 17 Nov 2015 02:20:37 GMT (1490kb,D)<br>
</div>
<div class="endorsers"><a href="http://arxiv.org/auth/show-endorsers/1511.05552">Which authors of this paper are endorsers?</a> | <a id="mathjax_toggle" href="">Disable MathJax</a> (<a href="http://arxiv.org/help/mathjax/">What is MathJax?</a>)</div>
</div>
</div>
</div>
</div>
</body></html>
